{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f382d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, json, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import Iterator, Tuple, Optional, List\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "PROJECT_DIR = \"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER\"\n",
    "SRC_DIR = str(Path(PROJECT_DIR) / \"src\")\n",
    "if SRC_DIR not in sys.path:\n",
    "    sys.path.insert(0, SRC_DIR)\n",
    "\n",
    "from multiomic_transformer.models.model import MultiomicTransformer\n",
    "from multiomic_transformer.datasets.dataset_refactor import MultiChromosomeDataset, SimpleScaler, fit_simple_scalers\n",
    "import multiomic_transformer.utils.experiment_loader as experiment_loader\n",
    "\n",
    "\n",
    "\n",
    "def tanh_scaled_figsize(\n",
    "    rows: int,\n",
    "    cols: int,\n",
    "    short_in: float = 3.0,\n",
    "    max_ratio: float = 5.0,\n",
    "    alpha: float = 0.85,\n",
    "    min_w: float = 2.5,\n",
    "    max_w: float = 10.0,\n",
    "    min_h: float = 2.0,\n",
    "    max_h: float = 10.0,\n",
    "):\n",
    "    if rows <= 0 or cols <= 0:\n",
    "        return (short_in, short_in)\n",
    "\n",
    "    raw_ratio = max(rows, cols) / max(1, min(rows, cols))  # >= 1\n",
    "    scaled_ratio = 1.0 + (max_ratio - 1.0) * math.tanh(alpha * math.log(raw_ratio))\n",
    "\n",
    "    if rows >= cols:\n",
    "        fig_w = short_in\n",
    "        fig_h = short_in * scaled_ratio\n",
    "    else:\n",
    "        fig_w = short_in * scaled_ratio\n",
    "        fig_h = short_in\n",
    "\n",
    "    # ---- NEW: clamp absolute size ----\n",
    "    fig_w = float(np.clip(fig_w, min_w, max_w))\n",
    "    fig_h = float(np.clip(fig_h, min_h, max_h))\n",
    "\n",
    "    return fig_w, fig_h\n",
    "\n",
    "\n",
    "def downsample_2d_mean(data: np.ndarray, max_rows=1500, max_cols=1500):\n",
    "    r, c = data.shape\n",
    "    row_bin = max(1, int(np.ceil(r / max_rows)))\n",
    "    col_bin = max(1, int(np.ceil(c / max_cols)))\n",
    "\n",
    "    r2 = (r // row_bin) * row_bin\n",
    "    c2 = (c // col_bin) * col_bin\n",
    "    data = data[:r2, :c2]\n",
    "\n",
    "    data = data.reshape(r2 // row_bin, row_bin, c2 // col_bin, col_bin).mean(axis=(1, 3))\n",
    "    return data, row_bin, col_bin\n",
    "\n",
    "def save_input_heatmaps_from_batch(exp, out_dir: Tuple[str, Path], batch_idx: int = 0):\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    batch = next(iter(exp.test_loader))\n",
    "    atac_wins, tf_tensor, tg_expr_true, bias, tf_ids, tg_ids, motif_mask = batch\n",
    "\n",
    "    # ---- TF expression vector (usually [B, n_tf] or [B, n_tf, 1]) ----\n",
    "    tf0 = tf_tensor[batch_idx]\n",
    "    if tf0.ndim == 2 and tf0.shape[-1] == 1:\n",
    "        tf0 = tf0.squeeze(-1)\n",
    "\n",
    "    save_heatmap_svg_rasterized_downsampled(\n",
    "        tf0,\n",
    "        out_dir / f\"input_tf_expr.svg\",\n",
    "        title=f\"Input TF Expr\",\n",
    "    )\n",
    "\n",
    "    # ---- TG true expression (often [B, n_tg] or [B, n_tg, 1]) ----\n",
    "    tg0 = tg_expr_true[batch_idx]\n",
    "    if tg0.ndim == 2 and tg0.shape[-1] == 1:\n",
    "        tg0 = tg0.squeeze(-1)\n",
    "\n",
    "    save_heatmap_svg_rasterized_downsampled(\n",
    "        tg0,\n",
    "        out_dir / f\"input_tg_expr_true.svg\",\n",
    "        title=f\"Input TG Expr True\",\n",
    "    )\n",
    "    \n",
    "    # ---- Batch TG embedding -----\n",
    "    tg_ids0 = tg_ids.to(exp.model.tg_identity_emb.weight.device)\n",
    "\n",
    "    tg_id_slice = exp.model.tg_identity_emb.weight[tg_ids0]  # [193, 128]\n",
    "    save_heatmap_svg_rasterized_downsampled(\n",
    "        tg_id_slice,\n",
    "        \"./dev/model_heatmaps_svg/tg_identity_emb_slice_batch.svg\",\n",
    "        title=\"TGs in Batch\",\n",
    "    )\n",
    "\n",
    "    # ---- Bias (shape varies; make it 2D-ish) ----\n",
    "    b0 = bias[batch_idx]\n",
    "    save_heatmap_svg_rasterized_downsampled(\n",
    "        b0,\n",
    "        out_dir / f\"input_bias.svg\",\n",
    "        title=f\"Input Bias\",\n",
    "    )\n",
    "\n",
    "    # ---- Motif mask (often [B, n_tf, n_tg] or similar) ----\n",
    "    mm0 = motif_mask[batch_idx]\n",
    "    save_heatmap_svg_rasterized_downsampled(\n",
    "        mm0,\n",
    "        out_dir / f\"input_motif_mask.svg\",\n",
    "        title=f\"Input Motif Mask\",\n",
    "    )\n",
    "\n",
    "    # ---- ATAC windows: pick something plottable ----\n",
    "    # If atac_wins is [B, n_peaks, n_bins] → save as 2D\n",
    "    # If higher-dim, flatten everything but last dim.\n",
    "    a0 = atac_wins[batch_idx]\n",
    "    if a0.ndim > 2:\n",
    "        a0 = a0.reshape(a0.shape[0], -1)  # keep first dim, flatten rest\n",
    "    save_heatmap_svg_rasterized_downsampled(\n",
    "        a0,\n",
    "        out_dir / f\"input_atac_wins.svg\",\n",
    "        title=f\"Input ATAC Wins\",\n",
    "        max_rows=1500,\n",
    "        max_cols=1500,\n",
    "    )\n",
    "\n",
    "    print(f\"Saved input heatmaps to: {out_dir}\")\n",
    "\n",
    "def save_heatmap_svg_rasterized_downsampled(\n",
    "    weight_tensor: torch.Tensor,\n",
    "    out_path: Tuple[str, Path],\n",
    "    title: str = \"\",\n",
    "    cmap: str = \"viridis\",\n",
    "    short_in: float = 3.0,\n",
    "    max_ratio: float = 5.0,\n",
    "    alpha: float = 0.85,\n",
    "    dpi: int = 200,\n",
    "    rasterize: bool = True,\n",
    "    vmin=None,\n",
    "    vmax=None,\n",
    "    max_rows: int = 1500,   # <-- NEW\n",
    "    max_cols: int = 1500,   # <-- NEW\n",
    "    is_data: bool = False,\n",
    "):\n",
    "    out_path = Path(out_path)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    data = weight_tensor.detach().cpu().numpy()\n",
    "\n",
    "    if data.ndim == 1:\n",
    "        data = data[None, :]  # shape (1, N)\n",
    "\n",
    "    if data.ndim != 2:\n",
    "        data = np.asarray(data).reshape(data.shape[0], -1)\n",
    "\n",
    "    rows, cols = data.shape\n",
    "    if rows > max_rows or cols > max_cols:\n",
    "        data, row_bin, col_bin = downsample_2d_mean(data, max_rows=max_rows, max_cols=max_cols)\n",
    "        rows, cols = data.shape\n",
    "        title = f\"{title}\"\n",
    "\n",
    "    fig_w, fig_h = tanh_scaled_figsize(\n",
    "        rows, cols,\n",
    "        short_in=short_in,\n",
    "        max_ratio=max_ratio,\n",
    "        alpha=alpha,\n",
    "        min_w=3.0, max_w=9.0,\n",
    "        min_h=2.0, max_h=7.0,\n",
    "    )\n",
    "    fig, ax = plt.subplots(figsize=(fig_w, fig_h))\n",
    "    \n",
    "    if is_data:\n",
    "        cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "    else:\n",
    "        cmap = cmap\n",
    "\n",
    "    sns.heatmap(\n",
    "        data,\n",
    "        cmap=cmap,\n",
    "        xticklabels=False,\n",
    "        yticklabels=False,\n",
    "        cbar=False,\n",
    "        ax=ax,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "\n",
    "    if rasterize and ax.collections:\n",
    "        ax.collections[0].set_rasterized(True)\n",
    "\n",
    "    title = title.replace(\"_\", \" \")\n",
    "    ax.set_title(title, fontsize=24)\n",
    "    ax.set_xlabel(f\"{cols}\", fontsize=32)\n",
    "    ax.set_ylabel(f\"{rows}\", fontsize=32)\n",
    "\n",
    "    fig.tight_layout(pad=0.15)\n",
    "    fig.savefig(out_path, format=out_path.suffix.lstrip(\".\"), dpi=dpi, bbox_inches=\"tight\", facecolor=fig.get_facecolor())\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def iter_weight_matrices(model: torch.nn.Module) -> Iterator[Tuple[str, torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Yields (name, weight_tensor) for 2D weight-like tensors.\n",
    "    Embeddings are treated as 2D weights too.\n",
    "    \"\"\"\n",
    "    for name, param in model.named_parameters():\n",
    "        if not isinstance(param, torch.Tensor):\n",
    "            continue\n",
    "        if param.ndim == 2:\n",
    "            yield name, param.detach()\n",
    "        # If you ever want to include 1D params (bias, layernorm), handle separately.\n",
    "\n",
    "\n",
    "def split_in_proj_weight_qkv(\n",
    "    in_proj_weight: torch.Tensor,\n",
    "    d_model: Optional[int] = None,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Split PyTorch MultiheadAttention in_proj_weight into (Wq, Wk, Wv).\n",
    "    in_proj_weight shape: (3*d_model, d_model)\n",
    "    \"\"\"\n",
    "    if in_proj_weight.ndim != 2:\n",
    "        raise ValueError(f\"in_proj_weight must be 2D, got {in_proj_weight.shape}\")\n",
    "\n",
    "    rows, cols = in_proj_weight.shape\n",
    "    if d_model is None:\n",
    "        d_model = cols\n",
    "\n",
    "    if rows != 3 * d_model:\n",
    "        raise ValueError(\n",
    "            f\"Expected in_proj_weight shape (3*d_model, d_model) = ({3*d_model}, {d_model}), \"\n",
    "            f\"got {in_proj_weight.shape}\"\n",
    "        )\n",
    "\n",
    "    Wq = in_proj_weight[0:d_model, :]\n",
    "    Wk = in_proj_weight[d_model:2*d_model, :]\n",
    "    Wv = in_proj_weight[2*d_model:3*d_model, :]\n",
    "    return Wq, Wk, Wv\n",
    "\n",
    "\n",
    "def save_model_weight_heatmaps(\n",
    "    model: torch.nn.Module,\n",
    "    out_dir: Tuple[str, Path],\n",
    "    include: Optional[List[str]] = None,   # OR logic\n",
    "    exclude: Optional[List[str]] = None,   # drop if any match\n",
    "    cmap: str = \"viridis\",\n",
    "    max_rows: int = 1500,\n",
    "    max_cols: int = 1500,\n",
    "    dpi: int = 200,\n",
    "    short_in: float = 3.0,\n",
    "    max_ratio: float = 5.0,\n",
    "    alpha: float = 0.85,\n",
    "    split_qkv: bool = True,               # <-- NEW\n",
    "):\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    saved = 0\n",
    "\n",
    "    for name, w in iter_weight_matrices(model):\n",
    "        # include/exclude filters\n",
    "        if include is not None and not any(s in name for s in include):\n",
    "            continue\n",
    "        if exclude is not None and any(s in name for s in exclude):\n",
    "            continue\n",
    "\n",
    "        # ---- Special case: split encoder self-attn packed QKV ----\n",
    "        # Typical names:\n",
    "        #   encoder.layers.0.self_attn.in_proj_weight\n",
    "        #   encoder.layers.1.self_attn.in_proj_weight\n",
    "        if split_qkv and name.endswith(\"self_attn.in_proj_weight\"):\n",
    "            d_model = w.shape[1]  # cols\n",
    "            Wq, Wk, Wv = split_in_proj_weight_qkv(w, d_model=d_model)\n",
    "\n",
    "            for tag, mat in [(\"Q\", Wq), (\"K\", Wk), (\"V\", Wv)]:\n",
    "                safe_name = name.replace(\"/\", \"_\") + f\"_{tag}\"\n",
    "                out_path = out_dir / f\"{safe_name}.svg\"\n",
    "                save_heatmap_svg_rasterized_downsampled(\n",
    "                    mat,\n",
    "                    out_path=out_path,\n",
    "                    title=f\"{name} [{tag}]\",\n",
    "                    cmap=cmap,\n",
    "                    short_in=short_in,\n",
    "                    max_ratio=max_ratio,\n",
    "                    alpha=alpha,\n",
    "                    dpi=dpi,\n",
    "                    # max_rows=max_rows,\n",
    "                    # max_cols=max_cols,\n",
    "                )\n",
    "                saved += 1\n",
    "\n",
    "            continue  # don't save the combined packed matrix unless you also want it\n",
    "        \n",
    "        else:\n",
    "            # ---- Default: save weight as-is ----\n",
    "            safe_name = name.replace(\"/\", \"_\")\n",
    "            out_path = out_dir / f\"{safe_name}.svg\"\n",
    "            save_heatmap_svg_rasterized_downsampled(\n",
    "                w,\n",
    "                out_path=out_path,\n",
    "                title=name,\n",
    "                cmap=cmap,\n",
    "                short_in=short_in,\n",
    "                max_ratio=max_ratio,\n",
    "                alpha=alpha,\n",
    "                dpi=dpi,\n",
    "                # max_rows=max_rows,\n",
    "                # max_cols=max_cols,\n",
    "            )\n",
    "        saved += 1\n",
    "\n",
    "    print(f\"Saved {saved} heatmaps to: {out_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e9d591",
   "metadata": {},
   "source": [
    "### Load the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da856b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = experiment_loader.ExperimentLoader(\n",
    "    experiment_dir = \"/gpfs/Labs/Uzun/DATA/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/experiments/\",\n",
    "    experiment_name=\"mESC_E7.5_rep1_hvg_filter_disp_0.5\",\n",
    "    model_num=1,\n",
    ")\n",
    "\n",
    "exp.load_trained_model(\"trained_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbff250",
   "metadata": {},
   "source": [
    "### Save the Heatmaps of the Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd39e693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 41 heatmaps to: dev/model_heatmaps_svg\n"
     ]
    }
   ],
   "source": [
    "save_model_weight_heatmaps(\n",
    "    exp.model,\n",
    "    \"./dev/model_heatmaps_svg\",\n",
    "    split_qkv=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9213e884",
   "metadata": {},
   "source": [
    "### Save Heatmaps of the Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4063e824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved input heatmaps to: dev/model_heatmaps_svg\n"
     ]
    }
   ],
   "source": [
    "save_input_heatmaps_from_batch(exp, \"./dev/model_heatmaps_svg\", batch_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae8a969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_heatmap_svg_rasterized_downsampled(\n",
    "    exp.model.tf_to_atac_cross_attn_pool.query,\n",
    "    \"./dev/model_heatmaps_svg/tf_to_atac_cross_attn_pool.query.svg\",\n",
    "    title=\"TF→ATAC Attention Pool Query\",\n",
    ")\n",
    "\n",
    "save_heatmap_svg_rasterized_downsampled(\n",
    "    exp.model.atac_to_tf_cross_attn_pool.query,\n",
    "    \"./dev/model_heatmaps_svg/atac_to_tf_cross_attn_pool.query.svg\",\n",
    "    title=\"ATAC→TF Attention Pool Query\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "54c17ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import math\n",
    "import torch\n",
    "\n",
    "batch = next(iter(exp.test_loader))\n",
    "atac_wins, tf_tensor, tg_expr_true, bias, tf_ids, tg_ids, motif_mask = batch\n",
    "device = next(exp.model.parameters()).device\n",
    "\n",
    "# move tensors you actually compute with\n",
    "atac_wins  = atac_wins.to(device)\n",
    "tf_tensor  = tf_tensor.to(device)\n",
    "tf_ids     = tf_ids.to(device)\n",
    "tg_ids     = tg_ids.to(device)\n",
    "bias       = None if bias is None else bias.to(device)\n",
    "motif_mask = None if motif_mask is None else motif_mask.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    # -------------------- ATAC dense input layer --------------------\n",
    "    atac_lin1        = exp.model.atac_acc_dense_input_layer[0](atac_wins)        # [B, W, d_ff]\n",
    "    atac_silu        = exp.model.atac_acc_dense_input_layer[1](atac_lin1)        # [B, W, d_ff]\n",
    "    atac_dropout     = exp.model.atac_acc_dense_input_layer[2](atac_silu)        # [B, W, d_ff]\n",
    "    atac_lin2        = exp.model.atac_acc_dense_input_layer[3](atac_dropout)     # [B, W, d_model]\n",
    "    atac_layer_norm  = exp.model.atac_acc_dense_input_layer[4](atac_lin2)        # [B, W, d_model]\n",
    "\n",
    "    win_emb = atac_layer_norm                                                   # [B, W, d_model]\n",
    "\n",
    "    # positional encoding + add\n",
    "    W = win_emb.shape[1]\n",
    "    pos = torch.arange(W, device=device, dtype=torch.float32)\n",
    "    pos_emb = exp.model.posenc(pos, bsz=win_emb.shape[0]).transpose(0, 1)        # [B, W, d_model]\n",
    "    win_emb_pos = win_emb + pos_emb                                             # [B, W, d_model]\n",
    "\n",
    "    # -------------------- ATAC Transformer encoder --------------------\n",
    "    window_encoder = exp.model.encoder(win_emb_pos)                               # [B, W, d_model]\n",
    "    # for consistency with forward(), after this point win_emb refers to encoded windows:\n",
    "    win_enc = window_encoder                                                     # [B, W, d_model]\n",
    "\n",
    "    # -------------------- TF embeddings --------------------\n",
    "    tf_id_emb = exp.model.tf_identity_emb(tf_ids)                                # [T, d_model]\n",
    "\n",
    "    # TF expr dense input layer (step-by-step)\n",
    "    tf_expr_in = tf_tensor.unsqueeze(-1)                                         # [B, T, 1]\n",
    "    tf_lin1    = exp.model.tf_expr_dense_input_layer[0](tf_expr_in)              # [B, T, d_ff]\n",
    "    tf_silu    = exp.model.tf_expr_dense_input_layer[1](tf_lin1)                 # [B, T, d_ff]\n",
    "    tf_dropout = exp.model.tf_expr_dense_input_layer[2](tf_silu)                 # [B, T, d_ff]\n",
    "    tf_lin2    = exp.model.tf_expr_dense_input_layer[3](tf_dropout)              # [B, T, d_model]\n",
    "    tf_ln      = exp.model.tf_expr_dense_input_layer[4](tf_lin2)                 # [B, T, d_model]\n",
    "    tf_expr_emb = tf_ln\n",
    "\n",
    "    # combined TF embedding used for cross-attn\n",
    "    tf_emb = tf_expr_emb + tf_id_emb.unsqueeze(0)                                # [B, T, d_model]\n",
    "\n",
    "    # -------------------- TF<->ATAC cross attention --------------------\n",
    "    # CrossAttention forward: out = norm(query + 0.1*dropout(attn(query, kv)))\n",
    "    tf_cross   = exp.model.cross_tf_to_atac(tf_emb,  win_enc)                    # [B, T, d_model]\n",
    "    atac_cross = exp.model.cross_atac_to_tf(win_enc, tf_emb)                     # [B, W, d_model]\n",
    "\n",
    "    # -------------------- Attention pooling --------------------\n",
    "    tf_repr,   tf_pool_weights   = exp.model.tf_to_atac_cross_attn_pool(tf_cross)     # [B, d_model], [B, T, 1]\n",
    "    atac_repr, atac_pool_weights = exp.model.atac_to_tf_cross_attn_pool(atac_cross)  # [B, d_model], [B, W, 1]\n",
    "\n",
    "    # -------------------- Pooled cross-attn dense layer --------------------\n",
    "    pooled_cat = torch.cat([tf_repr, atac_repr], dim=-1)                         # [B, 2*d_model]\n",
    "    pooled_lin1    = exp.model.pooled_cross_attn_dense_layer[0](pooled_cat)      # [B, d_ff]\n",
    "    pooled_gelu    = exp.model.pooled_cross_attn_dense_layer[1](pooled_lin1)     # [B, d_ff]\n",
    "    pooled_dropout = exp.model.pooled_cross_attn_dense_layer[2](pooled_gelu)     # [B, d_ff]\n",
    "    pooled_lin2    = exp.model.pooled_cross_attn_dense_layer[3](pooled_dropout)  # [B, d_model]\n",
    "    pooled_ln      = exp.model.pooled_cross_attn_dense_layer[4](pooled_lin2)     # [B, d_model]\n",
    "    tf_atac_cross_attn_output = pooled_ln                                        # [B, d_model]\n",
    "\n",
    "    # -------------------- TG query / identity embeddings --------------------\n",
    "    tg_query_emb = exp.model.tg_query_emb(tg_ids)                                # [G, d_model]\n",
    "    tg_base = tg_query_emb.unsqueeze(0).expand(win_enc.shape[0], -1, -1)         # [B, G, d_model]\n",
    "\n",
    "    tg_id_emb = exp.model.tg_identity_emb(tg_ids)                                # [G, d_model]\n",
    "\n",
    "    # -------------------- distance bias shaping (as in forward) --------------------\n",
    "    attn_bias = None\n",
    "    if exp.model.use_bias and (bias is not None):\n",
    "        attn_bias = bias\n",
    "        if attn_bias.dim() == 3:\n",
    "            attn_bias = attn_bias.unsqueeze(1)                                   # [B, 1, G, W]\n",
    "        if attn_bias.shape[1] == 1:\n",
    "            attn_bias = attn_bias.expand(win_enc.shape[0], exp.model.num_heads, tg_base.size(1), win_enc.size(1))\n",
    "        attn_bias = torch.nan_to_num(attn_bias, nan=0.0, posinf=1e4, neginf=-1e4)\n",
    "        attn_bias = (exp.model.bias_scale * attn_bias).clamp_(-20.0, 20.0)       # [B, H, G, W]\n",
    "\n",
    "    # -------------------- TG->ATAC cross attention --------------------\n",
    "    tg_cross = exp.model.cross_tg_to_atac(tg_base, win_enc, attn_bias=attn_bias) # [B, G, d_model]\n",
    "\n",
    "    # add pooled TF/ATAC summary to each TG (scaled)\n",
    "    n_tgs = tg_cross.size(1)\n",
    "    scale = 1.0 / math.sqrt(max(1, n_tgs))\n",
    "    tf_atac_expand = tf_atac_cross_attn_output.unsqueeze(1).expand(-1, n_tgs, -1) * scale  # [B, G, d_model]\n",
    "    tg_cross_attn_repr = tg_cross + tf_atac_expand                                # [B, G, d_model]\n",
    "\n",
    "    # -------------------- TG identity dot + gene_pred_dense --------------------\n",
    "    tg_similarity_to_attn_output = (tg_cross_attn_repr * tg_id_emb.unsqueeze(0)).sum(dim=-1)  # [B, G]\n",
    "\n",
    "    gene_lin1    = exp.model.gene_pred_dense[0](tg_cross_attn_repr)               # [B, G, d_ff]\n",
    "    gene_relu    = exp.model.gene_pred_dense[1](gene_lin1)                        # [B, G, d_ff]\n",
    "    gene_dropout = exp.model.gene_pred_dense[2](gene_relu)                        # [B, G, d_ff]\n",
    "    gene_lin2    = exp.model.gene_pred_dense[3](gene_dropout)                     # [B, G, 1]\n",
    "    gene_pred_term = gene_lin2.squeeze(-1)                                        # [B, G]\n",
    "\n",
    "    tg_pred_pre_shortcut = tg_similarity_to_attn_output + gene_pred_term          # [B, G]\n",
    "\n",
    "    # -------------------- Optional TF->TG shortcut --------------------\n",
    "    shortcut_out = None\n",
    "    shortcut_attn = None\n",
    "    tg_pred = tg_pred_pre_shortcut\n",
    "\n",
    "    if getattr(exp.model, \"use_shortcut\", False) and hasattr(exp.model, \"shortcut_layer\"):\n",
    "        # shortcut_layer expects: tg_emb [G,d], tf_id_emb [T,d], tf_expr [B,T], motif_mask [G,T]\n",
    "        # If your motif_mask is batched, slice batch 0; otherwise pass as-is.\n",
    "        mm_for_shortcut = None\n",
    "        if motif_mask is not None:\n",
    "            mm_for_shortcut = motif_mask[0] if motif_mask.dim() == 3 else motif_mask\n",
    "\n",
    "        shortcut_out, shortcut_attn = exp.model.shortcut_layer(\n",
    "            tg_id_emb, tf_id_emb, tf_tensor, motif_mask=mm_for_shortcut\n",
    "        )  # shortcut_out: [B,G], shortcut_attn: [G,T]\n",
    "        tg_pred = tg_pred + shortcut_out                                          # [B, G]\n",
    "\n",
    "\n",
    "# -------------------- model_dict (grouped outputs) --------------------\n",
    "model_dict = OrderedDict({\n",
    "    \"inputs\": [\n",
    "        (\"atac_windows\", atac_wins),\n",
    "        (\"tf_expr\", tf_tensor),\n",
    "        (\"tg_expr_true\", tg_expr_true),\n",
    "        (\"bias\", bias),\n",
    "        (\"tf_ids\", tf_ids),\n",
    "        (\"tg_ids\", tg_ids),\n",
    "        (\"motif_mask\", motif_mask),\n",
    "    ],\n",
    "\n",
    "    \"atac_dense_input_layer\": [\n",
    "        (\"lin1\", atac_lin1),\n",
    "        (\"silu\", atac_silu),\n",
    "        (\"dropout\", atac_dropout),\n",
    "        (\"lin2\", atac_lin2),\n",
    "        (\"layer_norm\", atac_layer_norm),\n",
    "        (\"pos_emb\", pos_emb),\n",
    "        (\"win_emb_pos\", win_emb_pos),\n",
    "    ],\n",
    "\n",
    "    \"window_encoder\": [\n",
    "        (\"output\", window_encoder),\n",
    "    ],\n",
    "\n",
    "    \"tf_id_emb\": [\n",
    "        (\"embedding\", tf_id_emb),\n",
    "    ],\n",
    "\n",
    "    \"tf_dense_input_layer\": [\n",
    "        (\"expr_in\", tf_expr_in),\n",
    "        (\"lin1\", tf_lin1),\n",
    "        (\"silu\", tf_silu),\n",
    "        (\"dropout\", tf_dropout),\n",
    "        (\"lin2\", tf_lin2),\n",
    "        (\"layer_norm\", tf_ln),\n",
    "    ],\n",
    "\n",
    "    \"tf_emb_combined\": [\n",
    "        (\"tf_expr_emb\", tf_expr_emb),\n",
    "        (\"tf_emb\", tf_emb),\n",
    "    ],\n",
    "\n",
    "    \"cross_tf_to_atac\": [\n",
    "        (\"tf_cross\", tf_cross),\n",
    "    ],\n",
    "\n",
    "    \"cross_atac_to_tf\": [\n",
    "        (\"atac_cross\", atac_cross),\n",
    "    ],\n",
    "\n",
    "    \"attention_pooling\": [\n",
    "        (\"tf_repr\", tf_repr),\n",
    "        (\"tf_pool_weights\", tf_pool_weights),\n",
    "        (\"atac_repr\", atac_repr),\n",
    "        (\"atac_pool_weights\", atac_pool_weights),\n",
    "    ],\n",
    "\n",
    "    \"pooled_cross_attn_dense_layer\": [\n",
    "        (\"cat_tf_atac\", pooled_cat),\n",
    "        (\"lin1\", pooled_lin1),\n",
    "        (\"gelu\", pooled_gelu),\n",
    "        (\"dropout\", pooled_dropout),\n",
    "        (\"lin2\", pooled_lin2),\n",
    "        (\"layer_norm\", pooled_ln),\n",
    "        (\"tf_atac_cross_attn_output\", tf_atac_cross_attn_output),\n",
    "    ],\n",
    "\n",
    "    \"tg_embeddings\": [\n",
    "        (\"tg_query_emb\", tg_query_emb),\n",
    "        (\"tg_base\", tg_base),\n",
    "        (\"tg_id_emb\", tg_id_emb),\n",
    "    ],\n",
    "\n",
    "    \"tg_to_atac_bias\": [\n",
    "        (\"attn_bias\", attn_bias),\n",
    "    ],\n",
    "\n",
    "    \"cross_tg_to_atac\": [\n",
    "        (\"tg_cross\", tg_cross),\n",
    "    ],\n",
    "\n",
    "    \"tg_cross_attn_fusion\": [\n",
    "        (\"tf_atac_expand\", tf_atac_expand),\n",
    "        (\"tg_cross_attn_repr\", tg_cross_attn_repr),\n",
    "    ],\n",
    "\n",
    "    \"tg_prediction_head\": [\n",
    "        (\"tg_similarity_to_attn_output\", tg_similarity_to_attn_output),\n",
    "        (\"gene_lin1\", gene_lin1),\n",
    "        (\"gene_relu\", gene_relu),\n",
    "        (\"gene_dropout\", gene_dropout),\n",
    "        (\"gene_lin2\", gene_lin2),\n",
    "        (\"gene_pred_term\", gene_pred_term),\n",
    "        (\"tg_pred_pre_shortcut\", tg_pred_pre_shortcut),\n",
    "        (\"tg_pred_final\", tg_pred),\n",
    "    ],\n",
    "\n",
    "    \"tf_tg_shortcut\": [\n",
    "        (\"shortcut_out\", shortcut_out),\n",
    "        (\"shortcut_attn\", shortcut_attn),\n",
    "    ],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5b61ae72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved grouped heatmaps to: dev/model_heatmaps_svg\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "\n",
    "def _slug(s: str) -> str:\n",
    "    s = s.strip().lower()\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \"_\", s)\n",
    "    return s.strip(\"_\")\n",
    "\n",
    "def _select_sample(x: torch.Tensor, batch_idx: int = 0):\n",
    "    \"\"\"\n",
    "    Make x plottable as 1D/2D:\n",
    "    - If x is [B, ...], take x[batch_idx]\n",
    "    - If x is >2D after that, flatten to 2D (keep first dim)\n",
    "    - If x is 1D, keep 1D (your heatmap fn will expand to (1,N))\n",
    "    \"\"\"\n",
    "    if isinstance(x, torch.Tensor) and x.ndim >= 3:\n",
    "        x = x[batch_idx]\n",
    "\n",
    "    # after slicing, flatten >2D to 2D\n",
    "    if isinstance(x, torch.Tensor) and x.ndim > 2:\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "    return x\n",
    "\n",
    "def save_grouped_heatmaps(\n",
    "    model_dict,\n",
    "    out_root: Tuple[str, Path],\n",
    "    batch_idx: int = 0,\n",
    "    dpi: int = 200,\n",
    "    cmap: str = \"viridis\",\n",
    "    skip_none: bool = True,\n",
    "):\n",
    "    out_root = Path(out_root)\n",
    "    out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # number of digits for folder numbering\n",
    "    n_parts = len(model_dict)\n",
    "    part_digits = max(2, len(str(n_parts - 1)))\n",
    "\n",
    "    for part_i, (part_name, items) in enumerate(model_dict.items()):\n",
    "\n",
    "        # ---- Numbered subdirectory ----\n",
    "        part_slug = _slug(part_name)\n",
    "        part_dir = out_root / f\"{part_i:0{part_digits}d}_{part_slug}\"\n",
    "        part_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # digits for files inside this part\n",
    "        n_items = len(items)\n",
    "        file_digits = max(2, len(str(n_items - 1)))\n",
    "\n",
    "        saved_i = 0\n",
    "        for item_name, tensor in items:\n",
    "\n",
    "            # ---- Skip None or non-tensors ----\n",
    "            if tensor is None:\n",
    "                if skip_none:\n",
    "                    continue\n",
    "                else:\n",
    "                    raise ValueError(f\"{part_name}/{item_name} is None\")\n",
    "\n",
    "            if not torch.is_tensor(tensor):\n",
    "                if skip_none:\n",
    "                    continue\n",
    "                else:\n",
    "                    raise TypeError(f\"{part_name}/{item_name} is not a tensor: {type(tensor)}\")\n",
    "\n",
    "            x = _select_sample(tensor, batch_idx=batch_idx)\n",
    "\n",
    "            # ---- Numbered file ----\n",
    "            fname = f\"{saved_i:0{file_digits}d}_{_slug(item_name)}.svg\"\n",
    "            out_path = part_dir / fname\n",
    "\n",
    "            # ---- Two-line title ----\n",
    "            title = f\"{part_name}\\n{item_name}\"\n",
    "\n",
    "            save_heatmap_svg_rasterized_downsampled(\n",
    "                x,\n",
    "                out_path,\n",
    "                title=title,\n",
    "                cmap=cmap,\n",
    "                dpi=dpi,\n",
    "            )\n",
    "\n",
    "            saved_i += 1\n",
    "\n",
    "    print(f\"Saved grouped heatmaps to: {out_root}\")\n",
    "\n",
    "\n",
    "\n",
    "save_grouped_heatmaps(\n",
    "    model_dict,\n",
    "    out_root=\"./dev/model_heatmaps_svg\",\n",
    "    batch_idx=0,\n",
    "    dpi=200,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "38c38303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote graph: ./dev/model_heatmaps_svg/model_flow.graphml\n",
      "Saved 41 heatmaps to: dev/model_heatmaps_svg/00_weights\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "import torch\n",
    "\n",
    "def _slug(s: str) -> str:\n",
    "    s = s.strip().replace(\" \", \"_\")\n",
    "    s = re.sub(r\"[^\\w\\-]+\", \"_\", s)\n",
    "    s = re.sub(r\"_+\", \"_\", s)\n",
    "    return s.strip(\"_\")\n",
    "\n",
    "def subdir_name(part_i: int, part_name: str, part_digits: int = 2) -> str:\n",
    "    return f\"{part_i:0{part_digits}d}_{_slug(part_name)}\"\n",
    "\n",
    "def file_name(item_i: int, item_name: str, file_digits: int = 2, ext: str = \".svg\") -> str:\n",
    "    return f\"{item_i:0{file_digits}d}_{_slug(item_name)}{ext}\"\n",
    "\n",
    "def data_node_path(out_root: Path, part_i: int, part_name: str, item_i: int, item_name: str) -> str:\n",
    "    sd = subdir_name(part_i, part_name)\n",
    "    fn = file_name(item_i, item_name)\n",
    "    return str((out_root / sd / fn).as_posix())\n",
    "\n",
    "def data_node_id(part_i: int, part_name: str, item_i: int, item_name: str) -> str:\n",
    "    # what you want to SEE in the graph\n",
    "    sd = subdir_name(part_i, part_name)\n",
    "    fn = file_name(item_i, item_name, ext=\"\")  # no .svg in label\n",
    "    return f\"{sd}/{fn}\"\n",
    "\n",
    "def weight_node_id(weights_subdir: str, param_name: str, tag: Optional[str] = None) -> str:\n",
    "    base = f\"{weights_subdir}/{param_name.replace('/', '_')}\"\n",
    "    return f\"{base}_{tag}\" if tag else base\n",
    "\n",
    "\n",
    "def weight_node_paths(out_root: Path, weights_subdir: str, param_name: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Returns list of svg paths for the given param, mirroring save_model_weight_heatmaps().\n",
    "    \"\"\"\n",
    "    base_dir = out_root / weights_subdir\n",
    "    base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if param_name.endswith(\"self_attn.in_proj_weight\"):\n",
    "        # split QKV\n",
    "        safe = param_name.replace(\"/\", \"_\")\n",
    "        return [\n",
    "            str((base_dir / f\"{safe}_Q.svg\").as_posix()),\n",
    "            str((base_dir / f\"{safe}_K.svg\").as_posix()),\n",
    "            str((base_dir / f\"{safe}_V.svg\").as_posix()),\n",
    "        ]\n",
    "    else:\n",
    "        safe = param_name.replace(\"/\", \"_\")\n",
    "        return [str((base_dir / f\"{safe}.svg\").as_posix())]\n",
    "\n",
    "def build_data_index(model_dict, out_root: Path) -> dict[tuple[str, str], dict]:\n",
    "    \"\"\"\n",
    "    Map (part_name, item_name) -> {\"id\": node_id, \"path\": svg_path}\n",
    "    \"\"\"\n",
    "    idx = {}\n",
    "    parts = list(model_dict.items())\n",
    "    part_digits = max(2, len(str(len(parts) - 1)))\n",
    "\n",
    "    for part_i, (part_name, items) in enumerate(parts):\n",
    "        file_digits = max(2, len(str(len(items) - 1)))\n",
    "\n",
    "        saved_i = 0\n",
    "        for item_name, tensor in items:\n",
    "            if tensor is None or (not torch.is_tensor(tensor)):\n",
    "                continue\n",
    "\n",
    "            sd = subdir_name(part_i, part_name, part_digits=part_digits)\n",
    "            fn = file_name(saved_i, item_name, file_digits=file_digits, ext=\".svg\")\n",
    "\n",
    "            node_id = f\"{sd}/{Path(fn).stem}\"                # << graph label\n",
    "            svg_path = str((out_root / sd / fn).as_posix())  # << actual file\n",
    "\n",
    "            idx[(part_name, item_name)] = {\"id\": node_id, \"path\": svg_path}\n",
    "            saved_i += 1\n",
    "\n",
    "    return idx\n",
    "\n",
    "\n",
    "\n",
    "def build_param_set(model: torch.nn.Module) -> set[str]:\n",
    "    return {name for name, _ in model.named_parameters()}\n",
    "\n",
    "\n",
    "def add_weight_nodes_for_param(G: nx.DiGraph, out_root: Path, weights_subdir: str, param_name: str):\n",
    "    base_dir = out_root / weights_subdir\n",
    "    safe = param_name.replace(\"/\", \"_\")\n",
    "\n",
    "    if param_name.endswith(\"self_attn.in_proj_weight\"):\n",
    "        for tag in [\"Q\", \"K\", \"V\"]:\n",
    "            node_id = weight_node_id(weights_subdir, param_name, tag=tag)\n",
    "            svg_path = str((base_dir / f\"{safe}_{tag}.svg\").as_posix())\n",
    "            if not G.has_node(node_id):\n",
    "                G.add_node(node_id, kind=\"weight\", param=param_name, path=svg_path, tag=tag)\n",
    "    else:\n",
    "        node_id = weight_node_id(weights_subdir, param_name, tag=None)\n",
    "        svg_path = str((base_dir / f\"{safe}.svg\").as_posix())\n",
    "        if not G.has_node(node_id):\n",
    "            G.add_node(node_id, kind=\"weight\", param=param_name, path=svg_path)\n",
    "\n",
    "\n",
    "\n",
    "def build_flow_graph(\n",
    "    model_dict,\n",
    "    model: torch.nn.Module,\n",
    "    out_root: Tuple[str, Path] = \"./dev/model_heatmaps_svg\",\n",
    "    weights_subdir: str = \"00_weights\",  # numbered so it sorts too\n",
    ") -> nx.DiGraph:\n",
    "    out_root = Path(out_root)\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # 1) add data nodes from model_dict\n",
    "    data_idx = build_data_index(model_dict, out_root)\n",
    "    for (part_name, item_name), meta in data_idx.items():\n",
    "        G.add_node(\n",
    "            meta[\"id\"],\n",
    "            kind=\"data\",\n",
    "            part=part_name,\n",
    "            item=item_name,\n",
    "            path=meta[\"path\"],\n",
    "        )\n",
    "\n",
    "    # 2) add weight nodes from model parameters (only when referenced)\n",
    "    param_names = build_param_set(model)\n",
    "\n",
    "    def link(data_src_key, param_name, data_dst_key):\n",
    "        if data_src_key not in data_idx or data_dst_key not in data_idx:\n",
    "            return\n",
    "        if param_name not in param_names:\n",
    "            return\n",
    "\n",
    "        src_id = data_idx[data_src_key][\"id\"]\n",
    "        dst_id = data_idx[data_dst_key][\"id\"]\n",
    "\n",
    "        # ensure data nodes exist (with path attr)\n",
    "        if not G.has_node(src_id):\n",
    "            G.add_node(src_id, kind=\"data\", **data_idx[data_src_key])\n",
    "        if not G.has_node(dst_id):\n",
    "            G.add_node(dst_id, kind=\"data\", **data_idx[data_dst_key])\n",
    "\n",
    "        add_weight_nodes_for_param(G, out_root, weights_subdir, param_name)\n",
    "\n",
    "        # connect through weight nodes\n",
    "        if param_name.endswith(\"self_attn.in_proj_weight\"):\n",
    "            for tag in [\"Q\", \"K\", \"V\"]:\n",
    "                w_id = weight_node_id(weights_subdir, param_name, tag=tag)\n",
    "                G.add_edge(src_id, w_id, kind=\"uses\")\n",
    "                G.add_edge(w_id, dst_id, kind=\"produces\")\n",
    "        else:\n",
    "            w_id = weight_node_id(weights_subdir, param_name, tag=None)\n",
    "            G.add_edge(src_id, w_id, kind=\"uses\")\n",
    "            G.add_edge(w_id, dst_id, kind=\"produces\")\n",
    "\n",
    "\n",
    "    # 3) Wiring spec: (src data) --param--> (dst data)\n",
    "\n",
    "    # ---- ATAC dense input layer ----\n",
    "    link((\"atac_dense_input_layer\", \"atac_windows\"), \"atac_acc_dense_input_layer.0.weight\", (\"atac_dense_input_layer\", \"lin1\"))\n",
    "    link((\"atac_dense_input_layer\", \"atac_windows\"), \"atac_acc_dense_input_layer.0.bias\",   (\"atac_dense_input_layer\", \"lin1\"))\n",
    "    link((\"atac_dense_input_layer\", \"lin1\"),        \"atac_acc_dense_input_layer.3.weight\", (\"atac_dense_input_layer\", \"lin2\"))\n",
    "    # LN has weight/bias\n",
    "    link((\"atac_dense_input_layer\", \"lin2\"),        \"atac_acc_dense_input_layer.4.weight\", (\"atac_dense_input_layer\", \"layer_norm\"))\n",
    "    link((\"atac_dense_input_layer\", \"lin2\"),        \"atac_acc_dense_input_layer.4.bias\",   (\"atac_dense_input_layer\", \"layer_norm\"))\n",
    "    # pos add is not a learned weight matrix here, but we can connect data->data directly:\n",
    "    if (\"atac_dense_input_layer\", \"layer_norm\") in data_idx and (\"atac_dense_input_layer\", \"win_emb_pos\") in data_idx:\n",
    "        src_id = data_idx[(\"atac_dense_input_layer\", \"layer_norm\")][\"id\"]\n",
    "        dst_id = data_idx[(\"atac_dense_input_layer\", \"win_emb_pos\")][\"id\"]\n",
    "        G.add_edge(src_id, dst_id, kind=\"add_posenc\")\n",
    "    # ---- Encoder layers (0-2) ----\n",
    "    for L in range(3):\n",
    "        # in_proj_weight splits into Q/K/V files\n",
    "        link((\"atac_dense_input_layer\", \"win_emb_pos\"),\n",
    "             f\"encoder.layers.{L}.self_attn.in_proj_weight\",\n",
    "             (\"window_encoder\", \"output\"))\n",
    "        link((\"atac_dense_input_layer\", \"win_emb_pos\"),\n",
    "             f\"encoder.layers.{L}.self_attn.out_proj.weight\",\n",
    "             (\"window_encoder\", \"output\"))\n",
    "        link((\"atac_dense_input_layer\", \"win_emb_pos\"),\n",
    "             f\"encoder.layers.{L}.linear1.weight\",\n",
    "             (\"window_encoder\", \"output\"))\n",
    "        link((\"atac_dense_input_layer\", \"win_emb_pos\"),\n",
    "             f\"encoder.layers.{L}.linear2.weight\",\n",
    "             (\"window_encoder\", \"output\"))\n",
    "\n",
    "    # ---- TF dense input layer ----\n",
    "    link((\"tf_dense_input_layer\", \"expr_in\"), \"tf_expr_dense_input_layer.0.weight\", (\"tf_dense_input_layer\", \"lin1\"))\n",
    "    link((\"tf_dense_input_layer\", \"expr_in\"), \"tf_expr_dense_input_layer.0.bias\",   (\"tf_dense_input_layer\", \"lin1\"))\n",
    "    link((\"tf_dense_input_layer\", \"lin2\"),    \"tf_expr_dense_input_layer.4.weight\", (\"tf_dense_input_layer\", \"layer_norm\"))\n",
    "    link((\"tf_dense_input_layer\", \"lin2\"),    \"tf_expr_dense_input_layer.4.bias\",   (\"tf_dense_input_layer\", \"layer_norm\"))\n",
    "\n",
    "    # ---- TF id embedding table (treated as weight) ----\n",
    "    # Connect ids -> embedding output via embedding weight\n",
    "    link((\"inputs\", \"tf_ids\"), \"tf_identity_emb.weight\", (\"tf_id_emb\", \"embedding\"))\n",
    "\n",
    "    # ---- Cross TF->ATAC (use Wq/Wk/Wv/Wo) ----\n",
    "    for p in [\"W_q.weight\",\"W_k.weight\",\"W_v.weight\",\"W_o.weight\"]:\n",
    "        link((\"tf_emb_combined\", \"tf_emb\"), f\"cross_tf_to_atac.attn.{p}\", (\"cross_tf_to_atac\", \"tf_cross\"))\n",
    "\n",
    "    # ---- Cross ATAC->TF ----\n",
    "    for p in [\"W_q.weight\",\"W_k.weight\",\"W_v.weight\",\"W_o.weight\"]:\n",
    "        link((\"window_encoder\", \"output\"), f\"cross_atac_to_tf.attn.{p}\", (\"cross_atac_to_tf\", \"atac_cross\"))\n",
    "\n",
    "    # ---- Attention pooling queries ----\n",
    "    link((\"cross_tf_to_atac\", \"tf_cross\"), \"tf_to_atac_cross_attn_pool.query\", (\"attention_pooling\", \"tf_repr\"))\n",
    "    link((\"cross_atac_to_tf\", \"atac_cross\"), \"atac_to_tf_cross_attn_pool.query\", (\"attention_pooling\", \"atac_repr\"))\n",
    "\n",
    "    # ---- Pooled dense ----\n",
    "    link((\"pooled_cross_attn_dense_layer\", \"cat_tf_atac\"), \"pooled_cross_attn_dense_layer.0.weight\", (\"pooled_cross_attn_dense_layer\", \"lin1\"))\n",
    "    link((\"pooled_cross_attn_dense_layer\", \"lin2\"),        \"pooled_cross_attn_dense_layer.4.weight\", (\"pooled_cross_attn_dense_layer\", \"layer_norm\"))\n",
    "    link((\"pooled_cross_attn_dense_layer\", \"lin2\"),        \"pooled_cross_attn_dense_layer.4.bias\",   (\"pooled_cross_attn_dense_layer\", \"layer_norm\"))\n",
    "\n",
    "    # ---- TG embeddings ----\n",
    "    link((\"inputs\", \"tg_ids\"), \"tg_query_emb.weight\",    (\"tg_embeddings\", \"tg_query_emb\"))\n",
    "    link((\"inputs\", \"tg_ids\"), \"tg_identity_emb.weight\", (\"tg_embeddings\", \"tg_id_emb\"))\n",
    "\n",
    "    # ---- Cross TG->ATAC ----\n",
    "    for p in [\"W_q.weight\",\"W_k.weight\",\"W_v.weight\",\"W_o.weight\"]:\n",
    "        link((\"tg_embeddings\", \"tg_base\"), f\"cross_tg_to_atac.attn.{p}\", (\"cross_tg_to_atac\", \"tg_cross\"))\n",
    "\n",
    "    # ---- Gene pred dense ----\n",
    "    link((\"tg_cross_attn_fusion\", \"tg_cross_attn_repr\"), \"gene_pred_dense.0.weight\", (\"tg_prediction_head\", \"gene_lin1\"))\n",
    "    link((\"tg_prediction_head\", \"gene_dropout\"),         \"gene_pred_dense.3.weight\", (\"tg_prediction_head\", \"gene_lin2\"))\n",
    "\n",
    "    return G\n",
    "\n",
    "G = build_flow_graph(model_dict, exp.model, out_root=\"./dev/model_heatmaps_svg\", weights_subdir=\"00_weights\")\n",
    "nx.write_graphml(G, \"./dev/model_heatmaps_svg/model_flow.graphml\")\n",
    "print(\"Wrote graph:\", \"./dev/model_heatmaps_svg/model_flow.graphml\")\n",
    "\n",
    "save_model_weight_heatmaps(\n",
    "    exp.model,\n",
    "    \"./dev/model_heatmaps_svg/00_weights\",\n",
    "    split_qkv=True,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
