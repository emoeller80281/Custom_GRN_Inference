{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c96203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import pytest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from pathlib import Path\n",
    "from anndata import AnnData\n",
    "import scanpy as sc\n",
    "\n",
    "from multiomic_transformer.pipeline.config import get_paths\n",
    "from multiomic_transformer.pipeline.io_utils import (\n",
    "    ensure_dir,\n",
    "    write_parquet_safe,\n",
    "    checkpoint_exists,\n",
    "    write_done_flag,\n",
    "    parquet_exists,\n",
    "    read_parquet_safely,\n",
    ")\n",
    "from multiomic_transformer.pipeline.qc_and_pseudobulk import filter_and_qc, pseudo_bulk, run_qc_and_pseudobulk\n",
    "from multiomic_transformer.pipeline.peak_gene_mapping import run_peak_gene_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd3525c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "from multiomic_transformer.pipeline.io_utils import (\n",
    "    ensure_dir,\n",
    "    write_parquet_safe,\n",
    "    checkpoint_exists,\n",
    "    write_done_flag,\n",
    "    StageTimer,\n",
    ")\n",
    "from multiomic_transformer.pipeline.config import get_paths\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Utility: compute correlations across pseudobulk samples\n",
    "# =====================================================================\n",
    "def compute_tf_tg_correlations(expr_df: pd.DataFrame, tfs: list[str], tgs: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute Pearson and Spearman correlations between TFs and TGs\n",
    "    across pseudobulk samples.\n",
    "\n",
    "    Args:\n",
    "        expr_df : DataFrame (genes × samples)\n",
    "        tfs : list of TF gene names present in expr_df.index\n",
    "        tgs : list of TG gene names present in expr_df.index\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame with columns:\n",
    "          [\"TF\", \"TG\", \"pearson_corr\", \"spearman_corr\"]\n",
    "    \"\"\"\n",
    "    tf_tg_corr = []\n",
    "    expr_df = expr_df.loc[expr_df.index.intersection(tfs + tgs)]\n",
    "\n",
    "    # Convert to float32 for efficiency\n",
    "    expr_mat = expr_df.astype(np.float32)\n",
    "\n",
    "    for tf in tfs:\n",
    "        if tf not in expr_mat.index:\n",
    "            continue\n",
    "        tf_values = expr_mat.loc[tf].values\n",
    "        for tg in tgs:\n",
    "            if tg not in expr_mat.index:\n",
    "                continue\n",
    "            tg_values = expr_mat.loc[tg].values\n",
    "            if np.all(tf_values == 0) or np.all(tg_values == 0):\n",
    "                pear, spear = np.nan, np.nan\n",
    "            else:\n",
    "                pear, _ = pearsonr(tf_values, tg_values)\n",
    "                spear, _ = spearmanr(tf_values, tg_values)\n",
    "            tf_tg_corr.append((tf, tg, pear, spear))\n",
    "\n",
    "    return pd.DataFrame(tf_tg_corr, columns=[\"TF\", \"TG\", \"pearson_corr\", \"spearman_corr\"])\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Main function: integrate features\n",
    "# =====================================================================\n",
    "def run_tf_tg_feature_construction(\n",
    "    pseudobulk_file: Path,\n",
    "    reg_potential_file: Path,\n",
    "    peak_gene_links_file: Path,\n",
    "    output_file: Path,\n",
    "    force: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Main entrypoint for Stage 3 TF–TG feature construction.\n",
    "    \"\"\"\n",
    "    if checkpoint_exists(output_file) and not force:\n",
    "        print(f\"[SKIP] {output_file} already exists.\")\n",
    "        return\n",
    "\n",
    "    with StageTimer(\"TF–TG Feature Construction\"):\n",
    "\n",
    "        # ---------------------------------------------------------------\n",
    "        # 1. Load inputs\n",
    "        # ---------------------------------------------------------------\n",
    "        print(f\"Loading pseudobulk expression: {pseudobulk_file}\")\n",
    "        expr_df = pd.read_parquet(pseudobulk_file)\n",
    "        if expr_df.shape[0] < expr_df.shape[1]:\n",
    "            # ensure genes × samples\n",
    "            print(\"Transposing pseudobulk expression to [genes × samples]\")\n",
    "            expr_df = expr_df.T\n",
    "\n",
    "        print(f\"Loading regulatory potential: {reg_potential_file}\")\n",
    "        tf_tg_reg = pd.read_parquet(reg_potential_file)\n",
    "\n",
    "        print(f\"Loading peak–gene links: {peak_gene_links_file}\")\n",
    "        peak_gene_links = pd.read_parquet(peak_gene_links_file)\n",
    "\n",
    "        # ---------------------------------------------------------------\n",
    "        # 2. Derive TF and TG sets\n",
    "        # ---------------------------------------------------------------\n",
    "        tfs = sorted(tf_tg_reg[\"TF\"].unique().tolist())\n",
    "        tgs = sorted(tf_tg_reg[\"TG\"].unique().tolist())\n",
    "        print(f\"Found {len(tfs)} TFs and {len(tgs)} TGs in regulatory potential file\")\n",
    "\n",
    "        # ---------------------------------------------------------------\n",
    "        # 3. Mean expression features (across pseudobulk samples)\n",
    "        # ---------------------------------------------------------------\n",
    "        common_tfs = [tf for tf in tfs if tf in expr_df.index]\n",
    "        common_tgs = [tg for tg in tgs if tg in expr_df.index]\n",
    "\n",
    "        mean_tf_expr = expr_df.loc[common_tfs].mean(axis=1).rename(\"mean_tf_expr\")\n",
    "        mean_tg_expr = expr_df.loc[common_tgs].mean(axis=1).rename(\"mean_tg_expr\")\n",
    "\n",
    "        mean_tf_expr = mean_tf_expr.reset_index().rename(columns={\"index\": \"TF\"})\n",
    "        mean_tg_expr = mean_tg_expr.reset_index().rename(columns={\"index\": \"TG\"})\n",
    "\n",
    "        # ---------------------------------------------------------------\n",
    "        # 4. Correlation features (across pseudobulk samples)\n",
    "        # ---------------------------------------------------------------\n",
    "        print(\"Computing TF–TG correlations across pseudobulk samples\")\n",
    "        corr_df = compute_tf_tg_correlations(expr_df, common_tfs, common_tgs)\n",
    "        print(f\"Correlation matrix computed for {len(corr_df):,} TF–TG pairs\")\n",
    "\n",
    "        # ---------------------------------------------------------------\n",
    "        # 5. Merge all feature sources\n",
    "        # ---------------------------------------------------------------\n",
    "        merged = tf_tg_reg.merge(mean_tf_expr, on=\"TF\", how=\"left\")\n",
    "        merged = merged.merge(mean_tg_expr, on=\"TG\", how=\"left\")\n",
    "        merged = merged.merge(corr_df, on=[\"TF\", \"TG\"], how=\"left\")\n",
    "\n",
    "        # Merge in distance-based features if available\n",
    "        if {\"peak_id\", \"TSS_dist\"}.issubset(peak_gene_links.columns):\n",
    "            # normalize TG naming\n",
    "            if \"TG\" not in peak_gene_links.columns and \"gene_id\" in peak_gene_links.columns:\n",
    "                peak_gene_links = peak_gene_links.rename(columns={\"gene_id\": \"TG\"})\n",
    "\n",
    "            dist_df = (\n",
    "                peak_gene_links[[\"peak_id\", \"TG\", \"TSS_dist\"]]\n",
    "                .groupby(\"TG\", as_index=False)\n",
    "                .agg(TSS_dist=(\"TSS_dist\", \"mean\"))\n",
    "            )\n",
    "            merged = merged.merge(dist_df, on=\"TG\", how=\"left\")\n",
    "            merged[\"neg_log_tss_dist\"] = -np.log1p(merged[\"TSS_dist\"].fillna(0))\n",
    "        else:\n",
    "            print(\"No TSS distance column found — skipping distance features.\")\n",
    "\n",
    "        # ---------------------------------------------------------------\n",
    "        # 6. Derived features\n",
    "        # ---------------------------------------------------------------\n",
    "        merged[\"expr_product\"] = merged[\"mean_tf_expr\"] * merged[\"mean_tg_expr\"]\n",
    "        merged[\"log_reg_pot\"] = np.log1p(merged.get(\"reg_potential\", 0))\n",
    "        merged[\"motif_present\"] = (merged.get(\"motif_density\", 0) > 0).astype(int)\n",
    "\n",
    "        # ---------------------------------------------------------------\n",
    "        # 7. Save output\n",
    "        # ---------------------------------------------------------------\n",
    "        if merged is None or merged.empty:\n",
    "            print(\"No TF–TG features generated; skipping Parquet write.\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            ensure_dir(output_file.parent)\n",
    "            write_parquet_safe(merged, output_file)\n",
    "            print(f\"[DONE] Stage 3 complete → {output_file} ({merged.shape[0]:,} rows)\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to write TF–TG features: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c37d7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pseudobulk expression: /gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/outputs/testing/pseudobulk_expr.parquet\n",
      "Loading regulatory potential: /gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/outputs/testing/tf_tg_regulatory_potential.parquet\n",
      "Loading peak–gene links: /gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/outputs/testing/peak_gene_links.parquet\n",
      "Found 2 TFs and 2 TGs in regulatory potential file\n",
      "Computing TF–TG correlations across pseudobulk samples\n",
      "Correlation matrix computed for 4 TF–TG pairs\n",
      "[DONE] Stage 3 complete → /gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/outputs/testing/tf_tg_features.parquet (4 rows)\n"
     ]
    }
   ],
   "source": [
    "def test_run_tf_tg_feature_construction(tmp_path):\n",
    "    \"\"\"\n",
    "    Validate Stage 3 TF–TG feature integration on synthetic data.\n",
    "\n",
    "    This test verifies:\n",
    "      • Correct merging of expression, regulatory potential, and distance data\n",
    "      • Creation of expected feature columns\n",
    "      • Proper .done checkpoint writing\n",
    "      • Correlation values within [-1, 1]\n",
    "      • No NaN or infinite values in key numerical fields\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------\n",
    "    # 1. Create minimal synthetic inputs (guaranteed TF–TG overlap)\n",
    "    # --------------------------------------------------------------\n",
    "    # Expression for both TFs and TGs (ensure non-constant variance)\n",
    "    expr_df = pd.DataFrame(\n",
    "        {\n",
    "            \"S1\": [0.1, 0.5, 0.3, 0.7],\n",
    "            \"S2\": [0.2, 0.6, 0.4, 0.8],\n",
    "            \"S3\": [0.3, 0.7, 0.5, 0.9],\n",
    "        },\n",
    "        index=[\"TF1\", \"TF2\", \"TG1\", \"TG2\"]\n",
    "    )\n",
    "    pseudobulk_file = tmp_path / \"pseudobulk_expr.parquet\"\n",
    "    expr_df.to_parquet(pseudobulk_file)\n",
    "\n",
    "\n",
    "    # Ensure TF/TG names overlap with expression index\n",
    "    tf_tg_reg = pd.DataFrame({\n",
    "        \"TF\": [\"TF1\", \"TF1\", \"TF2\", \"TF2\"],\n",
    "        \"TG\": [\"TG1\", \"TG2\", \"TG1\", \"TG2\"],   # matches expr_df.index\n",
    "        \"reg_potential\": [0.2, 0.5, 0.3, 0.1],\n",
    "        \"motif_density\": [3, 0, 5, 2],\n",
    "    })\n",
    "    reg_potential_file = tmp_path / \"tf_tg_regulatory_potential.parquet\"\n",
    "    tf_tg_reg.to_parquet(reg_potential_file)\n",
    "\n",
    "    peak_gene_links = pd.DataFrame({\n",
    "        \"peak_id\": [\"p1\", \"p2\", \"p3\", \"p4\"],\n",
    "        \"TG\": [\"TG1\", \"TG1\", \"TG2\", \"TG2\"],\n",
    "        \"TSS_dist\": [1000, 50000, 10000, 8000]\n",
    "    })\n",
    "    peak_gene_links_file = tmp_path / \"peak_gene_links.parquet\"\n",
    "    peak_gene_links.to_parquet(peak_gene_links_file)\n",
    "\n",
    "    output_file = tmp_path / \"tf_tg_features.parquet\"\n",
    "\n",
    "    # --------------------------------------------------------------\n",
    "    # 2. Run feature construction\n",
    "    # --------------------------------------------------------------\n",
    "    run_tf_tg_feature_construction(\n",
    "        pseudobulk_file=pseudobulk_file,\n",
    "        reg_potential_file=reg_potential_file,\n",
    "        peak_gene_links_file=peak_gene_links_file,\n",
    "        output_file=output_file,\n",
    "        force=True,\n",
    "    )\n",
    "\n",
    "tmp_path = Path(\"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/outputs/testing\")\n",
    "test_run_tf_tg_feature_construction(tmp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92497680",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.read_parquet(tmp_path / \"tf_tg_features.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
