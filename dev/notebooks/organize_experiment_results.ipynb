{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3507adf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing experiment: Initial Settings\n",
      "\n",
      "Processing experiment: large_neighborhood_count_filter\n",
      "\n",
      "Processing experiment: large_neighborhood\n",
      "\n",
      "Processing experiment: small_neighborhood\n",
      "\n",
      "Processing experiment: small_neighborhood_high_self_weight\n",
      "\n",
      "Processing experiment: slower_dist_decay\n",
      "\n",
      "Processing experiment: max_dist_bias\n",
      "\n",
      "Processing experiment: slow_decay_max_dist\n",
      "\n",
      "Processing experiment: filter_lowest_ten_pct\n",
      "\n",
      "Processing experiment: lower_peak_threshold\n",
      "\n",
      "Processing experiment: no_filter_to_nearest_gene\n",
      "\n",
      "Processing experiment: smaller_window_size\n",
      "\n",
      "Processing experiment: larger_window_size\n",
      "\n",
      "Processing experiment: lower_max_peak_dist\n",
      "\n",
      "Processing experiment: test_new_pipeline\n",
      "                            Experiment  num_tfs  num_windows  num_tgs  \\\n",
      "0                     Initial Settings      639        19727     6852   \n",
      "1      large_neighborhood_count_filter      396        33940     7297   \n",
      "2                   large_neighborhood      183         3174     2008   \n",
      "3                   small_neighborhood      625        37358     6852   \n",
      "4  small_neighborhood_high_self_weight      625        37358     6852   \n",
      "\n",
      "   unscaled_r2  scaled_r2  Gradient Attribution | Mean | AUROC  \\\n",
      "0     0.891642   0.738082                             0.532939   \n",
      "1     0.506693   0.259315                             0.527684   \n",
      "2     0.861252   0.850686                             0.474813   \n",
      "3     0.856216   0.590590                             0.529309   \n",
      "4     0.807781   0.493903                             0.503449   \n",
      "\n",
      "   Gradient Attribution | Mean | AUPRC  \\\n",
      "0                             0.530437   \n",
      "1                             0.528616   \n",
      "2                             0.511063   \n",
      "3                             0.528455   \n",
      "4                             0.519716   \n",
      "\n",
      "   Gradient Attribution | Mean | Per-TF AUROC  \\\n",
      "0                                    0.559440   \n",
      "1                                    0.555479   \n",
      "2                                    0.510617   \n",
      "3                                    0.559534   \n",
      "4                                    0.554433   \n",
      "\n",
      "   Gradient Attribution | Mean | Per-TF AUPRC  ...  \\\n",
      "0                                    0.564733  ...   \n",
      "1                                    0.555091  ...   \n",
      "2                                    0.525288  ...   \n",
      "3                                    0.565180  ...   \n",
      "4                                    0.563830  ...   \n",
      "\n",
      "   TF Knockout | RN114 | AUPRC  TF Knockout | RN114 | Per-TF AUPRC  \\\n",
      "0                     0.530609                            0.564567   \n",
      "1                     0.531406                            0.538003   \n",
      "2                     0.511956                            0.546204   \n",
      "3                     0.525119                            0.568520   \n",
      "4                     0.526098                            0.567162   \n",
      "\n",
      "   TF Knockout | RN115 | AUROC  TF Knockout | RN115 | Per-TF AUROC  \\\n",
      "0                     0.513193                            0.521233   \n",
      "1                     0.508470                            0.515691   \n",
      "2                     0.479439                            0.499117   \n",
      "3                     0.494207                            0.515304   \n",
      "4                     0.498937                            0.517331   \n",
      "\n",
      "   TF Knockout | RN115 | AUPRC  TF Knockout | RN115 | Per-TF AUPRC  \\\n",
      "0                     0.521609                            0.531399   \n",
      "1                     0.511289                            0.526034   \n",
      "2                     0.513868                            0.526016   \n",
      "3                     0.510533                            0.532648   \n",
      "4                     0.510453                            0.528130   \n",
      "\n",
      "   TF Knockout | RN116 | AUROC  TF Knockout | RN116 | Per-TF AUROC  \\\n",
      "0                     0.495819                            0.488241   \n",
      "1                     0.514246                            0.516103   \n",
      "2                     0.395269                            0.484709   \n",
      "3                     0.467490                            0.538295   \n",
      "4                     0.472423                            0.514372   \n",
      "\n",
      "   TF Knockout | RN116 | AUPRC  TF Knockout | RN116 | Per-TF AUPRC  \n",
      "0                     0.496978                            0.521792  \n",
      "1                     0.520572                            0.523413  \n",
      "2                     0.503294                            0.535923  \n",
      "3                     0.499747                            0.545193  \n",
      "4                     0.488189                            0.539313  \n",
      "\n",
      "[5 rows x 62 columns]\n",
      "Wrote: excel_chart_ready.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "experiment_dir = Path(\"/gpfs/Labs/Uzun/DATA/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/experiments\")\n",
    "training_data_cache_dir = Path(\"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/data/training_data_cache\")\n",
    "\n",
    "experiment_dict = {\n",
    "    \"Initial Settings\": experiment_dir / \"mESC_no_scale_linear\" / \"model_training_192_10k_metacells\",\n",
    "    \"large_neighborhood_count_filter\": experiment_dir / \"mESC_large_neighborhood_count_filter\" / \"chr19\" / \"model_training_001\",\n",
    "    \"large_neighborhood\": experiment_dir / \"mESC_large_neighborhood\" / \"chr19\" / \"model_training_001\",\n",
    "    \"small_neighborhood\": experiment_dir / \"mESC_small_neighborhood\" / \"chr19\" / \"model_training_001\",\n",
    "    \"small_neighborhood_high_self_weight\": experiment_dir / \"mESC_small_neighborhood_high_self_weight\" / \"chr19\" / \"model_training_001\",\n",
    "    \"slower_dist_decay\": experiment_dir / \"mESC_slower_dist_decay\" / \"chr19\" / \"model_training_001\",\n",
    "    \"max_dist_bias\": experiment_dir / \"mESC_max_dist_bias\" / \"chr19\" / \"model_training_002\",\n",
    "    \"slow_decay_max_dist\": experiment_dir / \"mESC_slow_decay_max_dist\" / \"chr19\" / \"model_training_001\",\n",
    "    \"filter_lowest_ten_pct\": experiment_dir / \"mESC_filter_lowest_ten_pct\" / \"chr19\" / \"model_training_003\",\n",
    "    \"lower_peak_threshold\": experiment_dir / \"mESC_lower_peak_threshold\" / \"chr19\" / \"model_training_001\",\n",
    "    \"no_filter_to_nearest_gene\": experiment_dir / \"mESC_no_filter_to_nearest_gene\" / \"chr19\" / \"model_training_001\",\n",
    "    \"smaller_window_size\": experiment_dir / \"mESC_smaller_window_size\" / \"chr19\" / \"model_training_001\",\n",
    "    \"larger_window_size\": experiment_dir / \"mESC_larger_window_size\" / \"chr19\" / \"model_training_001\",\n",
    "    \"lower_max_peak_dist\": experiment_dir / \"mESC_lower_max_peak_dist\" / \"chr19\" / \"model_training_001\",\n",
    "    # \"higher_max_peak_dist\": experiment_dir / \"mESC_higher_max_peak_dist\" / \"chr19\" / \"model_training_001\",\n",
    "    \"test_new_pipeline\": experiment_dir / \"mESC_test_new_pipeline\" / \"chr19\" / \"model_training_001\",\n",
    "    # \"slow_decay_filter_ten_pct\": experiment_dir / \"mESC_slow_decay_filter_ten_pct\" / \"chr19\" / \"model_training_001\"\n",
    "}\n",
    "\n",
    "experiment_training_data_dict = {\n",
    "    \"Initial Settings\": training_data_cache_dir / \"mESC_no_scale_linear\",\n",
    "    \"large_neighborhood_count_filter\": training_data_cache_dir / \"mESC_large_neighborhood_count_filter\",\n",
    "    \"large_neighborhood\": training_data_cache_dir / \"mESC_large_neighborhood\",\n",
    "    \"small_neighborhood\": training_data_cache_dir / \"mESC_small_neighborhood\",\n",
    "    \"small_neighborhood_high_self_weight\": training_data_cache_dir / \"mESC_small_neighborhood_high_self_weight\",\n",
    "    \"slower_dist_decay\": training_data_cache_dir / \"mESC_slower_dist_decay\",\n",
    "    \"max_dist_bias\": training_data_cache_dir / \"mESC_max_dist_bias\",\n",
    "    \"slow_decay_max_dist\": training_data_cache_dir / \"mESC_slow_decay_max_dist\",\n",
    "    \"filter_lowest_ten_pct\": training_data_cache_dir / \"mESC_filter_lowest_ten_pct\",\n",
    "    \"lower_peak_threshold\": training_data_cache_dir / \"mESC_lower_peak_threshold\",\n",
    "    \"no_filter_to_nearest_gene\": training_data_cache_dir / \"mESC_no_filter_to_nearest_gene\",\n",
    "    \"smaller_window_size\": training_data_cache_dir / \"mESC_smaller_window_size\",\n",
    "    \"larger_window_size\": training_data_cache_dir / \"mESC_larger_window_size\",\n",
    "    \"lower_max_peak_dist\": training_data_cache_dir / \"mESC_lower_max_peak_dist\",\n",
    "    # \"higher_max_peak_dist\": training_data_cache_dir / \"mESC_higher_max_peak_dist\",\n",
    "    \"test_new_pipeline\": training_data_cache_dir / \"mESC_test_new_pipeline\",\n",
    "    # \"slow_decay_filter_ten_pct\": training_data_cache_dir / \"mESC_slow_decay_filter_ten_pct\"\n",
    "}\n",
    "\n",
    "# Excel/Sheet ordering\n",
    "GT_ORDER = [\"ChIP-Atlas\", \"RN111\", \"RN112\", \"RN114\", \"RN115\", \"RN116\"]\n",
    "METHOD_ORDER = [\"Gradient Attribution\", \"TF Knockout\"]\n",
    "\n",
    "def compute_total_windows(cache_dir: Path) -> int:\n",
    "    total = 0\n",
    "    for d in cache_dir.iterdir():\n",
    "        if d.is_dir() and d.name.startswith(\"chr\"):\n",
    "            with open(cache_dir / d / f\"window_map_{d.name}.json\", \"r\") as f:\n",
    "                window_map = json.load(f)\n",
    "            total += len(window_map)\n",
    "    return total\n",
    "\n",
    "def format_block_columns(prefix: str, gt_order=GT_ORDER):\n",
    "    \"\"\"\n",
    "    Returns the column order for one method block exactly like your sheet:\n",
    "    Experiment | Mean AUROC/AUPRC | then each GT has AUROC, Per-TF AUROC, AUPRC, Per-TF AUPRC\n",
    "    \"\"\"\n",
    "    cols = [\n",
    "        (prefix, \"Mean\", \"AUROC\"),\n",
    "        (prefix, \"Mean\", \"AUPRC\"),\n",
    "        (prefix, \"Mean\", \"Per-TF AUROC\"),\n",
    "        (prefix, \"Mean\", \"Per-TF AUPRC\"),\n",
    "    ]\n",
    "    for gt in gt_order:\n",
    "        cols += [\n",
    "            (prefix, gt, \"AUROC\"),\n",
    "            (prefix, gt, \"Per-TF AUROC\"),\n",
    "            (prefix, gt, \"AUPRC\"),\n",
    "            (prefix, gt, \"Per-TF AUPRC\"),\n",
    "        ]\n",
    "    return cols\n",
    "\n",
    "all_experiments = []\n",
    "\n",
    "for experiment_name, EXPERIMENT_DIR in experiment_dict.items():\n",
    "    print(f\"\\nProcessing experiment: {experiment_name}\")\n",
    "\n",
    "    # --- dataset sizes ---\n",
    "    with open(EXPERIMENT_DIR / \"tf_vocab.json\", \"r\") as f:\n",
    "        num_tfs = len(json.load(f))\n",
    "    with open(EXPERIMENT_DIR / \"tg_vocab.json\", \"r\") as f:\n",
    "        num_tgs = len(json.load(f))\n",
    "\n",
    "    \n",
    "    total_windows = compute_total_windows(experiment_training_data_dict[experiment_name])\n",
    "\n",
    "    # --- final R2 ---\n",
    "    training_results = pd.read_csv(EXPERIMENT_DIR / \"training_log.csv\")\n",
    "    final_epoch_results = training_results.iloc[-1]\n",
    "    final_train_unscaled_r2 = float(final_epoch_results[\"R2_u\"])\n",
    "    final_train_scaled_r2   = float(final_epoch_results[\"R2_s\"])\n",
    "\n",
    "    # ============================================================\n",
    "    # UPDATED PART: pooled vs per-TF loaded separately\n",
    "    # ============================================================\n",
    "\n",
    "    # ---------- 1) POOLED overall mean AUROC/AUPRC ----------\n",
    "    pooled_overall = pd.read_csv(EXPERIMENT_DIR / \"method_ranking_by_auroc_pooled.csv\", header=0)\n",
    "    pooled_overall = pooled_overall.rename(columns={\"name\": \"method_name\"})\n",
    "    pooled_overall = pooled_overall[pooled_overall[\"method_name\"].isin(METHOD_ORDER)]\n",
    "    pooled_overall = pooled_overall.set_index(\"method_name\")[[\"mean_auroc\", \"mean_auprc\"]]\n",
    "\n",
    "    # ---------- 2) POOLED per-GT AUROC/AUPRC ----------\n",
    "    pooled_gt = pd.read_csv(EXPERIMENT_DIR / \"per_gt_method_aucs_pooled.csv\", header=0)\n",
    "    pooled_gt = pooled_gt.rename(columns={\"name\": \"method_name\"})\n",
    "    pooled_gt = pooled_gt[pooled_gt[\"method_name\"].isin(METHOD_ORDER)]\n",
    "    pooled_gt = pooled_gt[pooled_gt[\"gt_name\"].isin(GT_ORDER)]\n",
    "\n",
    "    pooled_gt_auroc = pooled_gt.pivot(index=\"method_name\", columns=\"gt_name\", values=\"auroc\")\n",
    "    pooled_gt_auprc = pooled_gt.pivot(index=\"method_name\", columns=\"gt_name\", values=\"auprc\")\n",
    "\n",
    "    # ---------- 3) PER-TF detailed -> mean across TFs ----------\n",
    "    per_tf = pd.read_csv(EXPERIMENT_DIR / \"per_tf_auroc_auprc_detailed.csv\", header=0)\n",
    "\n",
    "    # Standardize method column name\n",
    "    if \"method\" in per_tf.columns and \"method_name\" not in per_tf.columns:\n",
    "        per_tf = per_tf.rename(columns={\"method\": \"method_name\"})\n",
    "\n",
    "    per_tf = per_tf[per_tf[\"method_name\"].isin(METHOD_ORDER)].copy()\n",
    "    per_tf = per_tf[per_tf[\"gt_name\"].isin(GT_ORDER)].copy()\n",
    "\n",
    "    # Per-GT per-method: mean across TFs\n",
    "    per_tf_gt_means = (\n",
    "        per_tf.groupby([\"method_name\", \"gt_name\"], as_index=False)\n",
    "            .agg(\n",
    "                per_tf_auroc=(\"auroc\", \"mean\"),\n",
    "                per_tf_auprc=(\"auprc\", \"mean\"),\n",
    "                n_tfs=(\"tf\", \"nunique\"),\n",
    "            )\n",
    "    )\n",
    "\n",
    "    per_tf_auroc_lookup = per_tf_gt_means.set_index([\"method_name\", \"gt_name\"])[\"per_tf_auroc\"].to_dict()\n",
    "    per_tf_auprc_lookup = per_tf_gt_means.set_index([\"method_name\", \"gt_name\"])[\"per_tf_auprc\"].to_dict()\n",
    "\n",
    "    # Overall per-TF mean across GTs (left mean block \"Per-TF AUROC/AUPRC\")\n",
    "    per_tf_overall = (\n",
    "        per_tf_gt_means.groupby(\"method_name\", as_index=False)\n",
    "                    .agg(\n",
    "                        per_tf_mean_auroc=(\"per_tf_auroc\", \"mean\"),\n",
    "                        per_tf_mean_auprc=(\"per_tf_auprc\", \"mean\"),\n",
    "                    )\n",
    "                    .set_index(\"method_name\")\n",
    "    )\n",
    "\n",
    "    # ---------- 4) Build one row for this experiment ----------\n",
    "    row = {\n",
    "        (\"Meta\", \"\", \"Experiment\"): experiment_name,\n",
    "        (\"Meta\", \"\", \"num_tfs\"): num_tfs,\n",
    "        (\"Meta\", \"\", \"num_windows\"): total_windows,\n",
    "        (\"Meta\", \"\", \"num_tgs\"): num_tgs,\n",
    "        (\"Meta\", \"\", \"unscaled_r2\"): final_train_unscaled_r2,\n",
    "        (\"Meta\", \"\", \"scaled_r2\"): final_train_scaled_r2,\n",
    "    }\n",
    "\n",
    "    for method in METHOD_ORDER:\n",
    "        # ---- Mean block ----\n",
    "        # pooled mean AUROC/AUPRC\n",
    "        row[(method, \"Mean\", \"AUROC\")] = (\n",
    "            float(pooled_overall.loc[method, \"mean_auroc\"])\n",
    "            if method in pooled_overall.index else np.nan\n",
    "        )\n",
    "        row[(method, \"Mean\", \"AUPRC\")] = (\n",
    "            float(pooled_overall.loc[method, \"mean_auprc\"])\n",
    "            if method in pooled_overall.index else np.nan\n",
    "        )\n",
    "\n",
    "        # per-TF mean AUROC/AUPRC (mean across TFs, then mean across GTs)\n",
    "        row[(method, \"Mean\", \"Per-TF AUROC\")] = (\n",
    "            float(per_tf_overall.loc[method, \"per_tf_mean_auroc\"])\n",
    "            if method in per_tf_overall.index else np.nan\n",
    "        )\n",
    "        row[(method, \"Mean\", \"Per-TF AUPRC\")] = (\n",
    "            float(per_tf_overall.loc[method, \"per_tf_mean_auprc\"])\n",
    "            if method in per_tf_overall.index else np.nan\n",
    "        )\n",
    "\n",
    "        # ---- Per-GT blocks ----\n",
    "        for gt in GT_ORDER:\n",
    "            # pooled per-GT AUROC/AUPRC\n",
    "            row[(method, gt, \"AUROC\")] = (\n",
    "                float(pooled_gt_auroc.loc[method, gt])\n",
    "                if (method in pooled_gt_auroc.index and gt in pooled_gt_auroc.columns) else np.nan\n",
    "            )\n",
    "            row[(method, gt, \"AUPRC\")] = (\n",
    "                float(pooled_gt_auprc.loc[method, gt])\n",
    "                if (method in pooled_gt_auprc.index and gt in pooled_gt_auprc.columns) else np.nan\n",
    "            )\n",
    "\n",
    "            # per-TF per-GT means (mean across TFs)\n",
    "            row[(method, gt, \"Per-TF AUROC\")] = float(per_tf_auroc_lookup.get((method, gt), np.nan))\n",
    "            row[(method, gt, \"Per-TF AUPRC\")] = float(per_tf_auprc_lookup.get((method, gt), np.nan))\n",
    "\n",
    "    all_experiments.append(row)\n",
    "\n",
    "\n",
    "# Build final dataframe\n",
    "final_df = pd.DataFrame(all_experiments)\n",
    "\n",
    "# Order columns to match your sheet grouping\n",
    "meta_cols = [\n",
    "    (\"Meta\", \"\", \"Experiment\"),\n",
    "    (\"Meta\", \"\", \"num_tfs\"),\n",
    "    (\"Meta\", \"\", \"num_windows\"),\n",
    "    (\"Meta\", \"\", \"num_tgs\"),\n",
    "    (\"Meta\", \"\", \"unscaled_r2\"),\n",
    "    (\"Meta\", \"\", \"scaled_r2\"),\n",
    "]\n",
    "\n",
    "ordered_cols = meta_cols + format_block_columns(\"Gradient Attribution\") + format_block_columns(\"TF Knockout\")\n",
    "ordered_cols = [c for c in ordered_cols if c in final_df.columns]  # safety\n",
    "\n",
    "final_df = final_df[ordered_cols]\n",
    "\n",
    "# Flatten columns for easy Excel export\n",
    "def flat(c):\n",
    "    a, b, d = c\n",
    "    if a == \"Meta\":\n",
    "        return d\n",
    "    # e.g. \"Gradient Attribution | RN111 | Per-TF AUROC\"\n",
    "    return f\"{a} | {b} | {d}\"\n",
    "\n",
    "final_df.columns = [flat(c) for c in final_df.columns]\n",
    "\n",
    "print(final_df.head())\n",
    "\n",
    "# Export\n",
    "final_df.to_excel(\"dev/notebooks/excel_chart_ready.xlsx\", index=False)\n",
    "print(\"Wrote: excel_chart_ready.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
