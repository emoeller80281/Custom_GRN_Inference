{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATAC Data Loading & Alignment Pipeline\n",
    "\n",
    "This notebook shows how to load, combine, and align ATAC-seq window data.\n",
    "\n",
    "Handles:\n",
    "- Per-chromosome ATAC tensors and BED files\n",
    "- Combining across chromosomes\n",
    "- Aligning windows between training and holdout using nearest neighbor\n",
    "- Distance-based filtering to prevent misalignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions for ATAC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Solution 1 function defined\n"
     ]
    }
   ],
   "source": [
    "def load_bed_file(bed_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load a BED file with window coordinates.\n",
    "    \n",
    "    BED format (0-based, half-open):\n",
    "        chrom   start   end\n",
    "        chr1    1000    2000\n",
    "        chr1    2000    3000\n",
    "    \n",
    "    Computes window midpoint as standard position representation.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(bed_path, sep='\\t', header=None, \n",
    "                     names=['chrom', 'start', 'end'],\n",
    "                     usecols=[0, 1, 2])\n",
    "    \n",
    "    # Compute window midpoint\n",
    "    df['midpoint'] = (df['start'] + df['end']) / 2\n",
    "    \n",
    "    return df[['chrom', 'start', 'end', 'midpoint']]\n",
    "\n",
    "\n",
    "def load_chrom_atac_with_common_cells(\n",
    "    chrom_ids,\n",
    "    cache_path,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Load ATAC data for each chromosome separately.\n",
    "    Keep only common cells across all chromosomes.\n",
    "    \n",
    "    Returns per-chromosome tensors indexed by common cell IDs.\n",
    "    \"\"\"\n",
    "    print(f\"[Loading ATAC data - handling variable cells]\")\n",
    "    \n",
    "    chrom_tensors = {}\n",
    "    chrom_windows_list = {}\n",
    "    chrom_cell_counts = {}\n",
    "    \n",
    "    # Step 1: Load all data and track cell counts\n",
    "    print(f\"\\nStep 1: Load per-chromosome data\")\n",
    "    for chrom in chrom_ids:\n",
    "        chrom_path = os.path.join(cache_path, chrom)\n",
    "        \n",
    "        # Load tensor\n",
    "        tensor_file = os.path.join(chrom_path, f\"atac_window_tensor_all_{chrom}.pt\")\n",
    "        atac_tensor = torch.load(tensor_file)\n",
    "        n_cells, n_windows = atac_tensor.shape\n",
    "        \n",
    "        chrom_tensors[chrom] = atac_tensor\n",
    "        chrom_cell_counts[chrom] = n_cells\n",
    "        \n",
    "        # Load windows\n",
    "        bed_file = None\n",
    "        for pattern in [f\"{chrom}_windows_1kb.bed\", f\"windows_1kb.bed\", f\"{chrom}.bed\"]:\n",
    "            potential_file = os.path.join(chrom_path, pattern)\n",
    "            if os.path.exists(potential_file):\n",
    "                bed_file = potential_file\n",
    "                break\n",
    "        \n",
    "        if bed_file is None:\n",
    "            raise FileNotFoundError(f\"Could not find BED file for {chrom}\")\n",
    "        \n",
    "        windows_df = load_bed_file(bed_file)\n",
    "        windows_df['chrom_id'] = chrom\n",
    "        chrom_windows_list[chrom] = windows_df\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  {chrom}: {n_windows} windows, {n_cells} cells\")\n",
    "    \n",
    "    # Step 2: Find common cell count\n",
    "    print(f\"\\nStep 2: Cell count statistics\")\n",
    "    min_cells = min(chrom_cell_counts.values())\n",
    "    max_cells = max(chrom_cell_counts.values())\n",
    "    mean_cells = np.mean(list(chrom_cell_counts.values()))\n",
    "    \n",
    "    print(f\"  Min cells: {min_cells}\")\n",
    "    print(f\"  Max cells: {max_cells}\")\n",
    "    print(f\"  Mean cells: {mean_cells:.0f}\")\n",
    "    print(f\"  Total chromosomes: {len(chrom_ids)}\")\n",
    "    \n",
    "    print(f\"\\n  Using common cells: {min_cells}\")\n",
    "    print(f\"  This means:\")\n",
    "    print(f\"    - Keeping first {min_cells} cells from each chromosome\")\n",
    "    print(f\"    - Discarding up to {max_cells - min_cells} cells per chromosome\")\n",
    "    \n",
    "    # Step 3: Trim tensors to common cell count\n",
    "    print(f\"\\nStep 3: Trim tensors to common size\")\n",
    "    trimmed_tensors = {}\n",
    "    for chrom in chrom_ids:\n",
    "        trimmed_tensors[chrom] = chrom_tensors[chrom][:min_cells, :]\n",
    "    \n",
    "    # Step 4: Combine tensors\n",
    "    print(f\"\\nStep 4: Combine across chromosomes\")\n",
    "    combined_tensor = torch.cat(\n",
    "        [trimmed_tensors[chrom] for chrom in chrom_ids],\n",
    "        dim=1  # Concatenate along windows dimension\n",
    "    )\n",
    "    \n",
    "    # Step 5: Combine window coordinates\n",
    "    global_idx = 0\n",
    "    all_windows = []\n",
    "    for chrom in chrom_ids:\n",
    "        windows_df = chrom_windows_list[chrom].copy()\n",
    "        windows_df['global_idx'] = np.arange(global_idx, global_idx + len(windows_df))\n",
    "        all_windows.append(windows_df)\n",
    "        global_idx += len(windows_df)\n",
    "    \n",
    "    combined_windows = pd.concat(all_windows, ignore_index=True)\n",
    "    \n",
    "    print(f\"\\n[Combined ATAC data]\")\n",
    "    print(f\"  Cells: {combined_tensor.shape[0]}\")\n",
    "    print(f\"  Windows: {combined_tensor.shape[1]}\")\n",
    "    print(f\"  Total: {combined_tensor.shape[0] * combined_tensor.shape[1] / 1e9:.2f}B values\")\n",
    "    \n",
    "    return combined_tensor, combined_windows, chrom_cell_counts\n",
    "\n",
    "\n",
    "print(\"✓ Solution 1 function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Utility functions defined\n"
     ]
    }
   ],
   "source": [
    "def print_section(title, level=1):\n",
    "    \"\"\"Print a formatted section header.\"\"\"\n",
    "    if level == 1:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\"{title}\")\n",
    "        print(\"=\"*70)\n",
    "    else:\n",
    "        print(f\"\\n{title}\")\n",
    "        print(\"-\" * len(title))\n",
    "\n",
    "print(\"✓ Utility functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Training cache: data/training_data_cache/mESC_no_scale_linear\n",
      "Holdout cache: data/training_data_cache/mESC_holdout\n",
      "Chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# USER CONFIGURATION - MODIFY THESE PATHS\n",
    "# ============================================================================\n",
    "\n",
    "TRAINING_DATA_CACHE = Path(\"data/training_data_cache/mESC_no_scale_linear\")\n",
    "HOLDOUT_DATA_CACHE = Path(\"data/training_data_cache/mESC_holdout\")\n",
    "CHROM_IDS = [f\"chr{i}\" for i in range(1, 20)]\n",
    "\n",
    "# Evaluation settings\n",
    "CKPT_PATH = \"path/to/checkpoint.pt\"  # Update this\n",
    "SELECTED_EXPERIMENT_DIR = \"path/to/experiment\"  # Update this\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Training cache: {TRAINING_DATA_CACHE}\")\n",
    "print(f\"Holdout cache: {HOLDOUT_DATA_CACHE}\")\n",
    "print(f\"Chromosomes: {CHROM_IDS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Alignment functions defined\n"
     ]
    }
   ],
   "source": [
    "def align_atac_windows(\n",
    "    train_windows: pd.DataFrame,\n",
    "    holdout_windows: pd.DataFrame,\n",
    "    max_distance_bp: int = 5000,\n",
    "    verbose: bool = True\n",
    ") -> Tuple[np.ndarray, np.ndarray, Dict]:\n",
    "    \"\"\"\n",
    "    Align ATAC windows using nearest neighbor with distance threshold.\n",
    "    \n",
    "    For each holdout window:\n",
    "    1. Find nearest training window on same chromosome\n",
    "    2. Only align if within max_distance_bp\n",
    "    3. Track distances and unaligned windows\n",
    "    \n",
    "    Args:\n",
    "        train_windows: DataFrame with columns: chrom, midpoint, global_idx\n",
    "        holdout_windows: DataFrame with columns: chrom, midpoint, global_idx\n",
    "        max_distance_bp: Maximum distance for valid alignment (default: 5kb)\n",
    "        verbose: Print diagnostics\n",
    "        \n",
    "    Returns:\n",
    "        train_indices: Indices into training windows [n_aligned]\n",
    "        holdout_indices: Indices into holdout windows [n_aligned]\n",
    "        stats: Dictionary with alignment statistics\n",
    "    \"\"\"\n",
    "    print(f\"\\n[Aligning ATAC windows (max distance: {max_distance_bp} bp)]\")\n",
    "    \n",
    "    # Get overlapping chromosomes\n",
    "    train_chroms = set(train_windows['chrom'].unique())\n",
    "    holdout_chroms = set(holdout_windows['chrom'].unique())\n",
    "    common_chroms = sorted(train_chroms & holdout_chroms)\n",
    "    \n",
    "    if len(common_chroms) == 0:\n",
    "        raise ValueError(\"No overlapping chromosomes\")\n",
    "    \n",
    "    print(f\"  Found {len(common_chroms)} overlapping chromosomes: {common_chroms}\")\n",
    "    \n",
    "    train_indices = []\n",
    "    holdout_indices = []\n",
    "    all_distances = []\n",
    "    stats = {\n",
    "        'n_total_holdout': len(holdout_windows),\n",
    "        'n_aligned': 0,\n",
    "        'n_unaligned': 0,\n",
    "        'per_chrom': {}\n",
    "    }\n",
    "    \n",
    "    # Align per chromosome\n",
    "    for chrom in common_chroms:\n",
    "        train_chrom = train_windows[train_windows['chrom'] == chrom].copy()\n",
    "        holdout_chrom = holdout_windows[holdout_windows['chrom'] == chrom].copy()\n",
    "        \n",
    "        train_pos = train_chrom['midpoint'].values\n",
    "        holdout_pos = holdout_chrom['midpoint'].values\n",
    "        \n",
    "        train_global = train_chrom['global_idx'].values.astype(int)\n",
    "        holdout_global = holdout_chrom['global_idx'].values.astype(int)\n",
    "        \n",
    "        chrom_aligned = 0\n",
    "        chrom_unaligned = 0\n",
    "        chrom_distances = []\n",
    "        \n",
    "        # For each holdout window, find nearest training window\n",
    "        for h_idx, h_pos in enumerate(holdout_pos):\n",
    "            distances = np.abs(train_pos - h_pos)\n",
    "            nearest_idx = np.argmin(distances)\n",
    "            min_distance = distances[nearest_idx]\n",
    "            \n",
    "            # Check distance threshold\n",
    "            if min_distance > max_distance_bp:\n",
    "                chrom_unaligned += 1\n",
    "                continue\n",
    "            \n",
    "            # Record alignment\n",
    "            train_indices.append(train_global[nearest_idx])\n",
    "            holdout_indices.append(holdout_global[h_idx])\n",
    "            chrom_distances.append(min_distance)\n",
    "            chrom_aligned += 1\n",
    "        \n",
    "        # Update stats\n",
    "        stats['n_aligned'] += chrom_aligned\n",
    "        stats['n_unaligned'] += chrom_unaligned\n",
    "        stats['per_chrom'][chrom] = {\n",
    "            'n_total_holdout': len(holdout_chrom),\n",
    "            'n_aligned': chrom_aligned,\n",
    "            'n_unaligned': chrom_unaligned,\n",
    "            'mean_distance_bp': np.mean(chrom_distances) if chrom_distances else 0,\n",
    "        }\n",
    "        all_distances.extend(chrom_distances)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  {chrom}: {chrom_aligned} aligned, {chrom_unaligned} unaligned\")\n",
    "    \n",
    "    # Convert to arrays\n",
    "    train_indices = np.array(train_indices, dtype=np.int32)\n",
    "    holdout_indices = np.array(holdout_indices, dtype=np.int32)\n",
    "    stats['distances'] = np.array(all_distances)\n",
    "    \n",
    "    # Summary\n",
    "    if verbose:\n",
    "        print(f\"\\n[Alignment Summary]\")\n",
    "        print(f\"  Total holdout windows: {stats['n_total_holdout']}\")\n",
    "        print(f\"  Aligned: {stats['n_aligned']} ({stats['n_aligned']/stats['n_total_holdout']*100:.1f}%)\")\n",
    "        print(f\"  Unaligned: {stats['n_unaligned']}\")\n",
    "        if len(all_distances) > 0:\n",
    "            print(f\"  Distance: mean={np.mean(all_distances):.0f} bp, \"\n",
    "                  f\"median={np.median(all_distances):.0f} bp, \"\n",
    "                  f\"max={np.max(all_distances):.0f} bp\")\n",
    "    \n",
    "    return train_indices, holdout_indices, stats\n",
    "\n",
    "print(\"✓ Alignment functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Training ATAC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 1: LOAD TRAINING ATAC DATA\n",
      "======================================================================\n",
      "[Loading ATAC data - handling variable cells]\n",
      "\n",
      "Step 1: Load per-chromosome data\n",
      "  chr1: 50789 windows, 1179 cells\n",
      "  chr2: 50789 windows, 1598 cells\n",
      "  chr3: 50789 windows, 812 cells\n",
      "  chr4: 50789 windows, 1535 cells\n",
      "  chr5: 50789 windows, 1308 cells\n",
      "  chr6: 50789 windows, 1105 cells\n",
      "  chr7: 50789 windows, 1366 cells\n",
      "  chr8: 50789 windows, 919 cells\n",
      "  chr9: 50789 windows, 1158 cells\n",
      "  chr10: 50789 windows, 1060 cells\n",
      "  chr11: 50789 windows, 1727 cells\n",
      "  chr12: 50789 windows, 743 cells\n",
      "  chr13: 50789 windows, 694 cells\n",
      "  chr14: 50789 windows, 598 cells\n",
      "  chr15: 50789 windows, 911 cells\n",
      "  chr16: 50789 windows, 529 cells\n",
      "  chr17: 50789 windows, 865 cells\n",
      "  chr18: 50789 windows, 589 cells\n",
      "  chr19: 50789 windows, 834 cells\n",
      "\n",
      "Step 2: Cell count statistics\n",
      "  Min cells: 529\n",
      "  Max cells: 1727\n",
      "  Mean cells: 1028\n",
      "  Total chromosomes: 19\n",
      "\n",
      "  Using common cells: 529\n",
      "  This means:\n",
      "    - Keeping first 529 cells from each chromosome\n",
      "    - Discarding up to 1198 cells per chromosome\n",
      "\n",
      "Step 3: Trim tensors to common size\n",
      "\n",
      "Step 4: Combine across chromosomes\n",
      "\n",
      "[Combined ATAC data]\n",
      "  Cells: 529\n",
      "  Windows: 964991\n",
      "  Total: 0.51B values\n",
      "[Loading ATAC data - handling variable cells]\n",
      "\n",
      "Step 1: Load per-chromosome data\n",
      "  chr1: 3470 windows, 261 cells\n",
      "  chr2: 3470 windows, 331 cells\n",
      "  chr3: 3470 windows, 189 cells\n",
      "  chr4: 3470 windows, 273 cells\n",
      "  chr5: 3470 windows, 253 cells\n",
      "  chr6: 3470 windows, 239 cells\n",
      "  chr7: 3470 windows, 236 cells\n",
      "  chr8: 3470 windows, 199 cells\n",
      "  chr9: 3470 windows, 211 cells\n",
      "  chr10: 3470 windows, 172 cells\n",
      "  chr11: 3470 windows, 317 cells\n",
      "  chr12: 3470 windows, 155 cells\n",
      "  chr13: 3470 windows, 141 cells\n",
      "  chr14: 3470 windows, 123 cells\n",
      "  chr15: 3470 windows, 159 cells\n",
      "  chr16: 3470 windows, 101 cells\n",
      "  chr17: 3470 windows, 119 cells\n",
      "  chr18: 3470 windows, 148 cells\n",
      "  chr19: 3470 windows, 146 cells\n",
      "\n",
      "Step 2: Cell count statistics\n",
      "  Min cells: 101\n",
      "  Max cells: 331\n",
      "  Mean cells: 199\n",
      "  Total chromosomes: 19\n",
      "\n",
      "  Using common cells: 101\n",
      "  This means:\n",
      "    - Keeping first 101 cells from each chromosome\n",
      "    - Discarding up to 230 cells per chromosome\n",
      "\n",
      "Step 3: Trim tensors to common size\n",
      "\n",
      "Step 4: Combine across chromosomes\n",
      "\n",
      "[Combined ATAC data]\n",
      "  Cells: 101\n",
      "  Windows: 65930\n",
      "  Total: 0.01B values\n",
      "\n",
      "✓ Loaded training ATAC data\n",
      "  Tensor shape: torch.Size([529, 964991])\n",
      "  Windows shape: (2462755, 6)\n"
     ]
    }
   ],
   "source": [
    "print_section(\"STEP 1: LOAD TRAINING ATAC DATA\")\n",
    "\n",
    "train_atac_full, train_windows, cell_counts = load_chrom_atac_with_common_cells(\n",
    "    CHROM_IDS, str(TRAINING_DATA_CACHE)\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Loaded training ATAC data\")\n",
    "print(f\"  Tensor shape: {train_atac_full.shape}\")\n",
    "print(f\"  Windows shape: {train_windows.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Holdout ATAC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 2: LOAD HOLDOUT ATAC DATA\n",
      "======================================================================\n",
      "[Loading ATAC data - handling variable cells]\n",
      "\n",
      "Step 1: Load per-chromosome data\n",
      "  chr1: 3470 windows, 261 cells\n",
      "  chr2: 3470 windows, 331 cells\n",
      "  chr3: 3470 windows, 189 cells\n",
      "  chr4: 3470 windows, 273 cells\n",
      "  chr5: 3470 windows, 253 cells\n",
      "  chr6: 3470 windows, 239 cells\n",
      "  chr7: 3470 windows, 236 cells\n",
      "  chr8: 3470 windows, 199 cells\n",
      "  chr9: 3470 windows, 211 cells\n",
      "  chr10: 3470 windows, 172 cells\n",
      "  chr11: 3470 windows, 317 cells\n",
      "  chr12: 3470 windows, 155 cells\n",
      "  chr13: 3470 windows, 141 cells\n",
      "  chr14: 3470 windows, 123 cells\n",
      "  chr15: 3470 windows, 159 cells\n",
      "  chr16: 3470 windows, 101 cells\n",
      "  chr17: 3470 windows, 119 cells\n",
      "  chr18: 3470 windows, 148 cells\n",
      "  chr19: 3470 windows, 146 cells\n",
      "\n",
      "Step 2: Cell count statistics\n",
      "  Min cells: 101\n",
      "  Max cells: 331\n",
      "  Mean cells: 199\n",
      "  Total chromosomes: 19\n",
      "\n",
      "  Using common cells: 101\n",
      "  This means:\n",
      "    - Keeping first 101 cells from each chromosome\n",
      "    - Discarding up to 230 cells per chromosome\n",
      "\n",
      "Step 3: Trim tensors to common size\n",
      "\n",
      "Step 4: Combine across chromosomes\n",
      "\n",
      "[Combined ATAC data]\n",
      "  Cells: 101\n",
      "  Windows: 65930\n",
      "  Total: 0.01B values\n",
      "\n",
      "✓ Loaded holdout ATAC data\n",
      "  Tensor shape: torch.Size([101, 65930])\n",
      "  Windows shape: (2462755, 6)\n"
     ]
    }
   ],
   "source": [
    "print_section(\"STEP 2: LOAD HOLDOUT ATAC DATA\")\n",
    "\n",
    "holdout_atac_full, holdout_windows, holdout_cell_counts = load_chrom_atac_with_common_cells(\n",
    "    CHROM_IDS, str(HOLDOUT_DATA_CACHE)\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Loaded holdout ATAC data\")\n",
    "print(f\"  Tensor shape: {holdout_atac_full.shape}\")\n",
    "print(f\"  Windows shape: {holdout_windows.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Align Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 3: ALIGN ATAC WINDOWS\n",
      "======================================================================\n",
      "\n",
      "[Aligning ATAC windows (max distance: 5000 bp)]\n",
      "  Found 19 overlapping chromosomes: ['chr1', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9']\n",
      "  chr1: 195472 aligned, 0 unaligned\n",
      "  chr10: 130695 aligned, 0 unaligned\n",
      "  chr11: 122083 aligned, 0 unaligned\n",
      "  chr12: 120130 aligned, 0 unaligned\n",
      "  chr13: 120422 aligned, 0 unaligned\n",
      "  chr14: 124903 aligned, 0 unaligned\n",
      "  chr15: 104044 aligned, 0 unaligned\n",
      "  chr16: 98208 aligned, 0 unaligned\n",
      "  chr17: 94988 aligned, 0 unaligned\n",
      "  chr18: 90703 aligned, 0 unaligned\n",
      "  chr19: 61432 aligned, 0 unaligned\n",
      "  chr2: 182114 aligned, 0 unaligned\n",
      "  chr3: 160040 aligned, 0 unaligned\n",
      "  chr4: 156509 aligned, 0 unaligned\n",
      "  chr5: 151835 aligned, 0 unaligned\n",
      "  chr6: 149737 aligned, 0 unaligned\n",
      "  chr7: 145442 aligned, 0 unaligned\n",
      "  chr8: 129402 aligned, 0 unaligned\n",
      "  chr9: 124596 aligned, 0 unaligned\n",
      "\n",
      "[Alignment Summary]\n",
      "  Total holdout windows: 2462755\n",
      "  Aligned: 2462755 (100.0%)\n",
      "  Unaligned: 0\n",
      "  Distance: mean=0 bp, median=0 bp, max=0 bp\n",
      "\n",
      "✓ Alignment complete\n"
     ]
    }
   ],
   "source": [
    "print_section(\"STEP 3: ALIGN ATAC WINDOWS\")\n",
    "\n",
    "# Align with 5kb distance threshold\n",
    "# Adjust if needed - some workflows use 1kb, 2kb, or 10kb\n",
    "train_atac_idx, holdout_atac_idx, atac_alignment_stats = align_atac_windows(\n",
    "    train_windows,\n",
    "    holdout_windows,\n",
    "    max_distance_bp=5000,  # ← Modify this threshold if needed\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Alignment complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align ATAC Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aligned_atac_tensors(\n",
    "    train_atac_path: str,\n",
    "    holdout_atac_path: str,\n",
    "    train_indices: np.ndarray,\n",
    "    holdout_indices: np.ndarray,\n",
    "    batch_size: int = 100000\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Convert peak indices to window indices using window_map files,\n",
    "    then extract aligned windows from tensors.\n",
    "    \"\"\"\n",
    "    print(f\"\\n[Creating aligned tensors]\")\n",
    "    \n",
    "    import json\n",
    "    \n",
    "    # Load all window maps to convert peak IDs to window indices\n",
    "    def load_window_maps(base_path):\n",
    "        \"\"\"Load window_map_{chrom}.json files.\"\"\"\n",
    "        window_maps = {}\n",
    "        for chrom_num in range(1, 20):\n",
    "            chrom = f\"chr{chrom_num}\"\n",
    "            map_file = f\"{base_path}/{chrom}/window_map_{chrom}.json\"\n",
    "            if os.path.exists(map_file):\n",
    "                with open(map_file) as f:\n",
    "                    window_maps[chrom] = json.load(f)\n",
    "        return window_maps\n",
    "    \n",
    "    # Convert peak indices to window indices\n",
    "    def peak_indices_to_window_indices(peak_indices, window_maps):\n",
    "        \"\"\"Map global peak indices to window indices.\"\"\"\n",
    "        peak_id_to_window = {}\n",
    "        global_peak_idx = 0\n",
    "        \n",
    "        # Build mapping: global peak index → (chrom, window_idx)\n",
    "        for chrom_num in range(1, 20):\n",
    "            chrom = f\"chr{chrom_num}\"\n",
    "            if chrom in window_maps:\n",
    "                for peak_id, win_idx in window_maps[chrom].items():\n",
    "                    peak_id_to_window[global_peak_idx] = (chrom, win_idx)\n",
    "                    global_peak_idx += 1\n",
    "        \n",
    "        # Calculate correct chromosome offsets from actual window counts\n",
    "        chrom_offsets = {}\n",
    "        offset = 0\n",
    "        for chrom_num in range(1, 20):\n",
    "            chrom = f\"chr{chrom_num}\"\n",
    "            if chrom in window_maps:\n",
    "                chrom_offsets[chrom] = offset\n",
    "                max_win_idx = max(window_maps[chrom].values())\n",
    "                offset += max_win_idx + 1  # +1 because indices are 0-based\n",
    "        \n",
    "        window_indices = []\n",
    "        for pidx in peak_indices:\n",
    "            if pidx in peak_id_to_window:\n",
    "                chrom, win_idx = peak_id_to_window[pidx]\n",
    "                global_win_idx = chrom_offsets[chrom] + win_idx\n",
    "                window_indices.append(global_win_idx)\n",
    "        \n",
    "        return np.array(window_indices, dtype=np.int64)\n",
    "    \n",
    "    print(f\"  Loading window maps...\")\n",
    "    train_window_maps = load_window_maps(train_atac_path)\n",
    "    holdout_window_maps = load_window_maps(holdout_atac_path)\n",
    "    \n",
    "    print(f\"  Converting peak indices to window indices...\")\n",
    "    train_window_idx = peak_indices_to_window_indices(train_indices, train_window_maps)\n",
    "    holdout_window_idx = peak_indices_to_window_indices(holdout_indices, holdout_window_maps)\n",
    "    \n",
    "    print(f\"    Training: {len(train_window_idx)} peaks → windows\")\n",
    "    print(f\"    Holdout: {len(holdout_window_idx)} peaks → windows\")\n",
    "    \n",
    "    # Now load and index tensors\n",
    "    def load_full_atac(base_path):\n",
    "        chrom_tensors = []\n",
    "        min_cells = float('inf')\n",
    "        \n",
    "        for chrom_num in range(1, 20):\n",
    "            chrom = f\"chr{chrom_num}\"\n",
    "            pattern = f\"{base_path}/{chrom}/atac_window_tensor_all_{chrom}.pt\"\n",
    "            if os.path.exists(pattern):\n",
    "                tensor = torch.load(pattern)\n",
    "                min_cells = min(min_cells, tensor.shape[0])\n",
    "        \n",
    "        for chrom_num in range(1, 20):\n",
    "            chrom = f\"chr{chrom_num}\"\n",
    "            pattern = f\"{base_path}/{chrom}/atac_window_tensor_all_{chrom}.pt\"\n",
    "            if os.path.exists(pattern):\n",
    "                tensor = torch.load(pattern)\n",
    "                chrom_tensors.append(tensor[:min_cells, :])\n",
    "        \n",
    "        return torch.cat(chrom_tensors, dim=1)\n",
    "    \n",
    "    print(f\"  Loading training tensors...\")\n",
    "    train_atac_full = load_full_atac(train_atac_path)\n",
    "    print(f\"  Loading holdout tensors...\")\n",
    "    holdout_atac_full = load_full_atac(holdout_atac_path)\n",
    "    \n",
    "    print(f\"  train_atac: {train_atac_full.shape}\")\n",
    "    print(f\"  holdout_atac: {holdout_atac_full.shape}\")\n",
    "    \n",
    "    train_window_idx_tensor = torch.from_numpy(train_window_idx).long()\n",
    "    holdout_window_idx_tensor = torch.from_numpy(holdout_window_idx).long()\n",
    "    \n",
    "    def batch_index(tensor, indices, batch_size):\n",
    "        batches = []\n",
    "        for i in range(0, len(indices), batch_size):\n",
    "            batch_idx = indices[i:i+batch_size]\n",
    "            batches.append(tensor[:, batch_idx])\n",
    "        return torch.cat(batches, dim=1)\n",
    "    \n",
    "    train_aligned = batch_index(train_atac_full, train_window_idx_tensor, batch_size)\n",
    "    holdout_aligned = batch_index(holdout_atac_full, holdout_window_idx_tensor, batch_size)\n",
    "    \n",
    "    print(f\"  Training aligned: {train_aligned.shape}\")\n",
    "    print(f\"  Holdout aligned: {holdout_aligned.shape}\")\n",
    "    \n",
    "    return train_aligned, holdout_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Creating aligned tensors]\n",
      "  Loading window maps...\n",
      "  Converting peak indices to window indices...\n",
      "    Training: 19727 peaks → windows\n",
      "    Holdout: 3792 peaks → windows\n",
      "  Loading training tensors...\n",
      "  Loading holdout tensors...\n",
      "  train_atac: torch.Size([529, 964991])\n",
      "  holdout_atac: torch.Size([101, 65930])\n",
      "  Training aligned: torch.Size([529, 19727])\n",
      "  Holdout aligned: torch.Size([101, 3792])\n"
     ]
    }
   ],
   "source": [
    "train_atac_aligned, holdout_atac_aligned = create_aligned_atac_tensors(\n",
    "    TRAINING_DATA_CACHE,      # directory containing per-chromosome .pt files\n",
    "    HOLDOUT_DATA_CACHE,    # directory containing per-chromosome .pt files\n",
    "    train_atac_idx,\n",
    "    holdout_atac_idx\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_atac.shape: torch.Size([529, 964991])\n",
      "holdout_atac.shape: torch.Size([101, 65930])\n",
      "train_indices: min=0, max=2462754, len=2462755\n",
      "holdout_indices: min=0, max=2462754, len=2462755\n"
     ]
    }
   ],
   "source": [
    "def diagnose_atac_tensors(\n",
    "    train_atac: torch.Tensor,\n",
    "    holdout_atac: torch.Tensor,\n",
    "    train_indices: np.ndarray,\n",
    "    holdout_indices: np.ndarray\n",
    "):\n",
    "    \"\"\"\n",
    "    Diagnose tensor/index mismatch.\n",
    "    \"\"\"\n",
    "    print(f\"train_atac.shape: {train_atac.shape}\")\n",
    "    print(f\"holdout_atac.shape: {holdout_atac.shape}\")\n",
    "    print(f\"train_indices: min={train_indices.min()}, max={train_indices.max()}, len={len(train_indices)}\")\n",
    "    print(f\"holdout_indices: min={holdout_indices.min()}, max={holdout_indices.max()}, len={len(holdout_indices)}\")\n",
    "\n",
    "# Run this first\n",
    "diagnose_atac_tensors(train_atac_full, holdout_atac_full, train_atac_idx, holdout_atac_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Verify Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 5: VERIFY ALIGNMENT\n",
      "======================================================================\n",
      "\n",
      "[Alignment Quality Checks]\n",
      "\n",
      "1. Chromosome matching:\n",
      "   All aligned windows on same chromosome: True ✓\n",
      "\n",
      "2. Distance verification:\n",
      "   Mean distance:   0.0 bp\n",
      "   Median distance: 0.0 bp\n",
      "   Max distance:    0.0 bp\n",
      "   All within 5kb:  True ✓\n",
      "\n",
      "3. Data integrity:\n",
      "   Training windows aligned:  2462755\n",
      "   Holdout windows aligned:   2462755\n",
      "   Match: True ✓\n",
      "\n",
      "✓ All alignment checks passed!\n"
     ]
    }
   ],
   "source": [
    "print_section(\"STEP 5: VERIFY ALIGNMENT\")\n",
    "\n",
    "# Get positions of aligned windows\n",
    "train_pos = train_windows.iloc[train_atac_idx]['midpoint'].values\n",
    "holdout_pos = holdout_windows.iloc[holdout_atac_idx]['midpoint'].values\n",
    "train_chrom = train_windows.iloc[train_atac_idx]['chrom'].values\n",
    "holdout_chrom = holdout_windows.iloc[holdout_atac_idx]['chrom'].values\n",
    "\n",
    "# Verify alignment quality\n",
    "distances = np.abs(train_pos - holdout_pos)\n",
    "on_same_chrom = (train_chrom == holdout_chrom).all()\n",
    "all_within_threshold = (distances <= 5000).all()\n",
    "\n",
    "print(f\"\\n[Alignment Quality Checks]\")\n",
    "print(f\"\\n1. Chromosome matching:\")\n",
    "print(f\"   All aligned windows on same chromosome: {on_same_chrom} ✓\")\n",
    "\n",
    "print(f\"\\n2. Distance verification:\")\n",
    "print(f\"   Mean distance:   {np.mean(distances):.1f} bp\")\n",
    "print(f\"   Median distance: {np.median(distances):.1f} bp\")\n",
    "print(f\"   Max distance:    {np.max(distances):.1f} bp\")\n",
    "print(f\"   All within 5kb:  {all_within_threshold} ✓\")\n",
    "\n",
    "print(f\"\\n3. Data integrity:\")\n",
    "print(f\"   Training windows aligned:  {len(train_atac_idx)}\")\n",
    "print(f\"   Holdout windows aligned:   {len(holdout_atac_idx)}\")\n",
    "print(f\"   Match: {len(train_atac_idx) == len(holdout_atac_idx)} ✓\")\n",
    "\n",
    "print(f\"\\n✓ All alignment checks passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ATAC DATA SUMMARY\n",
      "======================================================================\n",
      "\n",
      "╔════════════════════════════════════════════════════════════════╗\n",
      "║              ATAC DATA LOADING COMPLETE                        ║\n",
      "╚════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "ORIGINAL DATA:\n",
      "  Training ATAC:   torch.Size([529, 964991])\n",
      "  Holdout ATAC:    torch.Size([101, 65930])\n",
      "\n",
      "ALIGNMENT RESULTS:\n",
      "  Alignment rate:  100.0%\n",
      "  Aligned windows: 2462755\n",
      "  Unaligned:       0\n",
      "\n",
      "ALIGNED DATA (READY TO USE):\n",
      "  Training ATAC aligned:  torch.Size([529, 19727])  [n_cells, n_windows]\n",
      "  Holdout ATAC aligned:   torch.Size([101, 3792])  [n_cells, n_windows]\n",
      "\n",
      "NEXT STEPS:\n",
      "  • Use train_atac_aligned and holdout_atac_aligned in your model\n",
      "  • All data is in memory - no file I/O needed\n",
      "  • Windows are aligned by genomic position (nearest neighbor, 5kb threshold)\n",
      "  • You can now use this alongside TG/TF data for joint analysis\n",
      "\n",
      "DISTANCE DISTRIBUTION OF ALIGNED WINDOWS:\n",
      "  Mean:   0.0 bp\n",
      "  Median: 0.0 bp\n",
      "  Std:    0.0 bp\n",
      "  Max:    0.0 bp\n",
      "\n",
      "✓ Ready for analysis!\n"
     ]
    }
   ],
   "source": [
    "print_section(\"ATAC DATA SUMMARY\")\n",
    "\n",
    "print(f\"\"\"\n",
    "╔════════════════════════════════════════════════════════════════╗\n",
    "║              ATAC DATA LOADING COMPLETE                        ║\n",
    "╚════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "ORIGINAL DATA:\n",
    "  Training ATAC:   {train_atac_full.shape}\n",
    "  Holdout ATAC:    {holdout_atac_full.shape}\n",
    "\n",
    "ALIGNMENT RESULTS:\n",
    "  Alignment rate:  {atac_alignment_stats['n_aligned'] / atac_alignment_stats['n_total_holdout'] * 100:.1f}%\n",
    "  Aligned windows: {atac_alignment_stats['n_aligned']}\n",
    "  Unaligned:       {atac_alignment_stats['n_unaligned']}\n",
    "\n",
    "ALIGNED DATA (READY TO USE):\n",
    "  Training ATAC aligned:  {train_atac_aligned.shape}  [n_cells, n_windows]\n",
    "  Holdout ATAC aligned:   {holdout_atac_aligned.shape}  [n_cells, n_windows]\n",
    "\n",
    "NEXT STEPS:\n",
    "  • Use train_atac_aligned and holdout_atac_aligned in your model\n",
    "  • All data is in memory - no file I/O needed\n",
    "  • Windows are aligned by genomic position (nearest neighbor, 5kb threshold)\n",
    "  • You can now use this alongside TG/TF data for joint analysis\n",
    "\n",
    "DISTANCE DISTRIBUTION OF ALIGNED WINDOWS:\n",
    "  Mean:   {np.mean(atac_alignment_stats['distances']):.1f} bp\n",
    "  Median: {np.median(atac_alignment_stats['distances']):.1f} bp\n",
    "  Std:    {np.std(atac_alignment_stats['distances']):.1f} bp\n",
    "  Max:    {np.max(atac_alignment_stats['distances']):.1f} bp\n",
    "\"\"\")\n",
    "\n",
    "print(\"✓ Ready for analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling to Align Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "def scale_aligned_atac_tensors(\n",
    "    train_atac_aligned: torch.Tensor,\n",
    "    holdout_atac_aligned: torch.Tensor\n",
    ") -> Tuple[torch.Tensor, dict]:\n",
    "    \"\"\"\n",
    "    Scale holdout ATAC to match training global distribution.\n",
    "    Handles mismatched window counts.\n",
    "    \"\"\"\n",
    "    print(f\"\\n[Scaling aligned tensors]\")\n",
    "    \n",
    "    train_np = train_atac_aligned.cpu().numpy().astype(np.float64)\n",
    "    holdout_np = holdout_atac_aligned.cpu().numpy().astype(np.float64)\n",
    "    \n",
    "    print(f\"  Training: {train_np.shape}, Holdout: {holdout_np.shape}\")\n",
    "    \n",
    "    # Before scaling\n",
    "    print(f\"\\n  Before scaling:\")\n",
    "    train_mean_before = np.nanmean(train_np)\n",
    "    train_std_before = np.nanstd(train_np)\n",
    "    holdout_mean_before = np.nanmean(holdout_np)\n",
    "    holdout_std_before = np.nanstd(holdout_np)\n",
    "    \n",
    "    print(f\"    Training: mean={train_mean_before:.6f}, std={train_std_before:.6f}\")\n",
    "    print(f\"    Holdout:  mean={holdout_mean_before:.6f}, std={holdout_std_before:.6f}\")\n",
    "    ks_before = stats.ks_2samp(train_np.flatten(), holdout_np.flatten())[1]\n",
    "    print(f\"    KS test: {ks_before:.2e}\")\n",
    "    \n",
    "    # Scale holdout to match training mean and std\n",
    "    holdout_scaled = (holdout_np - holdout_mean_before) / (holdout_std_before + 1e-8)\n",
    "    holdout_scaled = holdout_scaled * train_std_before + train_mean_before\n",
    "    \n",
    "    # After scaling\n",
    "    print(f\"\\n  After scaling:\")\n",
    "    holdout_mean_after = np.nanmean(holdout_scaled)\n",
    "    holdout_std_after = np.nanstd(holdout_scaled)\n",
    "    \n",
    "    print(f\"    Training: mean={train_mean_before:.6f}, std={train_std_before:.6f}\")\n",
    "    print(f\"    Holdout:  mean={holdout_mean_after:.6f}, std={holdout_std_after:.6f}\")\n",
    "    ks_after = stats.ks_2samp(train_np.flatten(), holdout_scaled.flatten())[1]\n",
    "    print(f\"    KS test: {ks_after:.2e}\")\n",
    "    \n",
    "    holdout_scaled_tensor = torch.from_numpy(holdout_scaled).float()\n",
    "    \n",
    "    stats_dict = {\n",
    "        \"train_mean\": train_mean_before,\n",
    "        \"train_std\": train_std_before,\n",
    "        \"holdout_mean_before\": holdout_mean_before,\n",
    "        \"holdout_std_before\": holdout_std_before,\n",
    "        \"holdout_mean_after\": holdout_mean_after,\n",
    "        \"holdout_std_after\": holdout_std_after,\n",
    "        \"ks_before\": ks_before,\n",
    "        \"ks_after\": ks_after,\n",
    "    }\n",
    "    \n",
    "    return holdout_scaled_tensor, stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Scaling aligned tensors]\n",
      "  Training: (529, 19727), Holdout: (101, 3792)\n",
      "\n",
      "  Before scaling:\n",
      "    Training: mean=0.032189, std=0.096603\n",
      "    Holdout:  mean=0.132038, std=0.245231\n",
      "    KS test: 0.00e+00\n",
      "\n",
      "  After scaling:\n",
      "    Training: mean=0.032189, std=0.096603\n",
      "    Holdout:  mean=0.032189, std=0.096603\n",
      "    KS test: 0.00e+00\n"
     ]
    }
   ],
   "source": [
    "stats_dict = scale_aligned_atac_tensors(\n",
    "    train_atac_aligned,\n",
    "    holdout_atac_aligned\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
