{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4254f5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, json, os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "PROJECT_DIR = \"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER\"\n",
    "SRC_DIR = str(Path(PROJECT_DIR) / \"src\")\n",
    "if SRC_DIR not in sys.path:\n",
    "    sys.path.insert(0, SRC_DIR)\n",
    "\n",
    "import multiomic_transformer.utils.experiment_loader as experiment_loader\n",
    "import multiomic_transformer.datasets.dataset_refactor as dataset_refactor\n",
    "import multiomic_transformer.models.model as model_module\n",
    "\n",
    "GROUND_TRUTH_DIR = Path(\"data/ground_truth_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c3164672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'multiomic_transformer.utils.experiment_loader' from '/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/src/multiomic_transformer/utils/experiment_loader.py'>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://psh01com1hdns08:8885/'. Verify the server is running and reachable. (Failed to connect to the remote Jupyter Server 'http://psh01com1hdns08:8885/'. Verify the server is running and reachable. (request to http://psh01com1hdns08:8885/api/kernels?1771602813203 failed, reason: connect ECONNREFUSED 10.90.29.221:8885).)."
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(experiment_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593dc875",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18755ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_grad_attrib_grn(grad_attr_np, tf_names, tg_names):\n",
    "    score = np.nan_to_num(grad_attr_np, nan=0.0)\n",
    "    score_abs = np.abs(score)\n",
    "    \n",
    "    median_val = np.median(score_abs, axis=1, keepdims=True)\n",
    "    mad = np.median(np.abs(score_abs - median_val), axis=1, keepdims=True) + 1e-6\n",
    "    score = (score_abs - median_val) / mad\n",
    "    \n",
    "    T, G = score_abs.shape\n",
    "    tf_idx, tg_idx = np.meshgrid(np.arange(T), np.arange(G), indexing=\"ij\")\n",
    "    \n",
    "    tf_idx = tf_idx.ravel()\n",
    "    tg_idx = tg_idx.ravel()\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"Source\": np.asarray(tf_names, dtype=object)[tf_idx],\n",
    "        \"Target\": np.asarray(tg_names, dtype=object)[tg_idx],\n",
    "        \"Score\": score.ravel(),\n",
    "    })\n",
    "    \n",
    "    df[\"Source\"] = df[\"Source\"].astype(str).str.upper()\n",
    "    df[\"Target\"] = df[\"Target\"].astype(str).str.upper()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def format_tf_ko_grn(tf_ko_np, tf_names, tg_names):\n",
    "    score = np.nan_to_num(tf_ko_np, nan=0.0)\n",
    "    score = np.maximum(score, 0.0) # Keep only activation-like effects; set inhibition-like effects to 0\n",
    "    score_abs = np.abs(score)\n",
    "    \n",
    "    median_val = np.median(score_abs, axis=1, keepdims=True)\n",
    "    mad = np.median(np.abs(score_abs - median_val), axis=1, keepdims=True) + 1e-6\n",
    "    score = (score_abs - median_val) / mad\n",
    "    \n",
    "    T, G = score.shape\n",
    "    tf_idx, tg_idx = np.meshgrid(np.arange(T), np.arange(G), indexing=\"ij\")\n",
    "    \n",
    "    tf_idx = tf_idx.ravel()\n",
    "    tg_idx = tg_idx.ravel()\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"Source\": np.asarray(tf_names, dtype=object)[tf_idx],\n",
    "        \"Target\": np.asarray(tg_names, dtype=object)[tg_idx],\n",
    "        \"Score\": score.ravel(),\n",
    "    })\n",
    "    \n",
    "    df[\"Source\"] = df[\"Source\"].astype(str).str.upper()\n",
    "    df[\"Target\"] = df[\"Target\"].astype(str).str.upper()\n",
    "    \n",
    "    return df\n",
    "            \n",
    "def find_n_evenly_spaced_checkpoints(exp, n=10):\n",
    "    checkpoints = sorted([file.name for file in exp.model_training_dir.iterdir() if file.name.startswith(\"checkpoint_\")], key=lambda x: int(x.split(\"_\")[1].split(\".\")[0]))\n",
    "    checkpoint_nums = [int(name.split(\"_\")[1].split(\".\")[0]) for name in checkpoints]\n",
    "\n",
    "    max_checkpoint = checkpoint_nums[-1]\n",
    "\n",
    "    # Process n checkpoints, evenly spaced across the range of available checkpoints\n",
    "    num_to_process = min(n, len(checkpoint_nums))\n",
    "    checkpoints_to_process = np.linspace(0, max_checkpoint, num=num_to_process, dtype=int)\n",
    "    \n",
    "    # Round to the nearest available checkpoint number\n",
    "    checkpoints_to_process = [min(checkpoint_nums, key=lambda x: abs(x - num)) for num in checkpoints_to_process]\n",
    "    checkpoints_to_process = sorted(set(checkpoints_to_process))\n",
    "    \n",
    "    print(f\"Checkpoint Numbers to process: {checkpoints_to_process}\")\n",
    "    \n",
    "    checkpoint_files = [f\"checkpoint_{num}.pt\" for num in checkpoints_to_process]\n",
    "    \n",
    "    return checkpoint_files, checkpoints_to_process\n",
    "\n",
    "def load_ground_truth(ground_truth_file):\n",
    "    if type(ground_truth_file) == str:\n",
    "        ground_truth_file = Path(ground_truth_file)\n",
    "        \n",
    "    if ground_truth_file.suffix == \".csv\":\n",
    "        sep = \",\"\n",
    "    elif ground_truth_file.suffix == \".tsv\":\n",
    "        sep=\"\\t\"\n",
    "        \n",
    "    ground_truth_df = pd.read_csv(ground_truth_file, sep=sep, on_bad_lines=\"skip\", engine=\"python\")\n",
    "    \n",
    "    if \"chip\" in ground_truth_file.name and \"atlas\" in ground_truth_file.name:\n",
    "        ground_truth_df = ground_truth_df[[\"source_id\", \"target_id\"]]\n",
    "\n",
    "    if ground_truth_df.columns[0] != \"Source\" or ground_truth_df.columns[1] != \"Target\":\n",
    "        ground_truth_df = ground_truth_df.rename(columns={ground_truth_df.columns[0]: \"Source\", ground_truth_df.columns[1]: \"Target\"})\n",
    "    ground_truth_df[\"Source\"] = ground_truth_df[\"Source\"].astype(str).str.upper()\n",
    "    ground_truth_df[\"Target\"] = ground_truth_df[\"Target\"].astype(str).str.upper()\n",
    "    \n",
    "    # Build TF, TG, and edge sets for quick lookup later\n",
    "    gt = ground_truth_df[[\"Source\", \"Target\"]].dropna()\n",
    "\n",
    "    gt_tfs = set(gt[\"Source\"].unique())\n",
    "    gt_tgs = set(gt[\"Target\"].unique())\n",
    "    \n",
    "    gt_pairs = (gt[\"Source\"] + \"\\t\" + gt[\"Target\"]).drop_duplicates()\n",
    "    \n",
    "    gt_lookup = (gt_tfs, gt_tgs, set(gt_pairs))\n",
    "        \n",
    "    return ground_truth_df, gt_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958e3f56",
   "metadata": {},
   "source": [
    "## Load GT Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cde9073",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_by_dataset_dict = {\n",
    "    \"Macrophage\": {\n",
    "        \"RN204\": load_ground_truth(GROUND_TRUTH_DIR / \"rn204_macrophage_human_chipseq.tsv\"),\n",
    "        \"ChIP-Atlas macrophage\": load_ground_truth(GROUND_TRUTH_DIR / \"chipatlas_macrophage.csv\"),\n",
    "    },\n",
    "    \"mESC\": {\n",
    "        \"ChIP-Atlas mESC\": load_ground_truth(GROUND_TRUTH_DIR / \"chip_atlas_tf_peak_tg_dist.csv\"),\n",
    "        \"RN111\": load_ground_truth(GROUND_TRUTH_DIR / \"RN111.tsv\"),\n",
    "        \"RN112\": load_ground_truth(GROUND_TRUTH_DIR / \"RN112.tsv\"),\n",
    "        \"RN114\": load_ground_truth(GROUND_TRUTH_DIR / \"RN114.tsv\"),\n",
    "        \"RN116\": load_ground_truth(GROUND_TRUTH_DIR / \"RN116.tsv\"),        \n",
    "    },\n",
    "    \"K562\": {\n",
    "        \"ChIP-Atlas K562\": load_ground_truth(GROUND_TRUTH_DIR / \"chipatlas_K562.csv\"),\n",
    "        \"RN117\": load_ground_truth(GROUND_TRUTH_DIR / \"RN117.tsv\"),        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532e9ed8",
   "metadata": {},
   "source": [
    "## Gradient Attribution Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1baa756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gradient_attribution(\n",
    "    model,\n",
    "    test_loader,\n",
    "    tg_scaler,\n",
    "    tf_scaler,\n",
    "    state,\n",
    "    device,\n",
    "    use_amp,\n",
    "    max_batches: int = None,\n",
    "    disable_bias: bool = False,\n",
    "    disable_motif_mask: bool = False,\n",
    "    disable_shortcut: bool = False,\n",
    "    zero_tf_expr: bool = False,\n",
    "):\n",
    "\n",
    "    T_total = len(state[\"tf_scaler_mean\"])\n",
    "    G_total = len(state[\"tg_scaler_mean\"])\n",
    "\n",
    "    grad_sum = torch.zeros(T_total, G_total, device=device, dtype=torch.float32)\n",
    "    grad_count = torch.zeros_like(grad_sum)\n",
    "\n",
    "    model.to(device).eval()\n",
    "\n",
    "    iterator = tqdm(\n",
    "        test_loader,\n",
    "        desc=f\"Gradient attributions\",\n",
    "        unit=\"batches\",\n",
    "        total=max_batches,\n",
    "        ncols=100,\n",
    "    )\n",
    "\n",
    "    batch_grad_np = {}\n",
    "    for b_idx, batch in enumerate(iterator):\n",
    "        if max_batches is not None and b_idx >= max_batches:\n",
    "            break\n",
    "\n",
    "        atac_wins, tf_tensor, targets, bias, tf_ids, tg_ids, motif_mask = batch\n",
    "        \n",
    "        if disable_bias:\n",
    "            bias = None\n",
    "            model.use_bias = False\n",
    "        if disable_motif_mask:\n",
    "            motif_mask = None\n",
    "            model.use_motif_mask = False\n",
    "            if hasattr(model, \"shortcut_layer\"):\n",
    "                model.shortcut_layer.use_motif_mask = False\n",
    "        if disable_shortcut:\n",
    "            if hasattr(model, \"shortcut_layer\"):\n",
    "                with torch.no_grad():\n",
    "                    model.shortcut_layer.scale.zero_()\n",
    "        \n",
    "        atac_wins = atac_wins.to(device)\n",
    "        tf_tensor = tf_tensor.to(device)\n",
    "        bias = bias.to(device) if bias is not None else None\n",
    "        tf_ids = tf_ids.to(device)\n",
    "        tg_ids = tg_ids.to(device)\n",
    "        motif_mask = motif_mask.to(device) if motif_mask is not None else None\n",
    "\n",
    "        # Shapes\n",
    "        if tf_tensor.dim() == 2:\n",
    "            B, T_eval = tf_tensor.shape\n",
    "            F_dim = 1\n",
    "        else:\n",
    "            B, T_eval, F_dim = tf_tensor.shape\n",
    "\n",
    "        # Flatten TF IDs over batch for aggregation later\n",
    "        if tf_ids.dim() == 1:  # [T_eval]\n",
    "            tf_ids_flat = tf_ids.view(1, T_eval).expand(B, T_eval).reshape(-1)\n",
    "        else:                  # [B, T_eval]\n",
    "            tf_ids_flat = tf_ids.reshape(-1)\n",
    "\n",
    "        G_eval = tg_ids.shape[-1]\n",
    "\n",
    "        # Assign TGs to this rank and optionally chunk them to control memory.\n",
    "        owned_tg_indices = torch.arange(G_eval, device=device)\n",
    "\n",
    "        chunk_size = owned_tg_indices.numel()\n",
    "\n",
    "        # ---------- METHOD 1: plain saliency (grad * input) ----------\n",
    "        total_owned = owned_tg_indices.numel()\n",
    "\n",
    "        for chunk_start in range(0, total_owned, chunk_size):\n",
    "            tg_chunk = owned_tg_indices[chunk_start : chunk_start + chunk_size]\n",
    "\n",
    "            # Slice TG-specific inputs to shrink the attention graph per chunk\n",
    "            if bias is not None:\n",
    "                bias_idx = tg_chunk\n",
    "                if bias.device != tg_chunk.device:\n",
    "                    bias_idx = tg_chunk.to(bias.device)\n",
    "                if bias.dim() == 3:\n",
    "                    bias_chunk = bias[:, bias_idx, :]\n",
    "                else:\n",
    "                    bias_chunk = bias[:, :, bias_idx, :]\n",
    "                bias_chunk = bias_chunk.to(device, non_blocking=True)\n",
    "            else:\n",
    "                bias_chunk = None\n",
    "\n",
    "            if motif_mask is not None:\n",
    "                mm_idx = tg_chunk\n",
    "                if motif_mask.device != tg_chunk.device:\n",
    "                    mm_idx = tg_chunk.to(motif_mask.device)\n",
    "                motif_mask_chunk = motif_mask[mm_idx].to(device, non_blocking=True)\n",
    "            else:\n",
    "                motif_mask_chunk = None\n",
    "\n",
    "            if tg_ids.dim() == 1:\n",
    "                tg_ids_chunk = tg_ids[tg_chunk]\n",
    "            else:\n",
    "                tg_ids_chunk = tg_ids[:, tg_chunk]\n",
    "\n",
    "            # Need gradients w.r.t. tf_tensor\n",
    "            tf_tensor_chunk = tf_tensor.detach().requires_grad_(True)\n",
    "            \n",
    "            if zero_tf_expr:\n",
    "                tf_tensor_chunk = tf_tensor.detach().clone()\n",
    "                tf_tensor_chunk.requires_grad_(True)\n",
    "\n",
    "                # if tf_tensor is [B, T] (expression only)\n",
    "                tf_tensor_chunk = tf_tensor_chunk * 0.0\n",
    "            \n",
    "            # Forward only for this TG chunk\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=use_amp):\n",
    "                tf_scaled = (\n",
    "                    tf_scaler.transform(tf_tensor_chunk, tf_ids)\n",
    "                    if tf_scaler is not None\n",
    "                    else tf_tensor_chunk\n",
    "                )\n",
    "\n",
    "                preds_s, _, _ = model(\n",
    "                    atac_wins,\n",
    "                    tf_scaled,\n",
    "                    tf_ids=tf_ids,\n",
    "                    tg_ids=tg_ids_chunk,\n",
    "                    bias=bias_chunk,\n",
    "                    motif_mask=motif_mask_chunk,\n",
    "                    return_shortcut_contrib=False,\n",
    "                )\n",
    "                preds_u = (\n",
    "                    tg_scaler.inverse_transform(preds_s, tg_ids_chunk)\n",
    "                    if tg_scaler is not None\n",
    "                    else preds_s\n",
    "                )\n",
    "                preds_u = torch.nan_to_num(\n",
    "                    preds_u.float(), nan=0.0, posinf=1e6, neginf=-1e6\n",
    "                )\n",
    "\n",
    "            local_chunk = tg_chunk.numel()\n",
    "\n",
    "            for offset in range(local_chunk):\n",
    "                retain = offset < (local_chunk - 1)\n",
    "\n",
    "                grad_output_j = torch.zeros_like(preds_u)\n",
    "                grad_output_j[:, offset] = 1.0\n",
    "\n",
    "                grads = torch.autograd.grad(\n",
    "                    outputs=preds_u,\n",
    "                    inputs=tf_tensor_chunk,\n",
    "                    grad_outputs=grad_output_j,\n",
    "                    retain_graph=retain,\n",
    "                    create_graph=False,\n",
    "                )[0]\n",
    "\n",
    "                # grad * input (expression channel)\n",
    "                if grads.dim() == 3:\n",
    "                    expr_grad = grads[..., 0]\n",
    "                    expr_input = tf_tensor_chunk[..., 0]\n",
    "                else:\n",
    "                    expr_grad = grads\n",
    "                    expr_input = tf_tensor_chunk\n",
    "\n",
    "                # saliency = expr_grad * expr_input  # optionally .abs()\n",
    "                saliency = expr_grad.abs()  # optionally .abs()\n",
    "                \n",
    "                # Sum the gradient over all TFs for this chunk\n",
    "                if saliency.dim() == 3:\n",
    "                    grad_abs = saliency.sum(dim=-1)\n",
    "                else:\n",
    "                    grad_abs = saliency\n",
    "                \n",
    "                grad_flat = grad_abs.reshape(-1)\n",
    "                if tg_ids_chunk.dim() == 1:\n",
    "                    tg_global = int(tg_ids_chunk[offset].item())\n",
    "                else:\n",
    "                    tg_global = int(tg_ids_chunk[0, offset].item())\n",
    "\n",
    "                # grad_sum and grad_count are indexed by global TG ID, but we need to aggregate contributions from all samples in the batch that correspond to this TG\n",
    "                col_grad = grad_sum[:, tg_global]\n",
    "                col_count = grad_count[:, tg_global]\n",
    "\n",
    "                # Sum the gradient over all samples in the batch that correspond to this chunk\n",
    "                col_grad.index_add_(0, tf_ids_flat, grad_flat)\n",
    "                col_count.index_add_(0, tf_ids_flat, torch.ones_like(grad_flat))\n",
    "                \n",
    "                if b_idx % 20 == 0:\n",
    "                    batch_grad_np[b_idx] = (grad_sum / (grad_count + 1e-12)).detach().cpu().numpy()\n",
    "\n",
    "            # cleanup per chunk\n",
    "            del (\n",
    "                preds_u,\n",
    "                preds_s,\n",
    "                tf_scaled,\n",
    "                tf_tensor_chunk,\n",
    "                bias_chunk,\n",
    "                motif_mask_chunk,\n",
    "                tg_ids_chunk,\n",
    "            )\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        # cleanup\n",
    "        del (\n",
    "            atac_wins,\n",
    "            tf_tensor,\n",
    "            bias,\n",
    "            tf_ids,\n",
    "            tg_ids,\n",
    "            motif_mask,\n",
    "        )\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # Calculate the gradient attribution score by dividing the summed gradients by the count of contributions for each TG\n",
    "        grad_attr = grad_sum / (grad_count + 1e-12)\n",
    "        grad_attr_np = grad_attr.detach().cpu().numpy()\n",
    "        \n",
    "    return grad_attr_np, batch_grad_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c996b1cc",
   "metadata": {},
   "source": [
    "## TF Knockout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ba07e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_tf_knockout(\n",
    "    model,\n",
    "    test_loader,\n",
    "    tg_scaler,\n",
    "    tf_scaler,\n",
    "    state,\n",
    "    device,\n",
    "    use_amp,\n",
    "    max_batches=None,\n",
    "    max_tgs_per_batch=None,\n",
    "    disable_bias=False,\n",
    "    disable_motif_mask=False,\n",
    "    disable_shortcut=False,\n",
    "    zero_tf_expr=False,\n",
    "\n",
    "    # NEW: KO baseline controls\n",
    "    ko_mode=\"raw_percentile\",   # \"raw_zero\" | \"raw_percentile\" | \"scaled_k_sigma\"\n",
    "    raw_percentile=0.01,        # used if ko_mode=\"raw_percentile\"\n",
    "    k_sigma=3.0,                # used if ko_mode=\"scaled_k_sigma\"\n",
    "    skip_if_near_ko=True,\n",
    "    eps=1e-8,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      tf_tg_effect_np: [T_total, G_total] float64 mean delta (baseline - KO), aggregated over observed contexts\n",
    "      effect_count_np: [T_total, G_total] float64 counts (#times each TF,TG updated)\n",
    "    \"\"\"\n",
    "    T_total = len(state[\"tf_scaler_mean\"])\n",
    "    G_total = len(state[\"tg_scaler_mean\"])\n",
    "\n",
    "    effect_sum   = torch.zeros((T_total, G_total), device=device, dtype=torch.float64)\n",
    "    effect_count = torch.zeros((T_total, G_total), device=device, dtype=torch.float64)\n",
    "\n",
    "    model.to(device).eval()\n",
    "\n",
    "    iterator = tqdm(test_loader, desc=\"TF knockout\", unit=\"batches\", total=max_batches, ncols=100)\n",
    "\n",
    "    batch_tf_ko_np = {}\n",
    "    for b_idx, batch in enumerate(iterator):\n",
    "        if (max_batches is not None) and (b_idx >= max_batches):\n",
    "            break\n",
    "        \n",
    "        atac_wins, tf_tensor, targets, bias, tf_ids, tg_ids, motif_mask = batch\n",
    "        \n",
    "        if disable_bias:\n",
    "            bias = None\n",
    "            model.use_bias = False\n",
    "        if disable_motif_mask:\n",
    "            motif_mask = None\n",
    "            model.use_motif_mask = False\n",
    "            if hasattr(model, \"shortcut_layer\"):\n",
    "                model.shortcut_layer.use_motif_mask = False\n",
    "        if disable_shortcut:\n",
    "            if hasattr(model, \"shortcut_layer\"):\n",
    "                with torch.no_grad():\n",
    "                    model.shortcut_layer.scale.zero_()\n",
    "\n",
    "        atac_wins  = atac_wins.to(device, non_blocking=True)\n",
    "        tf_tensor  = tf_tensor.to(device, non_blocking=True)   # unscaled (your convention)\n",
    "        bias       = bias.to(device, non_blocking=True) if bias is not None else None\n",
    "        tf_ids     = tf_ids.to(device)\n",
    "        tg_ids     = tg_ids.to(device)\n",
    "        motif_mask = motif_mask.to(device, non_blocking=True) if motif_mask is not None else None\n",
    "\n",
    "        # Shapes\n",
    "        if tf_tensor.dim() == 2:\n",
    "            B, T_eval = tf_tensor.shape\n",
    "            F_dim = 1\n",
    "            tf_unscaled_expr = tf_tensor                          # [B, T_eval]\n",
    "        else:\n",
    "            B, T_eval, F_dim = tf_tensor.shape\n",
    "            tf_unscaled_expr = tf_tensor[..., 0]                  # [B, T_eval] (assumes expr is channel 0)\n",
    "            \n",
    "        if zero_tf_expr:\n",
    "            tf_tensor = tf_tensor.clone()\n",
    "            if tf_tensor.dim() == 2:\n",
    "                tf_tensor = tf_tensor.zero_()\n",
    "            else:\n",
    "                tf_tensor[..., 0] = tf_tensor[..., 0].zero_()\n",
    "\n",
    "        # ---- Scale TF inputs once ----\n",
    "        if tf_scaler is not None:\n",
    "            tf_scaled_base = tf_scaler.transform(tf_tensor, tf_ids)\n",
    "        else:\n",
    "            tf_scaled_base = tf_tensor\n",
    "\n",
    "        # Work internally as 3D [B, T_eval, F_dim]\n",
    "        if tf_scaled_base.dim() == 2:\n",
    "            tf_scaled_base_3d = tf_scaled_base.unsqueeze(-1)      # [B, T_eval, 1]\n",
    "        else:\n",
    "            tf_scaled_base_3d = tf_scaled_base                    # [B, T_eval, F_dim]\n",
    "\n",
    "        # ---- Baseline predictions ----\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=use_amp):\n",
    "            preds_base_s, _, _ = model(\n",
    "                atac_wins,\n",
    "                tf_scaled_base if tf_scaled_base.dim() == 2 else tf_scaled_base_3d,\n",
    "                tf_ids=tf_ids, tg_ids=tg_ids,\n",
    "                bias=bias, motif_mask=motif_mask,\n",
    "                return_shortcut_contrib=False,\n",
    "            )\n",
    "            preds_base_u = tg_scaler.inverse_transform(preds_base_s, tg_ids) if tg_scaler is not None else preds_base_s\n",
    "\n",
    "        preds_base_u = torch.nan_to_num(preds_base_u.float(), nan=0.0, posinf=1e6, neginf=-1e6)  # [B, G_eval]\n",
    "        B, G_eval = preds_base_u.shape\n",
    "\n",
    "        owned_tg_indices = torch.arange(G_eval, device=device)\n",
    "        chunk_size = max_tgs_per_batch if max_tgs_per_batch is not None else owned_tg_indices.numel()\n",
    "\n",
    "        # ---- Build KO target values ----\n",
    "        # We will produce a KO value in *scaled* space per TF position (and feature dim),\n",
    "        # then broadcast to [B, F_dim] when applying.\n",
    "        if ko_mode == \"raw_zero\":\n",
    "            # raw expr=0 -> scaled via scaler (if present)\n",
    "            if tf_scaler is not None:\n",
    "                zeros_expr_1 = torch.zeros_like(tf_tensor[:1])\n",
    "                zeros_scaled_1 = tf_scaler.transform(zeros_expr_1, tf_ids)\n",
    "                if zeros_scaled_1.dim() == 2:\n",
    "                    zeros_scaled = zeros_scaled_1.squeeze(0).unsqueeze(-1)  # [T_eval, 1]\n",
    "                else:\n",
    "                    zeros_scaled = zeros_scaled_1.squeeze(0)                # [T_eval, F_dim]\n",
    "            else:\n",
    "                zeros_scaled = torch.zeros((T_eval, F_dim), device=device, dtype=tf_tensor.dtype)\n",
    "\n",
    "            ko_scaled_per_pos = zeros_scaled  # [T_eval, F_dim]\n",
    "\n",
    "        elif ko_mode == \"raw_percentile\":\n",
    "            # compute per-position raw percentile across batch (on expression channel)\n",
    "            # KO raw target per t_pos: q_t = quantile(tf_unscaled_expr[:, t_pos], raw_percentile)\n",
    "            q = torch.quantile(tf_unscaled_expr.float(), q=raw_percentile, dim=0)  # [T_eval]\n",
    "            # create a raw tf_tensor clone of shape [1,B?] just to transform;\n",
    "            # easiest: build tf_ko_raw with same shape as tf_tensor but only fill expr channel for one sample.\n",
    "            tf_ko_raw_1 = tf_tensor[:1].clone()\n",
    "            if tf_ko_raw_1.dim() == 2:\n",
    "                tf_ko_raw_1[0, :] = q.to(tf_ko_raw_1.dtype)\n",
    "            else:\n",
    "                tf_ko_raw_1[0, :, 0] = q.to(tf_ko_raw_1.dtype)\n",
    "                # leave other channels unchanged (or zero them if you prefer)\n",
    "            if tf_scaler is not None:\n",
    "                tf_ko_scaled_1 = tf_scaler.transform(tf_ko_raw_1, tf_ids)\n",
    "            else:\n",
    "                tf_ko_scaled_1 = tf_ko_raw_1\n",
    "            if tf_ko_scaled_1.dim() == 2:\n",
    "                ko_scaled_per_pos = tf_ko_scaled_1.squeeze(0).unsqueeze(-1)  # [T_eval,1]\n",
    "            else:\n",
    "                ko_scaled_per_pos = tf_ko_scaled_1.squeeze(0)                # [T_eval,F_dim]\n",
    "\n",
    "        elif ko_mode == \"scaled_k_sigma\":\n",
    "            # KO in scaled space: reduce expression feature by k_sigma standard deviations\n",
    "            # NOTE: this uses the fact that scaler.transform standardizes by (x-mean)/std (or similar).\n",
    "            # If your transform is different, adjust accordingly.\n",
    "            ko_scaled_per_pos = tf_scaled_base_3d[:1].clone().squeeze(0)      # [T_eval,F_dim]\n",
    "            if ko_scaled_per_pos.dim() == 1:\n",
    "                ko_scaled_per_pos = ko_scaled_per_pos.unsqueeze(-1)\n",
    "            # subtract k sigma on expr channel only (assumed 0)\n",
    "            ko_scaled_per_pos[:, 0] = ko_scaled_per_pos[:, 0] - float(k_sigma)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ko_mode: {ko_mode}\")\n",
    "\n",
    "        # ---- Working tensor to edit in-place ----\n",
    "        tf_scaled_work = tf_scaled_base_3d.clone()  # [B, T_eval, F_dim]\n",
    "\n",
    "        for t_pos in range(T_eval):\n",
    "            # Optionally skip if TF already near KO baseline in raw space\n",
    "            if skip_if_near_ko:\n",
    "                if ko_mode in {\"raw_zero\", \"raw_percentile\"}:\n",
    "                    # compare raw expr to target raw baseline (approx)\n",
    "                    raw_now = tf_unscaled_expr[:, t_pos].abs().max().item()\n",
    "                    if ko_mode == \"raw_zero\" and raw_now < eps:\n",
    "                        continue\n",
    "                else:\n",
    "                    # scaled-k-sigma: skip if scaled expr already very low? not necessary; leave on.\n",
    "                    pass\n",
    "\n",
    "            # Apply KO in scaled space for this position\n",
    "            ko_val = ko_scaled_per_pos[t_pos].view(1, -1).expand(B, F_dim)  # [B,F_dim]\n",
    "            tf_scaled_work[:, t_pos, :] = ko_val\n",
    "\n",
    "            # Match model input dimensionality\n",
    "            tf_scaled_input = tf_scaled_work.squeeze(-1) if tf_tensor.dim() == 2 else tf_scaled_work\n",
    "\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=use_amp):\n",
    "                preds_ko_s, _, _ = model(\n",
    "                    atac_wins, tf_scaled_input,\n",
    "                    tf_ids=tf_ids, tg_ids=tg_ids,\n",
    "                    bias=bias, motif_mask=motif_mask,\n",
    "                    return_shortcut_contrib=False,\n",
    "                )\n",
    "                preds_ko_u = tg_scaler.inverse_transform(preds_ko_s, tg_ids) if tg_scaler is not None else preds_ko_s\n",
    "\n",
    "            preds_ko_u = torch.nan_to_num(preds_ko_u.float(), nan=0.0, posinf=1e6, neginf=-1e6)  # [B,G_eval]\n",
    "\n",
    "            # delta = baseline - KO (positive means TF supports expression)\n",
    "            delta_mean = (preds_base_u - preds_ko_u).mean(dim=0)  # [G_eval]\n",
    "\n",
    "            tf_global = int(tf_ids[t_pos].item())\n",
    "\n",
    "            # IMPORTANT: tg_ids are global vocab ids; tg_chunk indexes within batch output\n",
    "            for start in range(0, owned_tg_indices.numel(), chunk_size):\n",
    "                tg_chunk = owned_tg_indices[start : start + chunk_size]\n",
    "                tg_globals = tg_ids[tg_chunk].long()              # [chunk]\n",
    "                delta_chunk = delta_mean[tg_chunk].double()       # [chunk]\n",
    "                effect_sum[tf_global, tg_globals] += delta_chunk\n",
    "                effect_count[tf_global, tg_globals] += 1.0\n",
    "\n",
    "            # restore\n",
    "            tf_scaled_work[:, t_pos, :] = tf_scaled_base_3d[:, t_pos, :]\n",
    "            \n",
    "                            \n",
    "            if b_idx % 20 == 0:\n",
    "                batch_tf_ko_np[b_idx] = (effect_sum / (effect_count + 1e-12)).detach().cpu().numpy()\n",
    "\n",
    "        # free some refs (optional)\n",
    "        del preds_base_s, preds_base_u\n",
    "\n",
    "    tf_tg_effect = effect_sum / (effect_count + 1e-12)\n",
    "    return tf_tg_effect.detach().cpu().numpy(), effect_count.detach().cpu().numpy(), batch_tf_ko_np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0033f8a9",
   "metadata": {},
   "source": [
    "## Load Model and Run Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e2cb812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(selected_experiment_dir, checkpoint_file, device):\n",
    "    params_path = selected_experiment_dir / \"run_parameters.json\"\n",
    "    with open(params_path, \"r\") as f:\n",
    "        params = json.load(f)\n",
    "\n",
    "    # Pull out architecture hyperparameters\n",
    "    d_model   = params.get(\"d_model\")\n",
    "    num_heads = params.get(\"num_heads\")\n",
    "    num_layers = params.get(\"num_layers\")\n",
    "    d_ff      = params.get(\"d_ff\")\n",
    "    dropout   = params.get(\"dropout\", 0.0)\n",
    "    use_shortcut   = params.get(\"use_shortcut\", False)\n",
    "    use_dist_bias  = params.get(\"use_dist_bias\", False)\n",
    "    use_motif_mask = params.get(\"use_motif_mask\", False)\n",
    "\n",
    "    \n",
    "    # 1) Load test loader and checkpoint\n",
    "    test_loader = torch.load(selected_experiment_dir / \"test_loader.pt\", weights_only=False)\n",
    "\n",
    "    ckpt_path = os.path.join(selected_experiment_dir, checkpoint_file)\n",
    "    state = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    \n",
    "    # 2) Recreate model EXACTLY as in training\n",
    "    model = model_module.MultiomicTransformer(\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        num_layers=num_layers,\n",
    "        d_ff=d_ff,\n",
    "        dropout=dropout,\n",
    "        tf_vocab_size=len(state[\"tf_scaler_mean\"]),\n",
    "        tg_vocab_size=len(state[\"tg_scaler_mean\"]),\n",
    "        use_bias=use_dist_bias,\n",
    "        use_shortcut=use_shortcut,\n",
    "        use_motif_mask=use_motif_mask,\n",
    "    )\n",
    "\n",
    "    if isinstance(state, dict) and \"model_state_dict\" in state:\n",
    "        model.load_state_dict(state[\"model_state_dict\"])\n",
    "    else:\n",
    "        model.load_state_dict(state)\n",
    "\n",
    "    model.to(device).eval()\n",
    "\n",
    "    # 3) Rebuild scalers on the SAME DEVICE as inputs\n",
    "    tg_scaler = dataset_refactor.SimpleScaler(\n",
    "        mean=torch.as_tensor(state[\"tg_scaler_mean\"], device=device, dtype=torch.float32),\n",
    "        std=torch.as_tensor(state[\"tg_scaler_std\"],  device=device, dtype=torch.float32),\n",
    "    )\n",
    "    tf_scaler = dataset_refactor.SimpleScaler(\n",
    "        mean=torch.as_tensor(state[\"tf_scaler_mean\"], device=device, dtype=torch.float32),\n",
    "        std=torch.as_tensor(state[\"tf_scaler_std\"],  device=device, dtype=torch.float32),\n",
    "    )\n",
    "\n",
    "    return model, test_loader, tg_scaler, tf_scaler, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce4fc495",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = experiment_loader.ExperimentLoader(\n",
    "    experiment_dir = \"/gpfs/Labs/Uzun/DATA/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/experiments/\",\n",
    "    experiment_name=\"mESC_E7.5_rep1_hvg_filter_disp_0.01\",\n",
    "    model_num=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1df3124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment: mESC_E7.5_rep1_hvg_filter_disp_0.01, Sample type: mESC\n",
      "Using device: cuda\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_720885/456417205.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(ckpt_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint trained_model.pt loaded. Max batches for attribution: 333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gradient attributions: 100%|█████████████████████████████████| 333/333 [13:06<00:00,  2.36s/batches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Gradient attribution finished 333 batches in 786.79 seconds.\n",
      "  - Running TF knockout with mode: scaled_k_sigma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TF knockout: 100%|███████████████████████████████████████████| 333/333 [47:19<00:00,  8.53s/batches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - TF knockout finished 333 batches in 2839.51 seconds.\n",
      "  - Ground truth: ChIP-Atlas mESC\n",
      "  - Ground truth: RN111\n",
      "  - Ground truth: RN112\n"
     ]
    }
   ],
   "source": [
    "sample_type = exp.experiment_name.split(\"_\")[0]\n",
    "gt_names = list(gt_by_dataset_dict[sample_type].keys())\n",
    "\n",
    "print(f\"\\nExperiment: {exp.experiment_name}, Sample type: {sample_type}\")\n",
    "\n",
    "checkpoints = [\"trained_model.pt\"] #\"checkpoint_0.pt\", \n",
    "checkpoint_nums = [0, 1]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\\n\")\n",
    "\n",
    "max_batches = 350\n",
    "disable_bias = False\n",
    "disable_motif_mask = False\n",
    "disable_shortcut = False\n",
    "zero_tf_expr = False\n",
    "\n",
    "# batch_testing = [1, 10, 20, 40, 60, 80, 100, 120]\n",
    "# batch_testing = [140, 160, 180, 200]\n",
    "\n",
    "print()\n",
    "\n",
    "# batch_limit_list = []\n",
    "# for batch_limit in batch_testing:\n",
    "checkpoint_grn_df_list = []\n",
    "checkpoint_per_tf_grn_df_list = []\n",
    "batch_checkpoint_grn_df_list = []\n",
    "\n",
    "tf_ko_batch_mode_dict = {}\n",
    "batch_tf_ko_dfs = {}\n",
    "\n",
    "grad_attrib_dfs = {}\n",
    "tf_ko_dfs = {}\n",
    "for checkpoint_name, checkpoint_num in zip(checkpoints, checkpoint_nums):\n",
    "    \n",
    "    model, test_loader, tg_scaler, tf_scaler, state = load_model(\n",
    "        selected_experiment_dir=exp.model_training_dir,\n",
    "        checkpoint_file=checkpoint_name,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    max_batches = min(max_batches, len(test_loader))\n",
    "    \n",
    "    print(f\"Checkpoint {checkpoint_name} loaded. Max batches for attribution: {max_batches}\")\n",
    "    # print(f\"  - Disable bias: {disable_bias}\")\n",
    "    # print(f\"  - Disable motif mask: {disable_motif_mask}\")\n",
    "    # print(f\"  - Disable shortcut: {disable_shortcut}\")\n",
    "    # print(f\"  - Zero TF expression: {zero_tf_expr}\")\n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    grad_attr_np, batch_grad_np_dict = run_gradient_attribution(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        tg_scaler=tg_scaler,\n",
    "        tf_scaler=tf_scaler,\n",
    "        state=state,\n",
    "        use_amp=False,\n",
    "        max_batches=max_batches,\n",
    "        device=device,\n",
    "        disable_bias=disable_bias,\n",
    "        disable_motif_mask=disable_motif_mask,\n",
    "        disable_shortcut=disable_shortcut,\n",
    "        zero_tf_expr=zero_tf_expr\n",
    "        \n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print(f\"  - Gradient attribution finished {max_batches} batches in {end_time - start_time:.2f} seconds.\")\n",
    "    \n",
    "    grad_df = format_grad_attrib_grn(grad_attr_np, exp.tf_names, exp.tg_names)\n",
    "    \n",
    "    grad_attrib_dfs[checkpoint_name] = grad_df\n",
    "    \n",
    "    \n",
    "    tf_ko_dfs[checkpoint_name] = {}\n",
    "    tf_ko_batch_mode_dict[checkpoint_name] = {}\n",
    "    for ko_mode in [\"scaled_k_sigma\"]: # \"raw_zero\", \"raw_percentile\", \n",
    "        print(f\"  - Running TF knockout with mode: {ko_mode}\")\n",
    "        start_time = time.time()\n",
    "        tfko_np, counts, batch_tf_ko_np_dict = run_tf_knockout(\n",
    "            model=model,\n",
    "            test_loader=test_loader,\n",
    "            tg_scaler=tg_scaler,\n",
    "            tf_scaler=tf_scaler,\n",
    "            state=state,\n",
    "            device=device,\n",
    "            use_amp=False,\n",
    "            max_batches=max_batches,\n",
    "            ko_mode=ko_mode,\n",
    "            raw_percentile=0.01,\n",
    "            disable_bias=disable_bias,\n",
    "            disable_motif_mask=disable_motif_mask,\n",
    "            disable_shortcut=disable_shortcut,\n",
    "            zero_tf_expr=zero_tf_expr\n",
    "            \n",
    "        )\n",
    "        end_time = time.time()\n",
    "        print(f\"  - TF knockout finished {max_batches} batches in {end_time - start_time:.2f} seconds.\")\n",
    "        \n",
    "        tf_ko_df = format_tf_ko_grn(tfko_np, exp.tf_names, exp.tg_names)\n",
    "        tf_ko_df[\"KO_Mode\"] = ko_mode\n",
    "        \n",
    "        tf_ko_dfs[checkpoint_name][ko_mode] = tf_ko_df\n",
    "        \n",
    "        \n",
    "        tf_ko_batch_mode_dict[checkpoint_name][ko_mode] = batch_tf_ko_np_dict\n",
    "    \n",
    "    # Evaluate against each ground truth\n",
    "    for ground_truth_name in gt_names:\n",
    "        print(f\"  - Ground truth: {ground_truth_name}\")\n",
    "        gt_df = gt_by_dataset_dict[sample_type][ground_truth_name]\n",
    "\n",
    "        grad_attrib_metrics_df = exp.generate_pooled_metrics(\n",
    "            method_name=\"Gradient Attribution\",\n",
    "            score_df=grad_df,\n",
    "            ground_truth=gt_df,\n",
    "            ground_truth_name=ground_truth_name,\n",
    "            top_fracs=(0.001, 0.005, 0.01, 0.05),\n",
    "            balance=False,\n",
    "        )\n",
    "        \n",
    "        for n_batch, batch_grad_np in batch_grad_np_dict.items():\n",
    "            batch_grad_df = format_grad_attrib_grn(batch_grad_np, exp.tf_names, exp.tg_names)\n",
    "            batch_grad_df[\"Batch\"] = n_batch\n",
    "            \n",
    "            batch_grad_attrib_metrics_df = exp.generate_pooled_metrics(\n",
    "                method_name=f\"Gradient Attribution\",\n",
    "                score_df=batch_grad_df,\n",
    "                ground_truth=gt_df,\n",
    "                ground_truth_name=ground_truth_name,\n",
    "                top_fracs=(0.001, 0.005, 0.01, 0.05),\n",
    "                balance=False,\n",
    "            )\n",
    "            \n",
    "            batch_grad_attrib_metrics_df[\"Batch\"] = n_batch\n",
    "            \n",
    "            batch_grad_attrib_metrics_df[\"checkpoint_name\"] = checkpoint_name\n",
    "            batch_grad_attrib_metrics_df[\"KO_Mode\"] = np.nan\n",
    "            batch_checkpoint_grn_df_list.append(batch_grad_attrib_metrics_df)\n",
    "        \n",
    "        for ko_mode in tf_ko_batch_mode_dict[checkpoint_name].keys():\n",
    "            for n_batch, batch_tf_ko_np in tf_ko_batch_mode_dict[checkpoint_name][ko_mode].items():\n",
    "                batch_tf_ko_df = format_tf_ko_grn(batch_tf_ko_np, exp.tf_names, exp.tg_names)\n",
    "                batch_tf_ko_df[\"Batch\"] = n_batch\n",
    "                                \n",
    "                batch_tf_ko_metrics_df = exp.generate_pooled_metrics(\n",
    "                    method_name=f\"TF Knockout\",\n",
    "                    score_df=batch_tf_ko_df,\n",
    "                    ground_truth=gt_df,\n",
    "                    ground_truth_name=ground_truth_name,\n",
    "                    top_fracs=(0.001, 0.005, 0.01, 0.05),\n",
    "                    balance=False,\n",
    "                )\n",
    "                \n",
    "                batch_tf_ko_metrics_df[\"Batch\"] = n_batch\n",
    "                batch_tf_ko_metrics_df[\"KO_Mode\"] = ko_mode\n",
    "                \n",
    "                batch_tf_ko_metrics_df[\"checkpoint_name\"] = checkpoint_name\n",
    "                batch_checkpoint_grn_df_list.append(batch_tf_ko_metrics_df)\n",
    "            \n",
    "        \n",
    "        \n",
    "        # grad_attrib_metrics_per_tf_df = exp.generate_per_tf_metrics(\n",
    "        #     method_name=\"Gradient Attribution\",\n",
    "        #     score_df=grad_df,\n",
    "        #     ground_truth=gt_df,\n",
    "        #     ground_truth_name=ground_truth_name,\n",
    "        #     top_fracs=(0.001, 0.005, 0.01, 0.05),\n",
    "        #     balance=False,\n",
    "        # )\n",
    "        \n",
    "        # grad_attrib_metrics_per_tf_df[\"checkpoint_name\"] = checkpoint_name\n",
    "        # checkpoint_per_tf_grn_df_list.append(grad_attrib_metrics_per_tf_df)\n",
    "        \n",
    "        grad_attrib_metrics_df[\"checkpoint_name\"] = checkpoint_name\n",
    "        checkpoint_grn_df_list.append(grad_attrib_metrics_df)\n",
    "        \n",
    "        # for mode in [\"raw_zero\", \"raw_percentile\", \"scaled_k_sigma\"]:\n",
    "        #     mode_tf_ko_df = tf_ko_dfs[checkpoint_name][mode]\n",
    "        #     mode_metrics_df = exp.generate_pooled_metrics(\n",
    "        #         method_name=f\"TF Knockout Effect ({mode})\",\n",
    "        #         score_df=mode_tf_ko_df,\n",
    "        #         ground_truth=gt_df,\n",
    "        #         ground_truth_name=ground_truth_name,\n",
    "        #         top_fracs=(0.001, 0.005, 0.01, 0.05),\n",
    "        #         balance=False,\n",
    "        #     )\n",
    "            \n",
    "        #     mode_metrics_per_tf_df = exp.generate_per_tf_metrics(\n",
    "        #         method_name=f\"TF Knockout Effect ({mode})\",\n",
    "        #         score_df=mode_tf_ko_df,\n",
    "        #         ground_truth=gt_df,\n",
    "        #         ground_truth_name=ground_truth_name,\n",
    "        #         top_fracs=(0.001, 0.005, 0.01, 0.05),\n",
    "        #         balance=False,\n",
    "        #     )\n",
    "            \n",
    "        #     mode_metrics_per_tf_df[\"checkpoint_name\"] = checkpoint_name\n",
    "        #     mode_metrics_df[\"checkpoint_name\"] = checkpoint_name\n",
    "            \n",
    "        #     checkpoint_grn_df_list.append(mode_metrics_df)        \n",
    "        #     checkpoint_per_tf_grn_df_list.append(mode_metrics_per_tf_df)\n",
    "        \n",
    "checkpoint_grn_df = pd.concat(checkpoint_grn_df_list)\n",
    "# checkpoint_per_tf_grn_df = pd.concat(checkpoint_per_tf_grn_df_list)\n",
    "\n",
    "# checkpoint_grn_df[\"batch_limit\"] = batch_limit\n",
    "    \n",
    "# final_grn_df = pd.concat(batch_limit_list)\n",
    "final_grn_df = pd.concat(batch_checkpoint_grn_df_list)\n",
    "final_grn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbd425f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: trained_model.pt, KO Mode: raw_zero, Batch: 0\n",
      "Checkpoint: trained_model.pt, KO Mode: raw_zero, Batch: 20\n",
      "Checkpoint: trained_model.pt, KO Mode: raw_percentile, Batch: 0\n",
      "Checkpoint: trained_model.pt, KO Mode: raw_percentile, Batch: 20\n",
      "Checkpoint: trained_model.pt, KO Mode: scaled_k_sigma, Batch: 0\n",
      "Checkpoint: trained_model.pt, KO Mode: scaled_k_sigma, Batch: 20\n"
     ]
    }
   ],
   "source": [
    "for checkpoint_name in checkpoints:\n",
    "    for ko_mode in tf_ko_dfs[checkpoint_name].keys():\n",
    "        for batch_num in tf_ko_batch_mode_dict[checkpoint_name][ko_mode].keys():\n",
    "            print(f\"Checkpoint: {checkpoint_name}, KO Mode: {ko_mode}, Batch: {batch_num}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6ce153",
   "metadata": {},
   "source": [
    "## Formatting and Plotting the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_ko_by_batch = final_grn_df[final_grn_df[\"method\"] == \"TF Knockout\"].groupby([\"Batch\", \"checkpoint_name\", \"KO_Mode\"])[[\"auroc\", \"auprc\"]].mean().reset_index().sort_values(\"Batch\")\n",
    "grad_attr_by_batch = final_grn_df[final_grn_df[\"method\"] == \"Gradient Attribution\"].groupby([\"Batch\", \"checkpoint_name\"])[[\"auroc\", \"auprc\"]].mean().reset_index().sort_values(\"Batch\")\n",
    "\n",
    "auroc_result_dict = {\n",
    "    \"TF Knockout\": tf_ko_by_batch[[\"Batch\", \"checkpoint_name\", \"KO_Mode\", \"auroc\"]],\n",
    "    \"Gradient Attribution\": grad_attr_by_batch[[\"Batch\", \"checkpoint_name\", \"auroc\"]],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b08fc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e498292",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TF Knockout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m selected_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF Knockout\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m selected_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_zero\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mauroc_result_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselected_method\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKO_Mode\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m      7\u001b[0m     df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKO_Mode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m selected_mode]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TF Knockout'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://psh01com1hdns08:8885/'. Verify the server is running and reachable. (Failed to connect to the remote Jupyter Server 'http://psh01com1hdns08:8885/'. Verify the server is running and reachable. (request to http://psh01com1hdns08:8885/api/kernels?1771602825712 failed, reason: connect ECONNREFUSED 10.90.29.221:8885).)."
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "selected_method = \"TF Knockout\"\n",
    "selected_mode = \"raw_zero\"\n",
    "df = auroc_result_dict[selected_method]\n",
    "if \"KO_Mode\" in df.columns:\n",
    "    df = df[df[\"KO_Mode\"] == selected_mode]\n",
    "else:\n",
    "    selected_mode = \"\"\n",
    "\n",
    "for checkpoint_name in checkpoints:\n",
    "    subset = df[df[\"checkpoint_name\"] == checkpoint_name]\n",
    "    plt.plot(subset[\"Batch\"], subset[\"auroc\"], label=checkpoint_name, marker=\"o\")\n",
    "plt.xlabel(\"Number of Batches\")\n",
    "plt.ylabel(\"AUROC\")\n",
    "plt.xticks(df[\"Batch\"].unique())\n",
    "plt.ylim(0.5, 0.6)\n",
    "plt.legend()\n",
    "plt.title(f\"{selected_method} {selected_mode}\\nAUROC vs Number of Batches\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "da2546c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    checkpoint_name                               method     auroc\n",
      "0   checkpoint_0.pt                 Gradient Attribution  0.517559\n",
      "1   checkpoint_0.pt  TF Knockout Effect (raw_percentile)  0.509052\n",
      "2   checkpoint_0.pt        TF Knockout Effect (raw_zero)  0.500000\n",
      "3   checkpoint_0.pt  TF Knockout Effect (scaled_k_sigma)  0.509108\n",
      "4  trained_model.pt                 Gradient Attribution  0.517842\n",
      "5  trained_model.pt  TF Knockout Effect (raw_percentile)  0.508116\n",
      "6  trained_model.pt        TF Knockout Effect (raw_zero)  0.500000\n",
      "7  trained_model.pt  TF Knockout Effect (scaled_k_sigma)  0.508192\n"
     ]
    }
   ],
   "source": [
    "avg_auroc = checkpoint_grn_df.groupby([\"checkpoint_name\", \"method\"])[\"auroc\"].mean().reset_index()\n",
    "print(avg_auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "46600379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter fingerprints (mean, std) for loaded checkpoints:\n",
      "  - checkpoint_0.pt (-0.007206522859632969, 1.0109975337982178)\n",
      "  - trained_model.pt (-0.006401196122169495, 1.0115910768508911)\n"
     ]
    }
   ],
   "source": [
    "# Ensure that the trained and untrained models have different parameters (sanity check)\n",
    "def param_fingerprint(model):\n",
    "    with torch.no_grad():\n",
    "        p = next(model.parameters()).detach().float().cpu()\n",
    "    return float(p.mean()), float(p.std())\n",
    "\n",
    "print(\"Parameter fingerprints (mean, std) for loaded checkpoints:\")\n",
    "for ckpt in [\"checkpoint_0.pt\",\"trained_model.pt\"]:\n",
    "    exp.load_trained_model(ckpt)\n",
    "    print(f\"  - {ckpt} {param_fingerprint(exp.model)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b421443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Attribution differences between checkpoints:\n",
      "  - score corr: 0.18826708511253593\n",
      "  - mean abs diff: 0.00041256362\n",
      "\n",
      "TF Knockout differences for mode 'raw_zero' between checkpoints:\n",
      "  - score corr: nan\n",
      "  - mean abs diff: 0.0\n",
      "\n",
      "TF Knockout differences for mode 'raw_percentile' between checkpoints:\n",
      "  - score corr: 0.11032474539842768\n",
      "  - mean abs diff: 8.053749338495201e-05\n",
      "\n",
      "TF Knockout differences for mode 'scaled_k_sigma' between checkpoints:\n",
      "  - score corr: 0.11710114764598735\n",
      "  - mean abs diff: 0.0001149580067646866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/Home/esm5360/miniconda3/envs/my_env/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:3045: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n"
     ]
    }
   ],
   "source": [
    "ga0 = grad_attrib_dfs[\"checkpoint_0.pt\"][\"Score\"].to_numpy()\n",
    "ga1 = grad_attrib_dfs[\"trained_model.pt\"][\"Score\"].to_numpy()\n",
    "print(\"Gradient Attribution differences between checkpoints:\")\n",
    "print(\"  - score corr:\", np.corrcoef(ga0, ga1)[0,1])\n",
    "print(\"  - mean abs diff:\", np.mean(np.abs(ga0 - ga1)))\n",
    "\n",
    "for ko_mode in [\"raw_zero\", \"raw_percentile\", \"scaled_k_sigma\"]:\n",
    "    tfko0 = tf_ko_dfs[\"checkpoint_0.pt\"][ko_mode][\"Score\"].to_numpy()\n",
    "    tfko1 = tf_ko_dfs[\"trained_model.pt\"][ko_mode][\"Score\"].to_numpy()\n",
    "    print(f\"\\nTF Knockout differences for mode '{ko_mode}' between checkpoints:\")\n",
    "    print(\"  - score corr:\", np.corrcoef(tfko0, tfko1)[0,1])\n",
    "    print(\"  - mean abs diff:\", np.mean(np.abs(tfko0 - tfko1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f96ec139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF Knockout differences for mode 'raw_zero' between checkpoints:\n",
      "  - TFKO % exactly 0 (ckpt0): 1.0\n",
      "  - TFKO % exactly 0 (trained): 1.0\n",
      "  - TFKO p99: 0.0\n",
      "  - TFKO max: 0.0\n",
      "\n",
      "TF Knockout differences for mode 'raw_percentile' between checkpoints:\n",
      "  - TFKO % exactly 0 (ckpt0): 0.9786803313960178\n",
      "  - TFKO % exactly 0 (trained): 0.9798095003125459\n",
      "  - TFKO p99: 0.00012108414375676923\n",
      "  - TFKO max: 0.8015046119681926\n",
      "\n",
      "TF Knockout differences for mode 'scaled_k_sigma' between checkpoints:\n",
      "  - TFKO % exactly 0 (ckpt0): 0.9785937635825801\n",
      "  - TFKO % exactly 0 (trained): 0.9799151851847844\n",
      "  - TFKO p99: 0.000220346709101947\n",
      "  - TFKO max: 0.950663745402339\n"
     ]
    }
   ],
   "source": [
    "for ko_mode in [\"raw_zero\", \"raw_percentile\", \"scaled_k_sigma\"]:\n",
    "    tfko0 = tf_ko_dfs[\"checkpoint_0.pt\"][ko_mode][\"Score\"].to_numpy()\n",
    "    tfko1 = tf_ko_dfs[\"trained_model.pt\"][ko_mode][\"Score\"].to_numpy()\n",
    "    print(f\"\\nTF Knockout differences for mode '{ko_mode}' between checkpoints:\")\n",
    "    print(\"  - TFKO % exactly 0 (ckpt0):\", (tfko0 == 0).mean())\n",
    "    print(\"  - TFKO % exactly 0 (trained):\", (tfko1 == 0).mean())\n",
    "    print(\"  - TFKO p99:\", np.quantile(tfko1, 0.99))\n",
    "    print(\"  - TFKO max:\", tfko1.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d52b0e0",
   "metadata": {},
   "source": [
    "## Compare the TG prediction MSE when TF expression is zeroed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "47354c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing TF ON vs OFF for checkpoint: checkpoint_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TF on vs off:  44%|█████████████████████▌                           | 22/50 [00:00<00:01, 23.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - mse_on_mean: 1.5179482725533573\n",
      "  - mse_off_mean: 1.5164991508830676\n",
      "  - mse_off_minus_on: -0.0014491216702896548\n",
      "  - delta_pred_mean_abs: 0.01273659070615064\n",
      "  - n_batches: 22\n",
      "  - tf_off_mode: raw_zero\n",
      "\n",
      "Comparing TF ON vs OFF for checkpoint: trained_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TF on vs off:  44%|█████████████████████▌                           | 22/50 [00:00<00:01, 25.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - mse_on_mean: 0.014005149280737069\n",
      "  - mse_off_mean: 0.02706064588644288\n",
      "  - mse_off_minus_on: 0.01305549660570581\n",
      "  - delta_pred_mean_abs: 0.07132863338020715\n",
      "  - n_batches: 22\n",
      "  - tf_off_mode: raw_zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "@torch.no_grad()\n",
    "def compare_tf_on_off(\n",
    "    model,\n",
    "    test_loader,\n",
    "    tg_scaler,\n",
    "    tf_scaler,\n",
    "    device,\n",
    "    use_amp=False,\n",
    "    max_batches=50,\n",
    "    tf_off_mode=\"raw_zero\",   # \"raw_zero\" or \"scaled_zero\"\n",
    "    disable_bias=True,\n",
    "    disable_motif_mask=True,\n",
    "    disable_shortcut=True,\n",
    "):\n",
    "    model.eval().to(device)\n",
    "\n",
    "    # Optional: disable architecture priors for fairness\n",
    "    old_use_bias = getattr(model, \"use_bias\", None)\n",
    "    old_use_motif = getattr(model, \"use_motif_mask\", None)\n",
    "    old_shortcut_scale = None\n",
    "\n",
    "    if disable_bias and old_use_bias is not None:\n",
    "        model.use_bias = False\n",
    "    if disable_motif_mask and old_use_motif is not None:\n",
    "        model.use_motif_mask = False\n",
    "        if hasattr(model, \"shortcut_layer\"):\n",
    "            model.shortcut_layer.use_motif_mask = False\n",
    "    if disable_shortcut and hasattr(model, \"shortcut_layer\"):\n",
    "        old_shortcut_scale = model.shortcut_layer.scale.detach().clone()\n",
    "        model.shortcut_layer.scale.data.zero_()\n",
    "\n",
    "    mse_on, mse_off = [], []\n",
    "    delta_mean_abs = []\n",
    "\n",
    "    it = tqdm(test_loader, total=max_batches, desc=\"TF on vs off\", ncols=100)\n",
    "    for b_idx, batch in enumerate(it):\n",
    "        if max_batches is not None and b_idx >= max_batches:\n",
    "            break\n",
    "\n",
    "        atac_wins, tf_tensor, targets, bias, tf_ids, tg_ids, motif_mask = batch\n",
    "        atac_wins = atac_wins.to(device, non_blocking=True)\n",
    "        tf_tensor = tf_tensor.to(device, non_blocking=True)\n",
    "        targets   = targets.to(device, non_blocking=True)\n",
    "        tf_ids    = tf_ids.to(device, non_blocking=True)\n",
    "        tg_ids    = tg_ids.to(device, non_blocking=True)\n",
    "\n",
    "        # call-time disable\n",
    "        if disable_bias:\n",
    "            bias = None\n",
    "        else:\n",
    "            bias = bias.to(device, non_blocking=True) if bias is not None else None\n",
    "\n",
    "        if disable_motif_mask:\n",
    "            motif_mask = None\n",
    "        else:\n",
    "            motif_mask = motif_mask.to(device, non_blocking=True) if motif_mask is not None else None\n",
    "\n",
    "        # ---- TF ON ----\n",
    "        tf_scaled_on = tf_scaler.transform(tf_tensor, tf_ids) if tf_scaler is not None else tf_tensor\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=use_amp):\n",
    "            pred_on_s, _, _ = model(\n",
    "                atac_wins, tf_scaled_on,\n",
    "                tf_ids=tf_ids, tg_ids=tg_ids,\n",
    "                bias=bias, motif_mask=motif_mask,\n",
    "                return_shortcut_contrib=False,\n",
    "            )\n",
    "        pred_on = tg_scaler.inverse_transform(pred_on_s, tg_ids) if tg_scaler is not None else pred_on_s\n",
    "        pred_on = torch.nan_to_num(pred_on.float(), nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "\n",
    "        # ---- TF OFF ----\n",
    "        if tf_off_mode == \"raw_zero\":\n",
    "            tf_off = tf_tensor.clone()\n",
    "            if tf_off.dim() == 2:\n",
    "                tf_off.zero_()\n",
    "            else:\n",
    "                tf_off[..., 0].zero_()\n",
    "            tf_scaled_off = tf_scaler.transform(tf_off, tf_ids) if tf_scaler is not None else tf_off\n",
    "        elif tf_off_mode == \"scaled_zero\":\n",
    "            tf_scaled_off = torch.zeros_like(tf_scaled_on)\n",
    "        else:\n",
    "            raise ValueError(\"tf_off_mode must be 'raw_zero' or 'scaled_zero'\")\n",
    "\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=use_amp):\n",
    "            pred_off_s, _, _ = model(\n",
    "                atac_wins, tf_scaled_off,\n",
    "                tf_ids=tf_ids, tg_ids=tg_ids,\n",
    "                bias=bias, motif_mask=motif_mask,\n",
    "                return_shortcut_contrib=False,\n",
    "            )\n",
    "        pred_off = tg_scaler.inverse_transform(pred_off_s, tg_ids) if tg_scaler is not None else pred_off_s\n",
    "        pred_off = torch.nan_to_num(pred_off.float(), nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "\n",
    "        # ---- Metrics ----\n",
    "        # MSE in unscaled TG space (what you probably want for interpretability)\n",
    "        mse_on.append(torch.mean((pred_on - targets)**2).item())\n",
    "        mse_off.append(torch.mean((pred_off - targets)**2).item())\n",
    "\n",
    "        # average absolute change in predictions\n",
    "        delta_mean_abs.append(torch.mean(torch.abs(pred_on - pred_off)).item())\n",
    "\n",
    "    # restore model flags\n",
    "    if old_use_bias is not None:\n",
    "        model.use_bias = old_use_bias\n",
    "    if old_use_motif is not None:\n",
    "        model.use_motif_mask = old_use_motif\n",
    "    if old_shortcut_scale is not None and hasattr(model, \"shortcut_layer\"):\n",
    "        model.shortcut_layer.scale.data.copy_(old_shortcut_scale)\n",
    "\n",
    "    out = {\n",
    "        \"mse_on_mean\": float(np.mean(mse_on)),\n",
    "        \"mse_off_mean\": float(np.mean(mse_off)),\n",
    "        \"mse_off_minus_on\": float(np.mean(mse_off) - np.mean(mse_on)),\n",
    "        \"delta_pred_mean_abs\": float(np.mean(delta_mean_abs)),\n",
    "        \"n_batches\": len(mse_on),\n",
    "        \"tf_off_mode\": tf_off_mode,\n",
    "    }\n",
    "    return out\n",
    "\n",
    "for checkpoint_name in checkpoints:\n",
    "    print(f\"\\nComparing TF ON vs OFF for checkpoint: {checkpoint_name}\")\n",
    "    exp.load_trained_model(checkpoint_name)\n",
    "    res = compare_tf_on_off(\n",
    "        model=exp.model,\n",
    "        test_loader=exp.test_loader,\n",
    "        tg_scaler=exp.tg_scaler,\n",
    "        tf_scaler=exp.tf_scaler,\n",
    "        device=exp.device,\n",
    "        use_amp=False,\n",
    "        max_batches=50,\n",
    "        tf_off_mode=\"raw_zero\",\n",
    "        disable_bias=True,\n",
    "        disable_motif_mask=True,\n",
    "        disable_shortcut=True,\n",
    "    )\n",
    "    for key, value in res.items():\n",
    "        print(f\"  - {key}: {value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c90e7f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating per-TF knockout sensitivity for checkpoint: checkpoint_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Per-TF KO sensitivity: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:14<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - checkpoint_0.pt overall mean ΔMSE: -8.842757469601277e-06\n",
      "  - TFs evaluated: 134\n",
      "  - median ΔMSE: -5.79e-06\n",
      "  - 95th pct ΔMSE: 4.15e-06\n",
      "  - fraction ΔMSE > 0: 0.142\n",
      " tf_id 11, name CREM, ΔMSE 2.328e-05\n",
      " tf_id 9, name CREB5, ΔMSE 1.163e-05\n",
      " tf_id 80, name TEAD1, ΔMSE 1.016e-05\n",
      " tf_id 69, name SKIL, ΔMSE 8.364e-06\n",
      " tf_id 104, name ZNF347, ΔMSE 7.600e-06\n",
      " tf_id 64, name PRDM10, ΔMSE 5.370e-06\n",
      " tf_id 56, name NR1D2, ΔMSE 4.660e-06\n",
      " tf_id 44, name MAX, ΔMSE 3.872e-06\n",
      " tf_id 129, name ZNF865, ΔMSE 3.866e-06\n",
      " tf_id 100, name ZNF280A, ΔMSE 3.503e-06\n",
      "\n",
      "Evaluating per-TF knockout sensitivity for checkpoint: trained_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Per-TF KO sensitivity: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:14<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - trained_model.pt overall mean ΔMSE: 6.0023861798850616e-05\n",
      "  - TFs evaluated: 134\n",
      "  - median ΔMSE: 4.69e-07\n",
      "  - 95th pct ΔMSE: 1.95e-04\n",
      "  - fraction ΔMSE > 0: 0.784\n",
      " tf_id 65, name RFX3, ΔMSE 3.283e-03\n",
      " tf_id 42, name LIN28B, ΔMSE 2.189e-03\n",
      " tf_id 52, name MYC, ΔMSE 6.466e-04\n",
      " tf_id 88, name ZEB1, ΔMSE 2.899e-04\n",
      " tf_id 122, name ZNF730, ΔMSE 2.802e-04\n",
      " tf_id 16, name EGR1, ΔMSE 2.171e-04\n",
      " tf_id 41, name LEF1, ΔMSE 1.953e-04\n",
      " tf_id 128, name ZNF846, ΔMSE 1.941e-04\n",
      " tf_id 43, name MAFG, ΔMSE 1.722e-04\n",
      " tf_id 7, name CGGBP1, ΔMSE 1.110e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "@torch.no_grad()\n",
    "def per_tf_knockout_sensitivity(\n",
    "    model,\n",
    "    test_loader,\n",
    "    tg_scaler,\n",
    "    tf_scaler,\n",
    "    device,\n",
    "    use_amp=False,\n",
    "    max_batches=25,          # start smaller, then increase\n",
    "    tf_off_mode=\"raw_zero\",  # \"raw_zero\" or \"scaled_zero\"\n",
    "    disable_bias=True,\n",
    "    disable_motif_mask=True,\n",
    "    disable_shortcut=True,\n",
    "    eps_skip=1e-8,           # skip TF positions that are ~0 already\n",
    "):\n",
    "    model.eval().to(device)\n",
    "\n",
    "    # Disable priors safely (save+restore)\n",
    "    old_use_bias = getattr(model, \"use_bias\", None)\n",
    "    old_use_motif = getattr(model, \"use_motif_mask\", None)\n",
    "    old_shortcut_scale = None\n",
    "\n",
    "    if disable_bias and old_use_bias is not None:\n",
    "        model.use_bias = False\n",
    "    if disable_motif_mask and old_use_motif is not None:\n",
    "        model.use_motif_mask = False\n",
    "        if hasattr(model, \"shortcut_layer\"):\n",
    "            model.shortcut_layer.use_motif_mask = False\n",
    "    if disable_shortcut and hasattr(model, \"shortcut_layer\"):\n",
    "        old_shortcut_scale = model.shortcut_layer.scale.detach().clone()\n",
    "        model.shortcut_layer.scale.data.zero_()\n",
    "\n",
    "    # Accumulators over global TF vocab id\n",
    "    # We'll accumulate mean ΔMSE over batches where that TF appears in tf_ids\n",
    "    tf_vocab_size = None\n",
    "    # We'll infer tf_vocab_size from scaler if possible\n",
    "    if tf_scaler is not None and hasattr(tf_scaler, \"mean\"):\n",
    "        tf_vocab_size = int(tf_scaler.mean.numel())\n",
    "    else:\n",
    "        # fallback: track max tf_id seen\n",
    "        tf_vocab_size = 0\n",
    "\n",
    "    delta_sum = None\n",
    "    delta_cnt = None\n",
    "\n",
    "    it = tqdm(test_loader, total=max_batches, desc=\"Per-TF KO sensitivity\")\n",
    "\n",
    "    for b_idx, batch in enumerate(it):\n",
    "        if max_batches is not None and b_idx >= max_batches:\n",
    "            break\n",
    "\n",
    "        atac_wins, tf_tensor, targets, bias, tf_ids, tg_ids, motif_mask = batch\n",
    "        atac_wins = atac_wins.to(device, non_blocking=True)\n",
    "        tf_tensor = tf_tensor.to(device, non_blocking=True)   # unscaled\n",
    "        targets   = targets.to(device, non_blocking=True)\n",
    "        tf_ids    = tf_ids.to(device, non_blocking=True)\n",
    "        tg_ids    = tg_ids.to(device, non_blocking=True)\n",
    "\n",
    "        # call-time disable\n",
    "        if disable_bias:\n",
    "            bias = None\n",
    "        else:\n",
    "            bias = bias.to(device, non_blocking=True) if bias is not None else None\n",
    "        if disable_motif_mask:\n",
    "            motif_mask = None\n",
    "        else:\n",
    "            motif_mask = motif_mask.to(device, non_blocking=True) if motif_mask is not None else None\n",
    "\n",
    "        # Shapes\n",
    "        if tf_tensor.dim() == 2:\n",
    "            B, T_eval = tf_tensor.shape\n",
    "            F_dim = 1\n",
    "            tf_expr = tf_tensor                    # [B, T]\n",
    "        else:\n",
    "            B, T_eval, F_dim = tf_tensor.shape\n",
    "            tf_expr = tf_tensor[..., 0]            # [B, T]\n",
    "\n",
    "        # Infer vocab size from tf_ids if needed\n",
    "        max_id = int(tf_ids.max().item())\n",
    "        if tf_vocab_size is None or tf_vocab_size == 0:\n",
    "            tf_vocab_size = max_id + 1\n",
    "        else:\n",
    "            tf_vocab_size = max(tf_vocab_size, max_id + 1)\n",
    "\n",
    "        if delta_sum is None:\n",
    "            delta_sum = torch.zeros(tf_vocab_size, device=\"cpu\", dtype=torch.float64)\n",
    "            delta_cnt = torch.zeros(tf_vocab_size, device=\"cpu\", dtype=torch.float64)\n",
    "        elif tf_vocab_size > delta_sum.numel():\n",
    "            # expand if we discovered higher ids\n",
    "            new_sum = torch.zeros(tf_vocab_size, device=\"cpu\", dtype=torch.float64)\n",
    "            new_cnt = torch.zeros(tf_vocab_size, device=\"cpu\", dtype=torch.float64)\n",
    "            new_sum[: delta_sum.numel()] = delta_sum\n",
    "            new_cnt[: delta_cnt.numel()] = delta_cnt\n",
    "            delta_sum, delta_cnt = new_sum, new_cnt\n",
    "\n",
    "        # ---- baseline preds ----\n",
    "        tf_scaled_on = tf_scaler.transform(tf_tensor, tf_ids) if tf_scaler is not None else tf_tensor\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=use_amp):\n",
    "            pred_on_s, _, _ = model(\n",
    "                atac_wins, tf_scaled_on,\n",
    "                tf_ids=tf_ids, tg_ids=tg_ids,\n",
    "                bias=bias, motif_mask=motif_mask,\n",
    "                return_shortcut_contrib=False,\n",
    "            )\n",
    "        pred_on = tg_scaler.inverse_transform(pred_on_s, tg_ids) if tg_scaler is not None else pred_on_s\n",
    "        pred_on = torch.nan_to_num(pred_on.float(), nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "        mse_on = torch.mean((pred_on - targets) ** 2).item()\n",
    "\n",
    "        # ---- per-position KO ----\n",
    "        # We'll iterate TF positions within this batch’s evaluated TF list.\n",
    "        for t_pos in range(T_eval):\n",
    "            # skip if this TF has no expression anyway\n",
    "            if torch.all(tf_expr[:, t_pos].abs() < eps_skip):\n",
    "                continue\n",
    "\n",
    "            # build tf_off\n",
    "            if tf_off_mode == \"raw_zero\":\n",
    "                tf_off = tf_tensor.clone()\n",
    "                if tf_off.dim() == 2:\n",
    "                    tf_off[:, t_pos] = 0.0\n",
    "                else:\n",
    "                    tf_off[:, t_pos, 0] = 0.0\n",
    "            elif tf_off_mode == \"scaled_zero\":\n",
    "                # compute on once, then only edit scaled input\n",
    "                # (note: scaled_zero = set to mean)\n",
    "                tf_off = None\n",
    "            else:\n",
    "                raise ValueError(\"tf_off_mode must be 'raw_zero' or 'scaled_zero'\")\n",
    "\n",
    "            if tf_off_mode == \"raw_zero\":\n",
    "                tf_scaled_off = tf_scaler.transform(tf_off, tf_ids) if tf_scaler is not None else tf_off\n",
    "            else:\n",
    "                tf_scaled_off = tf_scaled_on.clone()\n",
    "                # set scaled expression channel for that position to 0\n",
    "                if tf_scaled_off.dim() == 2:\n",
    "                    tf_scaled_off[:, t_pos] = 0.0\n",
    "                else:\n",
    "                    tf_scaled_off[:, t_pos, 0] = 0.0\n",
    "\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=use_amp):\n",
    "                pred_off_s, _, _ = model(\n",
    "                    atac_wins, tf_scaled_off,\n",
    "                    tf_ids=tf_ids, tg_ids=tg_ids,\n",
    "                    bias=bias, motif_mask=motif_mask,\n",
    "                    return_shortcut_contrib=False,\n",
    "                )\n",
    "            pred_off = tg_scaler.inverse_transform(pred_off_s, tg_ids) if tg_scaler is not None else pred_off_s\n",
    "            pred_off = torch.nan_to_num(pred_off.float(), nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "            mse_off = torch.mean((pred_off - targets) ** 2).item()\n",
    "\n",
    "            delta = float(mse_off - mse_on)\n",
    "\n",
    "            tf_global = int(tf_ids[t_pos].item()) if tf_ids.dim() == 1 else int(tf_ids[0, t_pos].item())\n",
    "            delta_sum[tf_global] += delta\n",
    "            delta_cnt[tf_global] += 1.0\n",
    "\n",
    "    # restore model flags\n",
    "    if old_use_bias is not None:\n",
    "        model.use_bias = old_use_bias\n",
    "    if old_use_motif is not None:\n",
    "        model.use_motif_mask = old_use_motif\n",
    "    if old_shortcut_scale is not None and hasattr(model, \"shortcut_layer\"):\n",
    "        model.shortcut_layer.scale.data.copy_(old_shortcut_scale)\n",
    "\n",
    "    delta_mean = (delta_sum / (delta_cnt + 1e-12)).numpy()\n",
    "    counts = delta_cnt.numpy()\n",
    "\n",
    "    return delta_mean, counts\n",
    "\n",
    "for ckpt in [\"checkpoint_0.pt\", \"trained_model.pt\"]:\n",
    "    print(f\"\\nEvaluating per-TF knockout sensitivity for checkpoint: {ckpt}\")\n",
    "    exp.load_trained_model(ckpt)\n",
    "    delta_mean, counts = per_tf_knockout_sensitivity(\n",
    "        model=exp.model,\n",
    "        test_loader=exp.test_loader,\n",
    "        tg_scaler=exp.tg_scaler,\n",
    "        tf_scaler=exp.tf_scaler,\n",
    "        device=exp.device,\n",
    "        use_amp=False,\n",
    "        max_batches=22,\n",
    "        tf_off_mode=\"raw_zero\",\n",
    "        disable_bias=True,\n",
    "        disable_motif_mask=True,\n",
    "        disable_shortcut=True,\n",
    "    )\n",
    "    \n",
    "    print(f\"  - {ckpt} overall mean ΔMSE: {np.nanmean(delta_mean[counts > 0])}\")\n",
    "\n",
    "    if ckpt == \"trained_model.pt\":\n",
    "        delta_mean_trained = delta_mean.copy()\n",
    "        counts_trained = counts.copy()\n",
    "    \n",
    "    valid = counts > 0\n",
    "    d = delta_mean[valid]\n",
    "\n",
    "    print(f\"  - TFs evaluated: {valid.sum()}\")\n",
    "    print(f\"  - median ΔMSE: {np.median(d):.2e}\")\n",
    "    print(f\"  - 95th pct ΔMSE: {np.quantile(d, 0.95):.2e}\")\n",
    "    print(f\"  - fraction ΔMSE > 0: {np.mean(d > 0):.3f}\")\n",
    "    top = np.argsort(d)[-10:][::-1]\n",
    "    for tf_id in top:\n",
    "        print(f\" tf_id {tf_id}, name {exp.tf_names[tf_id]}, ΔMSE {d[tf_id]:.3e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa4c6bd",
   "metadata": {},
   "source": [
    "## Do the important TFs (high ΔMSE) actually correspond to higher AUROC TFs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8935c2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "method",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tf",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "checkpoint_0.pt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trained_model.pt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_auroc",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "5fa9cfa1-be89-4f0e-a97c-b52c61b58e38",
       "rows": [
        [
         "0",
         "Gradient Attribution",
         "ChIP-Atlas K562",
         "ATF3",
         "0.5188211036616307",
         "0.5188347721805795",
         "1.3668518948795061e-05"
        ],
        [
         "1",
         "Gradient Attribution",
         "ChIP-Atlas K562",
         "BCL6",
         "0.5165744553969337",
         "0.5168774554964756",
         "0.00030300009954187246"
        ],
        [
         "2",
         "Gradient Attribution",
         "ChIP-Atlas K562",
         "CGGBP1",
         "0.5148021995712699",
         "0.5146715779392379",
         "-0.00013062163203203525"
        ],
        [
         "3",
         "Gradient Attribution",
         "ChIP-Atlas K562",
         "CREB3L1",
         "0.5223843611227212",
         "0.5223971656249112",
         "1.2804502189989186e-05"
        ],
        [
         "4",
         "Gradient Attribution",
         "ChIP-Atlas K562",
         "CREB5",
         "0.5170244148158005",
         "0.5172602308628178",
         "0.00023581604701727876"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>checkpoint_name</th>\n",
       "      <th>method</th>\n",
       "      <th>gt</th>\n",
       "      <th>tf</th>\n",
       "      <th>checkpoint_0.pt</th>\n",
       "      <th>trained_model.pt</th>\n",
       "      <th>delta_auroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Attribution</td>\n",
       "      <td>ChIP-Atlas K562</td>\n",
       "      <td>ATF3</td>\n",
       "      <td>0.518821</td>\n",
       "      <td>0.518835</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Attribution</td>\n",
       "      <td>ChIP-Atlas K562</td>\n",
       "      <td>BCL6</td>\n",
       "      <td>0.516574</td>\n",
       "      <td>0.516877</td>\n",
       "      <td>0.000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Attribution</td>\n",
       "      <td>ChIP-Atlas K562</td>\n",
       "      <td>CGGBP1</td>\n",
       "      <td>0.514802</td>\n",
       "      <td>0.514672</td>\n",
       "      <td>-0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Attribution</td>\n",
       "      <td>ChIP-Atlas K562</td>\n",
       "      <td>CREB3L1</td>\n",
       "      <td>0.522384</td>\n",
       "      <td>0.522397</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Attribution</td>\n",
       "      <td>ChIP-Atlas K562</td>\n",
       "      <td>CREB5</td>\n",
       "      <td>0.517024</td>\n",
       "      <td>0.517260</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "checkpoint_name                method               gt       tf  \\\n",
       "0                Gradient Attribution  ChIP-Atlas K562     ATF3   \n",
       "1                Gradient Attribution  ChIP-Atlas K562     BCL6   \n",
       "2                Gradient Attribution  ChIP-Atlas K562   CGGBP1   \n",
       "3                Gradient Attribution  ChIP-Atlas K562  CREB3L1   \n",
       "4                Gradient Attribution  ChIP-Atlas K562    CREB5   \n",
       "\n",
       "checkpoint_name  checkpoint_0.pt  trained_model.pt  delta_auroc  \n",
       "0                       0.518821          0.518835     0.000014  \n",
       "1                       0.516574          0.516877     0.000303  \n",
       "2                       0.514802          0.514672    -0.000131  \n",
       "3                       0.522384          0.522397     0.000013  \n",
       "4                       0.517024          0.517260     0.000236  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = checkpoint_per_tf_grn_df.copy()\n",
    "\n",
    "ckpt_a = \"checkpoint_0.pt\"\n",
    "ckpt_b = \"trained_model.pt\"\n",
    "\n",
    "pivot = (\n",
    "    df[df[\"checkpoint_name\"].isin([ckpt_a, ckpt_b])]\n",
    "    .pivot_table(\n",
    "        index=[\"method\", \"gt\", \"tf\"],\n",
    "        columns=\"checkpoint_name\",\n",
    "        values=\"auroc\",\n",
    "        aggfunc=\"mean\"\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "pivot[\"delta_auroc\"] = pivot[ckpt_b] - pivot[ckpt_a]\n",
    "pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2a1550b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "method",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_tfs",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mean_delta",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "median_delta",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "frac_improved",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "frac_gt_001",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "frac_gt_002",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "b0162467-1ecf-4aff-8be1-5da931d0152c",
       "rows": [
        [
         "1",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_percentile)",
         "50",
         "0.0038758480287375188",
         "0.0054224421035789505",
         "0.78",
         "0.06",
         "0.0"
        ],
        [
         "3",
         "ChIP-Atlas K562",
         "TF Knockout Effect (scaled_k_sigma)",
         "50",
         "0.0027656848688082315",
         "0.003993534775067364",
         "0.76",
         "0.02",
         "0.0"
        ],
        [
         "2",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_zero)",
         "50",
         "2.7934800250006832e-05",
         "4.3878363966132206e-05",
         "0.52",
         "0.0",
         "0.0"
        ],
        [
         "0",
         "ChIP-Atlas K562",
         "Gradient Attribution",
         "50",
         "4.89498026719315e-05",
         "1.919348240603247e-05",
         "0.66",
         "0.0",
         "0.0"
        ],
        [
         "5",
         "RN117",
         "TF Knockout Effect (raw_percentile)",
         "17",
         "0.002612327265685362",
         "0.004238110796308536",
         "0.6470588235294118",
         "0.11764705882352941",
         "0.0"
        ],
        [
         "7",
         "RN117",
         "TF Knockout Effect (scaled_k_sigma)",
         "17",
         "0.002001495795724989",
         "0.003002906110364245",
         "0.6470588235294118",
         "0.0",
         "0.0"
        ],
        [
         "4",
         "RN117",
         "Gradient Attribution",
         "17",
         "-9.023591541939775e-06",
         "-5.052109085745826e-05",
         "0.35294117647058826",
         "0.0",
         "0.0"
        ],
        [
         "6",
         "RN117",
         "TF Knockout Effect (raw_zero)",
         "17",
         "-0.0016616768438491808",
         "-0.0016415180507304283",
         "0.35294117647058826",
         "0.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>method</th>\n",
       "      <th>n_tfs</th>\n",
       "      <th>mean_delta</th>\n",
       "      <th>median_delta</th>\n",
       "      <th>frac_improved</th>\n",
       "      <th>frac_gt_001</th>\n",
       "      <th>frac_gt_002</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChIP-Atlas K562</td>\n",
       "      <td>TF Knockout Effect (raw_percentile)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.005422</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChIP-Atlas K562</td>\n",
       "      <td>TF Knockout Effect (scaled_k_sigma)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChIP-Atlas K562</td>\n",
       "      <td>TF Knockout Effect (raw_zero)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChIP-Atlas K562</td>\n",
       "      <td>Gradient Attribution</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RN117</td>\n",
       "      <td>TF Knockout Effect (raw_percentile)</td>\n",
       "      <td>17</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>0.004238</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RN117</td>\n",
       "      <td>TF Knockout Effect (scaled_k_sigma)</td>\n",
       "      <td>17</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RN117</td>\n",
       "      <td>Gradient Attribution</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RN117</td>\n",
       "      <td>TF Knockout Effect (raw_zero)</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.001662</td>\n",
       "      <td>-0.001642</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                gt                               method  n_tfs  mean_delta  \\\n",
       "1  ChIP-Atlas K562  TF Knockout Effect (raw_percentile)     50    0.003876   \n",
       "3  ChIP-Atlas K562  TF Knockout Effect (scaled_k_sigma)     50    0.002766   \n",
       "2  ChIP-Atlas K562        TF Knockout Effect (raw_zero)     50    0.000028   \n",
       "0  ChIP-Atlas K562                 Gradient Attribution     50    0.000049   \n",
       "5            RN117  TF Knockout Effect (raw_percentile)     17    0.002612   \n",
       "7            RN117  TF Knockout Effect (scaled_k_sigma)     17    0.002001   \n",
       "4            RN117                 Gradient Attribution     17   -0.000009   \n",
       "6            RN117        TF Knockout Effect (raw_zero)     17   -0.001662   \n",
       "\n",
       "   median_delta  frac_improved  frac_gt_001  frac_gt_002  \n",
       "1      0.005422       0.780000     0.060000          0.0  \n",
       "3      0.003994       0.760000     0.020000          0.0  \n",
       "2      0.000044       0.520000     0.000000          0.0  \n",
       "0      0.000019       0.660000     0.000000          0.0  \n",
       "5      0.004238       0.647059     0.117647          0.0  \n",
       "7      0.003003       0.647059     0.000000          0.0  \n",
       "4     -0.000051       0.352941     0.000000          0.0  \n",
       "6     -0.001642       0.352941     0.000000          0.0  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = (\n",
    "    pivot\n",
    "    .groupby([\"gt\", \"method\"])\n",
    "    .agg(\n",
    "        n_tfs=(\"delta_auroc\", \"count\"),\n",
    "        mean_delta=(\"delta_auroc\", \"mean\"),\n",
    "        median_delta=(\"delta_auroc\", \"median\"),\n",
    "        frac_improved=(\"delta_auroc\", lambda x: np.mean(x > 0)),\n",
    "        frac_gt_001=(\"delta_auroc\", lambda x: np.mean(x > 0.01)),\n",
    "        frac_gt_002=(\"delta_auroc\", lambda x: np.mean(x > 0.02)),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values([\"gt\", \"median_delta\"], ascending=[True, False])\n",
    ")\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "dc5764bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "method",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tf",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "delta_auroc",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "66070e78-c14d-40d3-b4c6-92072dcfa2aa",
       "rows": [
        [
         "128",
         "RN117",
         "TF Knockout Effect (raw_percentile)",
         "RUNX1",
         "0.011515982631357446"
        ],
        [
         "120",
         "RN117",
         "TF Knockout Effect (raw_percentile)",
         "ETV6",
         "0.010948566445838193"
        ],
        [
         "107",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_percentile)",
         "ZNF12",
         "0.010745297653235952"
        ],
        [
         "86",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_percentile)",
         "KDM5B",
         "0.010406717572844948"
        ],
        [
         "114",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_percentile)",
         "ZNF449",
         "0.010292616441619828"
        ],
        [
         "205",
         "ChIP-Atlas K562",
         "TF Knockout Effect (scaled_k_sigma)",
         "CREB5",
         "0.010106107980058732"
        ],
        [
         "126",
         "RN117",
         "TF Knockout Effect (raw_percentile)",
         "NFYA",
         "0.00965039430670045"
        ],
        [
         "220",
         "ChIP-Atlas K562",
         "TF Knockout Effect (scaled_k_sigma)",
         "KDM5B",
         "0.0094918486890061"
        ],
        [
         "260",
         "RN117",
         "TF Knockout Effect (scaled_k_sigma)",
         "NFYA",
         "0.009197517829675927"
        ],
        [
         "84",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_percentile)",
         "HMGN3",
         "0.009092905913941518"
        ],
        [
         "187",
         "RN117",
         "TF Knockout Effect (raw_zero)",
         "ETV6",
         "0.008712036252141342"
        ],
        [
         "71",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_percentile)",
         "CREB5",
         "0.0085589589683438"
        ],
        [
         "108",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_percentile)",
         "ZNF140",
         "0.008310181685313944"
        ],
        [
         "101",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_percentile)",
         "SOX6",
         "0.008159367854525867"
        ],
        [
         "218",
         "ChIP-Atlas K562",
         "TF Knockout Effect (scaled_k_sigma)",
         "HMGN3",
         "0.008153000374292119"
        ],
        [
         "254",
         "RN117",
         "TF Knockout Effect (scaled_k_sigma)",
         "ETV6",
         "0.008149654500438808"
        ],
        [
         "241",
         "ChIP-Atlas K562",
         "TF Knockout Effect (scaled_k_sigma)",
         "ZNF12",
         "0.008136615230713518"
        ],
        [
         "195",
         "RN117",
         "TF Knockout Effect (raw_zero)",
         "RUNX1",
         "0.00766129073051891"
        ],
        [
         "182",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_zero)",
         "ZNF551",
         "0.0076360353088690824"
        ],
        [
         "242",
         "ChIP-Atlas K562",
         "TF Knockout Effect (scaled_k_sigma)",
         "ZNF140",
         "0.007576991856354853"
        ],
        [
         "79",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_percentile)",
         "ETV1",
         "0.00756588117424184"
        ],
        [
         "262",
         "RN117",
         "TF Knockout Effect (scaled_k_sigma)",
         "RUNX1",
         "0.00753186645461712"
        ],
        [
         "117",
         "RN117",
         "TF Knockout Effect (raw_percentile)",
         "ATF3",
         "0.00747693016859996"
        ],
        [
         "132",
         "RN117",
         "TF Knockout Effect (raw_percentile)",
         "ZNF143",
         "0.007272382602882765"
        ],
        [
         "148",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_zero)",
         "ETV6",
         "0.00712344311528712"
        ],
        [
         "97",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_percentile)",
         "RUNX1",
         "0.0070332916146615965"
        ],
        [
         "81",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_percentile)",
         "ETV6",
         "0.007020340751416221"
        ],
        [
         "94",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_percentile)",
         "PLAG1",
         "0.007012338018365316"
        ],
        [
         "248",
         "ChIP-Atlas K562",
         "TF Knockout Effect (scaled_k_sigma)",
         "ZNF449",
         "0.006919865833075134"
        ],
        [
         "73",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_percentile)",
         "DDIT3",
         "0.006884240683903475"
        ],
        [
         "93",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_percentile)",
         "NFYA",
         "0.006840176686024435"
        ],
        [
         "233",
         "ChIP-Atlas K562",
         "TF Knockout Effect (scaled_k_sigma)",
         "SKIL",
         "0.006826015775609262"
        ],
        [
         "99",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_percentile)",
         "SKIL",
         "0.006800197534801433"
        ],
        [
         "112",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_percentile)",
         "ZNF281",
         "0.006792222679211757"
        ],
        [
         "121",
         "RN117",
         "TF Knockout Effect (raw_percentile)",
         "JUN",
         "0.00655648589367297"
        ],
        [
         "258",
         "RN117",
         "TF Knockout Effect (scaled_k_sigma)",
         "MAX",
         "0.006520157732271548"
        ],
        [
         "251",
         "RN117",
         "TF Knockout Effect (scaled_k_sigma)",
         "ATF3",
         "0.006509339942462722"
        ],
        [
         "250",
         "ChIP-Atlas K562",
         "TF Knockout Effect (scaled_k_sigma)",
         "ZNF84",
         "0.006468906558196874"
        ],
        [
         "227",
         "ChIP-Atlas K562",
         "TF Knockout Effect (scaled_k_sigma)",
         "NFYA",
         "0.006386598184994541"
        ],
        [
         "171",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_zero)",
         "TEAD1",
         "0.006306901867531134"
        ],
        [
         "246",
         "ChIP-Atlas K562",
         "TF Knockout Effect (scaled_k_sigma)",
         "ZNF281",
         "0.006252340112391619"
        ],
        [
         "266",
         "RN117",
         "TF Knockout Effect (scaled_k_sigma)",
         "ZNF143",
         "0.0061246180076659495"
        ],
        [
         "213",
         "ChIP-Atlas K562",
         "TF Knockout Effect (scaled_k_sigma)",
         "ETV1",
         "0.005885241818361475"
        ],
        [
         "216",
         "ChIP-Atlas K562",
         "TF Knockout Effect (scaled_k_sigma)",
         "HBP1",
         "0.005822342784626566"
        ],
        [
         "131",
         "RN117",
         "TF Knockout Effect (raw_percentile)",
         "ZBTB11",
         "0.0058077435156945745"
        ],
        [
         "209",
         "ChIP-Atlas K562",
         "TF Knockout Effect (scaled_k_sigma)",
         "E2F7",
         "0.005750500598530772"
        ],
        [
         "208",
         "ChIP-Atlas K562",
         "TF Knockout Effect (scaled_k_sigma)",
         "E2F5",
         "0.005597089703853753"
        ],
        [
         "180",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_zero)",
         "ZNF347",
         "0.005542741465363155"
        ],
        [
         "228",
         "ChIP-Atlas K562",
         "TF Knockout Effect (scaled_k_sigma)",
         "PLAG1",
         "0.005451056776111796"
        ],
        [
         "124",
         "RN117",
         "TF Knockout Effect (raw_percentile)",
         "MAX",
         "0.005448191582611561"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 120
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>checkpoint_name</th>\n",
       "      <th>gt</th>\n",
       "      <th>method</th>\n",
       "      <th>tf</th>\n",
       "      <th>delta_auroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>RN117</td>\n",
       "      <td>TF Knockout Effect (raw_percentile)</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>0.011516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>RN117</td>\n",
       "      <td>TF Knockout Effect (raw_percentile)</td>\n",
       "      <td>ETV6</td>\n",
       "      <td>0.010949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>ChIP-Atlas K562</td>\n",
       "      <td>TF Knockout Effect (raw_percentile)</td>\n",
       "      <td>ZNF12</td>\n",
       "      <td>0.010745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>ChIP-Atlas K562</td>\n",
       "      <td>TF Knockout Effect (raw_percentile)</td>\n",
       "      <td>KDM5B</td>\n",
       "      <td>0.010407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>ChIP-Atlas K562</td>\n",
       "      <td>TF Knockout Effect (raw_percentile)</td>\n",
       "      <td>ZNF449</td>\n",
       "      <td>0.010293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>RN117</td>\n",
       "      <td>TF Knockout Effect (scaled_k_sigma)</td>\n",
       "      <td>SOX6</td>\n",
       "      <td>-0.004356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>RN117</td>\n",
       "      <td>TF Knockout Effect (raw_zero)</td>\n",
       "      <td>MYC</td>\n",
       "      <td>-0.005063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>RN117</td>\n",
       "      <td>TF Knockout Effect (raw_percentile)</td>\n",
       "      <td>PRDM10</td>\n",
       "      <td>-0.005145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>RN117</td>\n",
       "      <td>TF Knockout Effect (raw_zero)</td>\n",
       "      <td>SOX6</td>\n",
       "      <td>-0.006764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>RN117</td>\n",
       "      <td>TF Knockout Effect (raw_zero)</td>\n",
       "      <td>MAFG</td>\n",
       "      <td>-0.006989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "checkpoint_name               gt                               method      tf  \\\n",
       "128                        RN117  TF Knockout Effect (raw_percentile)   RUNX1   \n",
       "120                        RN117  TF Knockout Effect (raw_percentile)    ETV6   \n",
       "107              ChIP-Atlas K562  TF Knockout Effect (raw_percentile)   ZNF12   \n",
       "86               ChIP-Atlas K562  TF Knockout Effect (raw_percentile)   KDM5B   \n",
       "114              ChIP-Atlas K562  TF Knockout Effect (raw_percentile)  ZNF449   \n",
       "..                           ...                                  ...     ...   \n",
       "263                        RN117  TF Knockout Effect (scaled_k_sigma)    SOX6   \n",
       "192                        RN117        TF Knockout Effect (raw_zero)     MYC   \n",
       "127                        RN117  TF Knockout Effect (raw_percentile)  PRDM10   \n",
       "196                        RN117        TF Knockout Effect (raw_zero)    SOX6   \n",
       "190                        RN117        TF Knockout Effect (raw_zero)    MAFG   \n",
       "\n",
       "checkpoint_name  delta_auroc  \n",
       "128                 0.011516  \n",
       "120                 0.010949  \n",
       "107                 0.010745  \n",
       "86                  0.010407  \n",
       "114                 0.010293  \n",
       "..                       ...  \n",
       "263                -0.004356  \n",
       "192                -0.005063  \n",
       "127                -0.005145  \n",
       "196                -0.006764  \n",
       "190                -0.006989  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tfs = (\n",
    "    pivot\n",
    "    .sort_values(\"delta_auroc\", ascending=False)\n",
    "    .groupby([\"gt\", \"method\"])\n",
    "    .head(15)\n",
    ")\n",
    "\n",
    "top_tfs[[\"gt\",\"method\",\"tf\",\"delta_auroc\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8274b47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_mse_df = pd.DataFrame({\n",
    "    \"tf\": exp.tf_names,\n",
    "    \"delta_mse\": delta_mean  # from your per_tf_knockout_sensitivity\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2c61bedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 method               gt       tf  checkpoint_0.pt  \\\n",
      "0  Gradient Attribution  ChIP-Atlas K562     ATF3         0.518821   \n",
      "1  Gradient Attribution  ChIP-Atlas K562     BCL6         0.516574   \n",
      "2  Gradient Attribution  ChIP-Atlas K562   CGGBP1         0.514802   \n",
      "3  Gradient Attribution  ChIP-Atlas K562  CREB3L1         0.522384   \n",
      "4  Gradient Attribution  ChIP-Atlas K562    CREB5         0.517024   \n",
      "\n",
      "   trained_model.pt  delta_auroc     delta_mse  \n",
      "0          0.518835     0.000014  4.473100e-06  \n",
      "1          0.516877     0.000303  2.000227e-07  \n",
      "2          0.514672    -0.000131  1.110194e-04  \n",
      "3          0.522397     0.000013  2.593628e-06  \n",
      "4          0.517260     0.000236  1.440375e-07  \n"
     ]
    }
   ],
   "source": [
    "merged = pivot.merge(delta_mse_df, on=\"tf\", how=\"left\")\n",
    "print(merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "37b14e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                gt                               method   n  delta_auroc_std  \\\n",
      "0  ChIP-Atlas K562                 Gradient Attribution  50         0.000111   \n",
      "1  ChIP-Atlas K562  TF Knockout Effect (raw_percentile)  50         0.004771   \n",
      "2  ChIP-Atlas K562        TF Knockout Effect (raw_zero)  50         0.003623   \n",
      "3  ChIP-Atlas K562  TF Knockout Effect (scaled_k_sigma)  50         0.004608   \n",
      "4            RN117                 Gradient Attribution  17         0.000210   \n",
      "5            RN117  TF Knockout Effect (raw_percentile)  17         0.006526   \n",
      "6            RN117        TF Knockout Effect (raw_zero)  17         0.005042   \n",
      "7            RN117  TF Knockout Effect (scaled_k_sigma)  17         0.005614   \n",
      "\n",
      "   delta_mse_std  delta_auroc_nunique  auroc0_nunique  auroc1_nunique  \n",
      "0       0.000101                   50              50              50  \n",
      "1       0.000101                   50              50              50  \n",
      "2       0.000101                   50              50              50  \n",
      "3       0.000101                   50              50              50  \n",
      "4       0.000165                   17              17              17  \n",
      "5       0.000165                   17              17              17  \n",
      "6       0.000165                   17              17              17  \n",
      "7       0.000165                   17              17              17  \n"
     ]
    }
   ],
   "source": [
    "var_check = (merged\n",
    "    .groupby([\"gt\",\"method\"])\n",
    "    .agg(\n",
    "        n=(\"delta_auroc\",\"count\"),\n",
    "        delta_auroc_std=(\"delta_auroc\",\"std\"),\n",
    "        delta_mse_std=(\"delta_mse\",\"std\"),\n",
    "        delta_auroc_nunique=(\"delta_auroc\",\"nunique\"),\n",
    "        auroc0_nunique=(\"checkpoint_0.pt\",\"nunique\"),\n",
    "        auroc1_nunique=(\"trained_model.pt\",\"nunique\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(var_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d1387e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                gt                               method  \\\n",
      "2  ChIP-Atlas K562        TF Knockout Effect (raw_zero)   \n",
      "0  ChIP-Atlas K562                 Gradient Attribution   \n",
      "6            RN117        TF Knockout Effect (raw_zero)   \n",
      "4            RN117                 Gradient Attribution   \n",
      "1  ChIP-Atlas K562  TF Knockout Effect (raw_percentile)   \n",
      "3  ChIP-Atlas K562  TF Knockout Effect (scaled_k_sigma)   \n",
      "5            RN117  TF Knockout Effect (raw_percentile)   \n",
      "7            RN117  TF Knockout Effect (scaled_k_sigma)   \n",
      "\n",
      "   corr(delta_mse, delta_auroc)  \n",
      "2                     -0.128521  \n",
      "0                     -0.159794  \n",
      "6                     -0.220839  \n",
      "4                     -0.299145  \n",
      "1                     -0.411431  \n",
      "3                     -0.412405  \n",
      "5                     -0.492854  \n",
      "7                     -0.650137  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36461/1783682921.py:4: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g[[\"delta_mse\", \"delta_auroc\"]]\n"
     ]
    }
   ],
   "source": [
    "corr_df = (\n",
    "    merged\n",
    "    .groupby([\"gt\", \"method\"])\n",
    "    .apply(lambda g: g[[\"delta_mse\", \"delta_auroc\"]]\n",
    "           .dropna()\n",
    "           .corr()\n",
    "           .iloc[0,1])\n",
    "    .reset_index(name=\"corr(delta_mse, delta_auroc)\")\n",
    "    .sort_values(\"corr(delta_mse, delta_auroc)\", ascending=False)\n",
    ")\n",
    "\n",
    "print(corr_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "524b609c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                gt                               method  \\\n",
      "2  ChIP-Atlas K562        TF Knockout Effect (raw_zero)   \n",
      "0  ChIP-Atlas K562                 Gradient Attribution   \n",
      "6            RN117        TF Knockout Effect (raw_zero)   \n",
      "4            RN117                 Gradient Attribution   \n",
      "1  ChIP-Atlas K562  TF Knockout Effect (raw_percentile)   \n",
      "3  ChIP-Atlas K562  TF Knockout Effect (scaled_k_sigma)   \n",
      "5            RN117  TF Knockout Effect (raw_percentile)   \n",
      "7            RN117  TF Knockout Effect (scaled_k_sigma)   \n",
      "\n",
      "   corr(delta_mse, delta_auprc)  \n",
      "2                     -0.161439  \n",
      "0                     -0.194246  \n",
      "6                     -0.259321  \n",
      "4                     -0.386344  \n",
      "1                     -0.404680  \n",
      "3                     -0.474288  \n",
      "5                     -0.481501  \n",
      "7                     -0.625501  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36461/3510795068.py:13: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g[[\"delta_mse\",\"delta_auprc\"]].dropna().corr().iloc[0,1])\n"
     ]
    }
   ],
   "source": [
    "# build pivot for auprc, same as auroc\n",
    "pivot_pr = (\n",
    "    checkpoint_per_tf_grn_df[checkpoint_per_tf_grn_df[\"checkpoint_name\"].isin([\"checkpoint_0.pt\",\"trained_model.pt\"])]\n",
    "    .pivot_table(index=[\"gt\",\"method\",\"tf\"], columns=\"checkpoint_name\", values=\"auprc\", aggfunc=\"mean\")\n",
    "    .reset_index()\n",
    ")\n",
    "pivot_pr[\"delta_auprc\"] = pivot_pr[\"trained_model.pt\"] - pivot_pr[\"checkpoint_0.pt\"]\n",
    "\n",
    "merged_pr = pivot_pr.merge(delta_mse_df, on=\"tf\", how=\"left\")\n",
    "\n",
    "corr_pr = (\n",
    "    merged_pr.groupby([\"gt\",\"method\"])\n",
    "    .apply(lambda g: g[[\"delta_mse\",\"delta_auprc\"]].dropna().corr().iloc[0,1])\n",
    "    .reset_index(name=\"corr(delta_mse, delta_auprc)\")\n",
    "    .sort_values(\"corr(delta_mse, delta_auprc)\", ascending=False)\n",
    ")\n",
    "print(corr_pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dec369d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                gt                               method  \\\n",
      "4            RN117                 Gradient Attribution   \n",
      "6            RN117        TF Knockout Effect (raw_zero)   \n",
      "0  ChIP-Atlas K562                 Gradient Attribution   \n",
      "2  ChIP-Atlas K562        TF Knockout Effect (raw_zero)   \n",
      "5            RN117  TF Knockout Effect (raw_percentile)   \n",
      "7            RN117  TF Knockout Effect (scaled_k_sigma)   \n",
      "3  ChIP-Atlas K562  TF Knockout Effect (scaled_k_sigma)   \n",
      "1  ChIP-Atlas K562  TF Knockout Effect (raw_percentile)   \n",
      "\n",
      "   corr(delta_mse, auroc_trained)  \n",
      "4                        0.348655  \n",
      "6                        0.169597  \n",
      "0                        0.085636  \n",
      "2                       -0.000650  \n",
      "5                       -0.096821  \n",
      "7                       -0.104069  \n",
      "3                       -0.196001  \n",
      "1                       -0.206345  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36461/1402109170.py:6: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g[[\"delta_mse\",\"auroc_trained\"]].dropna().corr().iloc[0,1])\n"
     ]
    }
   ],
   "source": [
    "trained = merged[merged[\"gt\"].notna()].copy()  # use your merged with auroc columns\n",
    "trained[\"auroc_trained\"] = trained[\"trained_model.pt\"]\n",
    "\n",
    "corr_abs = (\n",
    "    trained.groupby([\"gt\",\"method\"])\n",
    "    .apply(lambda g: g[[\"delta_mse\",\"auroc_trained\"]].dropna().corr().iloc[0,1])\n",
    "    .reset_index(name=\"corr(delta_mse, auroc_trained)\")\n",
    "    .sort_values(\"corr(delta_mse, auroc_trained)\", ascending=False)\n",
    ")\n",
    "print(corr_abs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5c0930dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "method",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "corr(delta_mse, delta_auroc)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "corr(delta_mse, delta_auprc)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "corr(delta_mse, auroc_trained)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "8b7b0f62-978e-4d6a-b5ed-56de852477b2",
       "rows": [
        [
         "0",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_zero)",
         "-0.12852149612266583",
         "-0.16143869670884023",
         "-0.0006495623785908006"
        ],
        [
         "1",
         "ChIP-Atlas K562",
         "Gradient Attribution",
         "-0.1597935331787572",
         "-0.19424602049764525",
         "0.08563619905139545"
        ],
        [
         "2",
         "RN117",
         "TF Knockout Effect (raw_zero)",
         "-0.22083878100836984",
         "-0.2593208523056317",
         "0.16959670137313693"
        ],
        [
         "3",
         "RN117",
         "Gradient Attribution",
         "-0.2991453240540596",
         "-0.38634409468424685",
         "0.34865470578714386"
        ],
        [
         "4",
         "ChIP-Atlas K562",
         "TF Knockout Effect (raw_percentile)",
         "-0.41143075848949195",
         "-0.4046795752847519",
         "-0.20634493542315185"
        ],
        [
         "5",
         "ChIP-Atlas K562",
         "TF Knockout Effect (scaled_k_sigma)",
         "-0.4124047291253975",
         "-0.4742882768272419",
         "-0.19600133729609154"
        ],
        [
         "6",
         "RN117",
         "TF Knockout Effect (raw_percentile)",
         "-0.49285379719959704",
         "-0.4815009554835006",
         "-0.09682090065799084"
        ],
        [
         "7",
         "RN117",
         "TF Knockout Effect (scaled_k_sigma)",
         "-0.650137460568865",
         "-0.6255006305268979",
         "-0.10406873051572516"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>method</th>\n",
       "      <th>corr(delta_mse, delta_auroc)</th>\n",
       "      <th>corr(delta_mse, delta_auprc)</th>\n",
       "      <th>corr(delta_mse, auroc_trained)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChIP-Atlas K562</td>\n",
       "      <td>TF Knockout Effect (raw_zero)</td>\n",
       "      <td>-0.128521</td>\n",
       "      <td>-0.161439</td>\n",
       "      <td>-0.000650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChIP-Atlas K562</td>\n",
       "      <td>Gradient Attribution</td>\n",
       "      <td>-0.159794</td>\n",
       "      <td>-0.194246</td>\n",
       "      <td>0.085636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RN117</td>\n",
       "      <td>TF Knockout Effect (raw_zero)</td>\n",
       "      <td>-0.220839</td>\n",
       "      <td>-0.259321</td>\n",
       "      <td>0.169597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RN117</td>\n",
       "      <td>Gradient Attribution</td>\n",
       "      <td>-0.299145</td>\n",
       "      <td>-0.386344</td>\n",
       "      <td>0.348655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChIP-Atlas K562</td>\n",
       "      <td>TF Knockout Effect (raw_percentile)</td>\n",
       "      <td>-0.411431</td>\n",
       "      <td>-0.404680</td>\n",
       "      <td>-0.206345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ChIP-Atlas K562</td>\n",
       "      <td>TF Knockout Effect (scaled_k_sigma)</td>\n",
       "      <td>-0.412405</td>\n",
       "      <td>-0.474288</td>\n",
       "      <td>-0.196001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RN117</td>\n",
       "      <td>TF Knockout Effect (raw_percentile)</td>\n",
       "      <td>-0.492854</td>\n",
       "      <td>-0.481501</td>\n",
       "      <td>-0.096821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RN117</td>\n",
       "      <td>TF Knockout Effect (scaled_k_sigma)</td>\n",
       "      <td>-0.650137</td>\n",
       "      <td>-0.625501</td>\n",
       "      <td>-0.104069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                gt                               method  \\\n",
       "0  ChIP-Atlas K562        TF Knockout Effect (raw_zero)   \n",
       "1  ChIP-Atlas K562                 Gradient Attribution   \n",
       "2            RN117        TF Knockout Effect (raw_zero)   \n",
       "3            RN117                 Gradient Attribution   \n",
       "4  ChIP-Atlas K562  TF Knockout Effect (raw_percentile)   \n",
       "5  ChIP-Atlas K562  TF Knockout Effect (scaled_k_sigma)   \n",
       "6            RN117  TF Knockout Effect (raw_percentile)   \n",
       "7            RN117  TF Knockout Effect (scaled_k_sigma)   \n",
       "\n",
       "   corr(delta_mse, delta_auroc)  corr(delta_mse, delta_auprc)  \\\n",
       "0                     -0.128521                     -0.161439   \n",
       "1                     -0.159794                     -0.194246   \n",
       "2                     -0.220839                     -0.259321   \n",
       "3                     -0.299145                     -0.386344   \n",
       "4                     -0.411431                     -0.404680   \n",
       "5                     -0.412405                     -0.474288   \n",
       "6                     -0.492854                     -0.481501   \n",
       "7                     -0.650137                     -0.625501   \n",
       "\n",
       "   corr(delta_mse, auroc_trained)  \n",
       "0                       -0.000650  \n",
       "1                        0.085636  \n",
       "2                        0.169597  \n",
       "3                        0.348655  \n",
       "4                       -0.206345  \n",
       "5                       -0.196001  \n",
       "6                       -0.096821  \n",
       "7                       -0.104069  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_scores = pd.merge(\n",
    "    corr_df, corr_pr, on=[\"gt\",\"method\"], how='inner'\n",
    "    ).merge(\n",
    "    corr_abs, on=[\"gt\",\"method\"], how='inner'\n",
    "    )\n",
    "full_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d0d9074a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChIP-Atlas K562\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tf",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "checkpoint_0.pt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trained_model.pt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_auroc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_mse",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "cc705e7d-9015-4994-9ed5-2dc33cc31631",
       "rows": [
        [
         "25",
         "MYC",
         "0.522079734218679",
         "0.5220943305074395",
         "1.4596288760437837e-05",
         "0.0006465880115600856"
        ],
        [
         "9",
         "EGR1",
         "0.5205409728321747",
         "0.5205402785920826",
         "-6.942400920806335e-07",
         "0.00021712473508985576"
        ],
        [
         "21",
         "LEF1",
         "0.5230924645465932",
         "0.5230772700570621",
         "-1.5194489531134003e-05",
         "0.0001953344008969901"
        ],
        [
         "22",
         "MAFG",
         "0.5155836985085523",
         "0.5155464573130885",
         "-3.724119546388849e-05",
         "0.00017219339497386629"
        ],
        [
         "2",
         "CGGBP1",
         "0.5148021995712699",
         "0.5146715779392379",
         "-0.00013062163203203525",
         "0.00011101937641135168"
        ],
        [
         "36",
         "TCF7L2",
         "0.5214510029674742",
         "0.5214138499875721",
         "-3.7152979902033145e-05",
         "2.0073017698119075e-05"
        ],
        [
         "5",
         "CREM",
         "0.5217969112492578",
         "0.5217463118466079",
         "-5.059940264984242e-05",
         "1.9964127039366596e-05"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 7
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf</th>\n",
       "      <th>checkpoint_0.pt</th>\n",
       "      <th>trained_model.pt</th>\n",
       "      <th>delta_auroc</th>\n",
       "      <th>delta_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MYC</td>\n",
       "      <td>0.522080</td>\n",
       "      <td>0.522094</td>\n",
       "      <td>1.459629e-05</td>\n",
       "      <td>0.000647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EGR1</td>\n",
       "      <td>0.520541</td>\n",
       "      <td>0.520540</td>\n",
       "      <td>-6.942401e-07</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LEF1</td>\n",
       "      <td>0.523092</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>-1.519449e-05</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MAFG</td>\n",
       "      <td>0.515584</td>\n",
       "      <td>0.515546</td>\n",
       "      <td>-3.724120e-05</td>\n",
       "      <td>0.000172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CGGBP1</td>\n",
       "      <td>0.514802</td>\n",
       "      <td>0.514672</td>\n",
       "      <td>-1.306216e-04</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>TCF7L2</td>\n",
       "      <td>0.521451</td>\n",
       "      <td>0.521414</td>\n",
       "      <td>-3.715298e-05</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CREM</td>\n",
       "      <td>0.521797</td>\n",
       "      <td>0.521746</td>\n",
       "      <td>-5.059940e-05</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tf  checkpoint_0.pt  trained_model.pt   delta_auroc  delta_mse\n",
       "25     MYC         0.522080          0.522094  1.459629e-05   0.000647\n",
       "9     EGR1         0.520541          0.520540 -6.942401e-07   0.000217\n",
       "21    LEF1         0.523092          0.523077 -1.519449e-05   0.000195\n",
       "22    MAFG         0.515584          0.515546 -3.724120e-05   0.000172\n",
       "2   CGGBP1         0.514802          0.514672 -1.306216e-04   0.000111\n",
       "36  TCF7L2         0.521451          0.521414 -3.715298e-05   0.000020\n",
       "5     CREM         0.521797          0.521746 -5.059940e-05   0.000020"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RN117\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tf",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "checkpoint_0.pt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trained_model.pt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_auroc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_mse",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "929f718b-97de-4527-be0f-643ca1d2df56",
       "rows": [
        [
         "58",
         "MYC",
         "0.534499824000013",
         "0.5343954602723102",
         "-0.00010436372770272762",
         "0.0006465880115600856"
        ],
        [
         "52",
         "EGR1",
         "0.5294162316870565",
         "0.5294054447899031",
         "-1.0786897153391983e-05",
         "0.00021712473508985576"
        ],
        [
         "55",
         "LEF1",
         "0.5338745594157663",
         "0.5337882419174677",
         "-8.631749829868252e-05",
         "0.0001953344008969901"
        ],
        [
         "56",
         "MAFG",
         "0.5295990566776192",
         "0.5291002806045931",
         "-0.0004987760730260637",
         "0.00017219339497386629"
        ],
        [
         "63",
         "TCF7L2",
         "0.5188109876738769",
         "0.5187140351295612",
         "-9.695254431574263e-05",
         "2.0073017698119075e-05"
        ],
        [
         "51",
         "CREM",
         "0.5312313807662857",
         "0.5312010958099465",
         "-3.028495633927708e-05",
         "1.9964127039366596e-05"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf</th>\n",
       "      <th>checkpoint_0.pt</th>\n",
       "      <th>trained_model.pt</th>\n",
       "      <th>delta_auroc</th>\n",
       "      <th>delta_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>MYC</td>\n",
       "      <td>0.534500</td>\n",
       "      <td>0.534395</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>0.000647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>EGR1</td>\n",
       "      <td>0.529416</td>\n",
       "      <td>0.529405</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>LEF1</td>\n",
       "      <td>0.533875</td>\n",
       "      <td>0.533788</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>MAFG</td>\n",
       "      <td>0.529599</td>\n",
       "      <td>0.529100</td>\n",
       "      <td>-0.000499</td>\n",
       "      <td>0.000172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>TCF7L2</td>\n",
       "      <td>0.518811</td>\n",
       "      <td>0.518714</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>CREM</td>\n",
       "      <td>0.531231</td>\n",
       "      <td>0.531201</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tf  checkpoint_0.pt  trained_model.pt  delta_auroc  delta_mse\n",
       "58     MYC         0.534500          0.534395    -0.000104   0.000647\n",
       "52    EGR1         0.529416          0.529405    -0.000011   0.000217\n",
       "55    LEF1         0.533875          0.533788    -0.000086   0.000195\n",
       "56    MAFG         0.529599          0.529100    -0.000499   0.000172\n",
       "63  TCF7L2         0.518811          0.518714    -0.000097   0.000020\n",
       "51    CREM         0.531231          0.531201    -0.000030   0.000020"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top = np.argsort(d)[-20:][::-1]\n",
    "top_tfs = [exp.tf_names[tf_id] for tf_id in top]\n",
    "    \n",
    "for gt in merged[\"gt\"].unique():\n",
    "    sub = merged[(merged[\"gt\"]==gt) & (merged[\"method\"]==\"Gradient Attribution\") & (merged[\"tf\"].isin(top_tfs))]\n",
    "    print(gt)\n",
    "    display(sub[[\"tf\",\"checkpoint_0.pt\",\"trained_model.pt\",\"delta_auroc\",\"delta_mse\"]].sort_values(\"delta_mse\", ascending=False))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
