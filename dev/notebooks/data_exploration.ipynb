{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9361a3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Expression / Accessibility Files =======\n",
      "\n",
      "scATAC-seq processed\n",
      "                      E7.5_REP1.AAACAGCCAAACCCTA  E7.5_REP1.AAACAGCCAGGAACTG  E7.5_REP1.AAACAGCCATCCTGAA  E7.5_REP1.AAACAGCCATGCTATG  E7.5_REP1.AAACATGCAATGAATG  E7.5_REP1.AAACATGCAATTATGC  \\\n",
      "peak_coord                                                                                                                                                                                     \n",
      "chr1:3142536-3143136                    0.693147                    0.000000                         0.0                         0.0                         0.0                         0.0   \n",
      "chr1:3553099-3553699                    0.000000                    0.693147                         0.0                         0.0                         0.0                         0.0   \n",
      "chr1:3584996-3585596                    0.000000                    0.000000                         0.0                         0.0                         0.0                         0.0   \n",
      "chr1:3619552-3620152                    0.000000                    0.000000                         0.0                         0.0                         0.0                         0.0   \n",
      "chr1:3636978-3637578                    0.000000                    0.000000                         0.0                         0.0                         0.0                         0.0   \n",
      "\n",
      "                      E7.5_REP1.AAACATGCACCTATAG  ...  E7.5_REP1.TTTGTGTTCTGTGAGT  E7.5_REP1.TTTGTTGGTACAATGT  E7.5_REP1.TTTGTTGGTCCTTCTC  E7.5_REP1.TTTGTTGGTCGCAAAC  E7.5_REP1.TTTGTTGGTTAAGCCA  \\\n",
      "peak_coord                                        ...                                                                                                                                               \n",
      "chr1:3142536-3143136                         0.0  ...                    0.000000                         0.0                         0.0                         0.0                    1.098612   \n",
      "chr1:3553099-3553699                         0.0  ...                    0.000000                         0.0                         0.0                         0.0                    0.000000   \n",
      "chr1:3584996-3585596                         0.0  ...                    0.000000                         0.0                         0.0                         0.0                    0.000000   \n",
      "chr1:3619552-3620152                         0.0  ...                    0.693147                         0.0                         0.0                         0.0                    0.000000   \n",
      "chr1:3636978-3637578                         0.0  ...                    0.000000                         0.0                         0.0                         0.0                    0.000000   \n",
      "\n",
      "                      E7.5_REP1.TTTGTTGGTTAATGAC  E7.5_REP1.TTTGTTGGTTACTTGC  \n",
      "peak_coord                                                                    \n",
      "chr1:3142536-3143136                         0.0                         0.0  \n",
      "chr1:3553099-3553699                         0.0                         0.0  \n",
      "chr1:3584996-3585596                         0.0                         0.0  \n",
      "chr1:3619552-3620152                         0.0                         0.0  \n",
      "chr1:3636978-3637578                         0.0                         0.0  \n",
      "\n",
      "[5 rows x 7411 columns]\n",
      "(57324, 7411)\n",
      "\n",
      "scRNA-seq processed\n",
      "               E7.5_REP1.AAACAGCCAAACCCTA  E7.5_REP1.AAACAGCCAGGAACTG  E7.5_REP1.AAACAGCCATCCTGAA  E7.5_REP1.AAACAGCCATGCTATG  E7.5_REP1.AAACATGCAATGAATG  E7.5_REP1.AAACATGCAATTATGC  \\\n",
      "0610009E02RIK                    0.000000                         0.0                         0.0                         0.0                    0.000000                         0.0   \n",
      "0610010F05RIK                    0.279204                         0.0                         0.0                         0.0                    0.649935                         0.0   \n",
      "0610040J01RIK                    0.279204                         0.0                         0.0                         0.0                    0.649935                         0.0   \n",
      "1010001N08RIK                    0.000000                         0.0                         0.0                         0.0                    0.000000                         0.0   \n",
      "1110046J04RIK                    0.000000                         0.0                         0.0                         0.0                    0.000000                         0.0   \n",
      "\n",
      "               E7.5_REP1.AAACATGCACCTATAG  ...  E7.5_REP1.TTTGTGTTCTGTGAGT  E7.5_REP1.TTTGTTGGTACAATGT  E7.5_REP1.TTTGTTGGTCCTTCTC  E7.5_REP1.TTTGTTGGTCGCAAAC  E7.5_REP1.TTTGTTGGTTAAGCCA  \\\n",
      "0610009E02RIK                         0.0  ...                    0.000000                         0.0                         0.0                    0.000000                    0.000000   \n",
      "0610010F05RIK                         0.0  ...                    1.632884                         0.0                         0.0                    0.000000                    0.000000   \n",
      "0610040J01RIK                         0.0  ...                    0.000000                         0.0                         0.0                    0.482332                    0.690533   \n",
      "1010001N08RIK                         0.0  ...                    0.000000                         0.0                         0.0                    0.000000                    0.000000   \n",
      "1110046J04RIK                         0.0  ...                    0.000000                         0.0                         0.0                    0.000000                    0.000000   \n",
      "\n",
      "               E7.5_REP1.TTTGTTGGTTAATGAC  E7.5_REP1.TTTGTTGGTTACTTGC  \n",
      "0610009E02RIK                         0.0                    0.000000  \n",
      "0610010F05RIK                         0.0                    0.000000  \n",
      "0610040J01RIK                         0.0                    0.822866  \n",
      "1010001N08RIK                         0.0                    0.277067  \n",
      "1110046J04RIK                         0.0                    0.000000  \n",
      "\n",
      "[5 rows x 7411 columns]\n",
      "(2925, 7411)\n",
      "\n",
      "scATAC pseudobulk\n",
      "                      E7.5_REP1.AAACAGCCAAACCCTA  E7.5_REP1.AAACAGCCAGGAACTG  E7.5_REP1.AAACAGCCATCCTGAA  E7.5_REP1.AAACAGCCATGCTATG  E7.5_REP1.AAACATGCAATGAATG  E7.5_REP1.AAACATGCAATTATGC  \\\n",
      "peak_coord                                                                                                                                                                                     \n",
      "chr1:3142536-3143136                    0.093238                    0.000000                         0.0                    0.040567                    0.000000                    0.025242   \n",
      "chr1:3553099-3553699                    0.035439                    0.199449                         0.0                    0.360751                    0.000000                    0.000000   \n",
      "chr1:3584996-3585596                    0.000000                    0.000000                         0.0                    0.000000                    0.028881                    0.015926   \n",
      "chr1:3619552-3620152                    0.000000                    0.109861                         0.0                    0.306720                    0.000000                    0.062222   \n",
      "chr1:3636978-3637578                    0.000000                    0.034657                         0.0                    0.059429                    0.000000                    0.000000   \n",
      "\n",
      "                      E7.5_REP1.AAACATGCACCTATAG  ...  E7.5_REP1.TTTGTGTTCTGTGAGT  E7.5_REP1.TTTGTTGGTACAATGT  E7.5_REP1.TTTGTTGGTCCTTCTC  E7.5_REP1.TTTGTTGGTCGCAAAC  E7.5_REP1.TTTGTTGGTTAAGCCA  \\\n",
      "peak_coord                                        ...                                                                                                                                               \n",
      "chr1:3142536-3143136                    0.000000  ...                    0.000000                     0.00000                    0.000000                    0.030894                    0.093371   \n",
      "chr1:3553099-3553699                    0.000000  ...                    0.288973                     0.03662                    0.054931                    0.000000                    0.000000   \n",
      "chr1:3584996-3585596                    0.000000  ...                    0.000000                     0.03662                    0.000000                    0.000000                    0.047713   \n",
      "chr1:3619552-3620152                    0.074657  ...                    0.242267                     0.00000                    0.000000                    0.000000                    0.046686   \n",
      "chr1:3636978-3637578                    0.028881  ...                    0.000000                     0.00000                    0.000000                    0.000000                    0.000000   \n",
      "\n",
      "                      E7.5_REP1.TTTGTTGGTTAATGAC  E7.5_REP1.TTTGTTGGTTACTTGC  \n",
      "peak_coord                                                                    \n",
      "chr1:3142536-3143136                    0.000000                         0.0  \n",
      "chr1:3553099-3553699                    0.032312                         0.0  \n",
      "chr1:3584996-3585596                    0.032312                         0.0  \n",
      "chr1:3619552-3620152                    0.032312                         0.0  \n",
      "chr1:3636978-3637578                    0.000000                         0.0  \n",
      "\n",
      "[5 rows x 7411 columns]\n",
      "(57324, 7411)\n",
      "\n",
      "scRNA pseudobulk\n",
      "               E7.5_REP1.AAACAGCCAAACCCTA  E7.5_REP1.AAACAGCCAGGAACTG  E7.5_REP1.AAACAGCCATCCTGAA  E7.5_REP1.AAACAGCCATGCTATG  E7.5_REP1.AAACATGCAATGAATG  E7.5_REP1.AAACATGCAATTATGC  \\\n",
      "0610009E02RIK                    0.029195                    0.040145                    0.000000                    0.100867                    0.232718                    0.000000   \n",
      "0610010F05RIK                    0.280652                    0.323722                    0.000010                    0.210703                    0.153686                    0.123757   \n",
      "0610040J01RIK                    0.387565                    0.000000                    0.085814                    0.100423                    0.099137                    0.085260   \n",
      "1010001N08RIK                    0.033485                    0.000000                    0.056642                    0.000000                    0.000000                    0.066047   \n",
      "1110046J04RIK                    0.000000                    0.000000                    0.000000                    0.000000                    0.024284                    0.059800   \n",
      "\n",
      "               E7.5_REP1.AAACATGCACCTATAG  ...  E7.5_REP1.TTTGTGTTCTGTGAGT  E7.5_REP1.TTTGTTGGTACAATGT  E7.5_REP1.TTTGTTGGTCCTTCTC  E7.5_REP1.TTTGTTGGTCGCAAAC  E7.5_REP1.TTTGTTGGTTAAGCCA  \\\n",
      "0610009E02RIK                    0.000000  ...                    0.084049                    0.021284                    0.190455                    0.026778                    0.013361   \n",
      "0610010F05RIK                    0.042688  ...                    0.521917                    0.249322                    0.042369                    0.284674                    0.187651   \n",
      "0610040J01RIK                    0.036352  ...                    0.051176                    0.036209                    0.028068                    0.606975                    0.596446   \n",
      "1010001N08RIK                    0.000000  ...                    0.000000                    0.015728                    0.096709                    0.025387                    0.066247   \n",
      "1110046J04RIK                    0.040549  ...                    0.000000                    0.000000                    0.000000                    0.000000                    0.000000   \n",
      "\n",
      "               E7.5_REP1.TTTGTTGGTTAATGAC  E7.5_REP1.TTTGTTGGTTACTTGC  \n",
      "0610009E02RIK                    0.025250                    0.000000  \n",
      "0610010F05RIK                    0.268597                    0.325537  \n",
      "0610040J01RIK                    0.000000                    0.828459  \n",
      "1010001N08RIK                    0.016817                    0.013720  \n",
      "1110046J04RIK                    0.000000                    0.000000  \n",
      "\n",
      "[5 rows x 7411 columns]\n",
      "(2925, 7411)\n",
      "======= Calculated Information Files =======\n",
      "\n",
      "Sliding Window\n",
      "    TF               peak_id  sliding_window_score\n",
      "0  AHR  chr1:3142536-3143136                  -0.0\n",
      "1  AHR  chr1:3553099-3553699                  -0.0\n",
      "2  AHR  chr1:3584996-3585596                  -0.0\n",
      "3  AHR  chr1:3619552-3620152                  -0.0\n",
      "4  AHR  chr1:3636978-3637578                  -0.0\n",
      "(237591400, 3)\n",
      "\n",
      "Peak to Gene Distance\n",
      "      peak_chr  peak_start   peak_end                    peak_id gene_chr  gene_start   gene_end target_id  TSS_dist  TSS_dist_score\n",
      "23686     chr5   146230649  146231249   chr5:146230649-146231249     chr5   146231249  146231249      CDK8         0          1.0000\n",
      "22667     chr5   113772200  113772800   chr5:113772200-113772800     chr5   113772800  113772800      ISCU         0          1.0000\n",
      "10279    chr15    76080271   76080871    chr15:76080271-76080871    chr15    76080870   76080870     PUF60         1          0.9998\n",
      "6259     chr11   116130529  116131129  chr11:116130529-116131129    chr11   116131128  116131128    TRIM65         1          0.9998\n",
      "25458     chr6   149140914  149141514   chr6:149140914-149141514     chr6   149141512  149141512   ETFBKMT         2          0.9996\n",
      "(31182, 10)\n",
      "\n",
      "Gene TSS Location\n",
      "                      0     1     2         3\n",
      "0  chr4_GL456350_random  1095  1095    CCL21B\n",
      "1  chr4_GL456350_random  1131  1131   GM13304\n",
      "2  chr4_JH584294_random  1717  1717    GM2506\n",
      "3  chr4_JH584294_random  3059  3059   GM13306\n",
      "4  chr4_JH584292_random  3535  3535  VMN2R122\n",
      "(25120, 4)\n",
      "\n",
      "Peak Location\n",
      "      0        1        2                     3\n",
      "0  chr1  3142536  3143136  chr1:3142536-3143136\n",
      "1  chr1  3553099  3553699  chr1:3553099-3553699\n",
      "2  chr1  3584996  3585596  chr1:3584996-3585596\n",
      "3  chr1  3619552  3620152  chr1:3619552-3620152\n",
      "4  chr1  3636978  3637578  chr1:3636978-3637578\n",
      "(57324, 4)\n",
      "======= Prior Knowledge Networks =======\n",
      "\n",
      "KEGG\n",
      "     TF       TG  kegg_signal  kegg_n_pathways kegg_pathways\n",
      "0  CMAH     NANS            0                1      mmu00541\n",
      "1  CMAH      NPL            0                1      mmu00541\n",
      "2  CMAH     CMAS            0                1      mmu00541\n",
      "3  CMAH   CYB5R3            0                1      mmu00541\n",
      "4  CMAH  GM57850            0                1      mmu00541\n",
      "(90610, 5)\n",
      "\n",
      "STRING\n",
      "      TF     TG  string_neighborhood_score  string_fusion_score  string_cooccurence_score  string_coexpression_score  string_experimental_score  string_database_score  string_textmining_score  \\\n",
      "0  Gnai3   Rgs4                          0                    0                         0                         56                        594                    500                      492   \n",
      "1  Gnai3   Drd2                          0                    0                         0                          0                        604                    900                      301   \n",
      "2  Gnai3   Gnb4                          0                    0                         0                        151                        639                    650                      310   \n",
      "3  Gnai3   Rgs3                          0                    0                         0                         90                        271                    900                      425   \n",
      "4  Gnai3  Gnai1                          0                    0                        47                          0                          0                    900                       50   \n",
      "\n",
      "   string_combined_score  \n",
      "0                  0.889  \n",
      "1                  0.969  \n",
      "2                  0.916  \n",
      "3                  0.956  \n",
      "4                  0.901  \n",
      "(248848, 10)\n",
      "\n",
      "TRRUST\n",
      "     TF      TG  trrust_sign trrust_regulation trrust_pmids  trrust_support_n\n",
      "0  AATF    BAK1            0           Unknown     22983126                 1\n",
      "1  AATF     BAX            0           Unknown     22983126                 1\n",
      "2  AATF    BBC3            0           Unknown     22983126                 1\n",
      "3  AATF  CDKN1A            0           Unknown     21317046                 1\n",
      "4  AATF    TPT1            1        Activation     17157788                 1\n",
      "(6490, 6)\n",
      "======= Ground Truth Datasets =======\n",
      "\n",
      "ChIP Atlas\n",
      "   gene_id               peak_id\n",
      "0    Smad4  chr1:3003564-3003922\n",
      "1     Ctcf  chr1:3012605-3012815\n",
      "2     Ctcf  chr1:3012635-3012824\n",
      "3  Epitope  chr1:3031387-3031654\n",
      "4    Smad4  chr1:3031454-3031677\n",
      "(7624391, 2)\n",
      "\n",
      "Beeline\n",
      "  Gene1     Gene2\n",
      "0  ADNP  MIS18BP1\n",
      "1  ADNP      EXD1\n",
      "2  ADNP      CHP1\n",
      "3  ADNP     OSCAR\n",
      "4  ADNP    NDUFA3\n",
      "(977841, 2)\n",
      "\n",
      "ChIP-Atlas TF-peak-TG\n",
      "  source_id               peak_id target_id  distance\n",
      "0     SMAD4  chr1:3003564-3003922      XKR4    667576\n",
      "1      CTCF  chr1:3012605-3012815      XKR4    658683\n",
      "2      CTCF  chr1:3012635-3012824      XKR4    658674\n",
      "3   EPITOPE  chr1:3031387-3031654      XKR4    639844\n",
      "4     SMAD4  chr1:3031454-3031677      XKR4    639821\n",
      "(7734466, 4)\n",
      "\n",
      "ChIP-Atlas Beeline Shared Peaks\n",
      "  source_id target_id  chrom      start        end\n",
      "0     ASCL1     ACACB   chr5  114173037  114173222\n",
      "1     ASCL1     ACACB   chr5  114173103  114173157\n",
      "2     ASCL1    BTBD17  chr11  114795327  114795552\n",
      "3     ASCL1    BTBD17  chr11  114795386  114795436\n",
      "4     ASCL1      DLL3   chr7   28302269   28302413\n",
      "(1721462, 5)\n",
      "\n",
      "BEAR-GRN\n",
      "  Source Target\n",
      "0   AFF3   XKR4\n",
      "1  BTAF1   XKR4\n",
      "2   CBX7   XKR4\n",
      "3   CDK8   XKR4\n",
      "4   CTCF   XKR4\n",
      "(1018410, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 15)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "# ----- Expression / Accessibility Files -----\n",
    "rna_file = \"data/raw/mESC_no_scale_linear/E7.5_rep1/scRNA_seq_processed.parquet\"\n",
    "atac_file = \"data/raw/mESC_no_scale_linear/E7.5_rep1/scATAC_seq_processed.parquet\"\n",
    "\n",
    "rna_pseudobulk_file = \"data/raw/mESC_no_scale_linear/E7.5_rep1/TG_pseudobulk.parquet\"\n",
    "atac_pseudobulk_file = \"data/raw/mESC_no_scale_linear/E7.5_rep1/RE_pseudobulk.parquet\"\n",
    "\n",
    "# ----- Calculated Information Files -----\n",
    "sliding_window_file = \"data/processed/mESC_no_scale_linear/E7.5_rep1/sliding_window.parquet\"\n",
    "peak_to_gene_dist_file = \"data/processed/mESC_no_scale_linear/E7.5_rep1/peak_to_gene_dist.parquet\"\n",
    "gene_tss_location_file = \"data/genome_data/genome_annotation/mm10/gene_tss.bed\"\n",
    "peak_location_file = \"data/processed/mESC_no_scale_linear/E7.5_rep1/peaks.bed\"\n",
    "\n",
    "# ----- Prior Knowledge Networks -----\n",
    "kegg_pkn_file = \"data/prior_knowledge_network_data/mm10/KEGG/kegg_mm10_pkn.csv\"\n",
    "string_pkn_file = \"data/prior_knowledge_network_data/mm10/STRING/string_mm10_pkn.csv\"\n",
    "trrust_pkn_file = \"data/prior_knowledge_network_data/mm10/TRRUST/trrust_mm10_pkn.csv\"\n",
    "\n",
    "# ----- Ground Truth Datasets -----\n",
    "chip_atlas_raw_file = \"data/ground_truth_files/chipatlas_mESC.csv\"\n",
    "chip_atlas_tf_peak_tg_file = \"data/ground_truth_files/chip_atlas_tf_peak_tg_dist.csv\"\n",
    "beeline_raw_file = \"data/ground_truth_files/mESC_beeline_ChIP-seq.csv\"\n",
    "chip_atlas_beeline_shared_peaks_file = \"data/ground_truth_files/chipatlas_beeline_mESC_shared_edges.csv\"\n",
    "bear_grn_ground_truth_file = \"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.GRN_BENCHMARKING.MOELLER/testing_bear_grn/GROUND.TRUTHS/filtered_RN111_and_RN112_mESC_E7.5_rep1.tsv\"\n",
    "\n",
    "\n",
    "atac_df = pd.read_parquet(atac_file)\n",
    "rna_df = pd.read_parquet(rna_file)\n",
    "\n",
    "atac_pseudobulk_df = pd.read_parquet(atac_pseudobulk_file)\n",
    "rna_pseudobulk_df = pd.read_parquet(rna_pseudobulk_file)\n",
    "\n",
    "\n",
    "sliding_window_df = pd.read_parquet(sliding_window_file)\n",
    "peak_to_gene_dist_df = pd.read_parquet(peak_to_gene_dist_file)\n",
    "gene_tss_location_df = pd.read_csv(gene_tss_location_file, sep=\"\\t\", header=None)\n",
    "peak_location_df = pd.read_csv(peak_location_file, sep=\"\\t\", header=None)\n",
    "\n",
    "kegg_pkn_df = pd.read_csv(kegg_pkn_file)\n",
    "string_pkn_df = pd.read_csv(string_pkn_file)\n",
    "trrust_pkn_df = pd.read_csv(trrust_pkn_file)\n",
    "\n",
    "chip_atlas_df = pd.read_csv(chip_atlas_raw_file)\n",
    "beeline_df = pd.read_csv(beeline_raw_file)\n",
    "chip_atlas_tf_peak_tg_df = pd.read_csv(chip_atlas_tf_peak_tg_file)\n",
    "chip_atlas_beeline_shared_peaks_df = pd.read_csv(chip_atlas_beeline_shared_peaks_file)\n",
    "bear_grn_ground_truth_df = pd.read_csv(bear_grn_ground_truth_file, sep=\"\\t\")\n",
    "\n",
    "print(\"======= Expression / Accessibility Files =======\")\n",
    "print(\"\\nscATAC-seq processed\")\n",
    "print(atac_df.head())\n",
    "print(atac_df.shape)\n",
    "\n",
    "print(\"\\nscRNA-seq processed\")\n",
    "print(rna_df.head())\n",
    "print(rna_df.shape)\n",
    "\n",
    "print(\"\\nscATAC pseudobulk\")\n",
    "print(atac_pseudobulk_df.head())\n",
    "print(atac_pseudobulk_df.shape)\n",
    "\n",
    "print(\"\\nscRNA pseudobulk\")\n",
    "print(rna_pseudobulk_df.head())\n",
    "print(rna_pseudobulk_df.shape)\n",
    "\n",
    "print(\"======= Calculated Information Files =======\")\n",
    "print(\"\\nSliding Window\")\n",
    "print(sliding_window_df.head())\n",
    "print(sliding_window_df.shape)\n",
    "\n",
    "print(\"\\nPeak to Gene Distance\")\n",
    "print(peak_to_gene_dist_df.head())\n",
    "print(peak_to_gene_dist_df.shape)\n",
    "\n",
    "print(\"\\nGene TSS Location\")\n",
    "print(gene_tss_location_df.head())\n",
    "print(gene_tss_location_df.shape)\n",
    "\n",
    "print(\"\\nPeak Location\")\n",
    "print(peak_location_df.head())\n",
    "print(peak_location_df.shape)\n",
    "\n",
    "print(\"======= Prior Knowledge Networks =======\")\n",
    "print(\"\\nKEGG\")\n",
    "print(kegg_pkn_df.head())\n",
    "print(kegg_pkn_df.shape)\n",
    "\n",
    "print(\"\\nSTRING\")\n",
    "print(string_pkn_df.head())\n",
    "print(string_pkn_df.shape)\n",
    "\n",
    "print(\"\\nTRRUST\")\n",
    "print(trrust_pkn_df.head())\n",
    "print(trrust_pkn_df.shape)\n",
    "\n",
    "print(\"======= Ground Truth Datasets =======\")\n",
    "print(\"\\nChIP Atlas\")\n",
    "print(chip_atlas_df.head())\n",
    "print(chip_atlas_df.shape)\n",
    "\n",
    "print(\"\\nBeeline\")\n",
    "print(beeline_df.head())\n",
    "print(beeline_df.shape)\n",
    "\n",
    "print(\"\\nChIP-Atlas TF-peak-TG\")\n",
    "print(chip_atlas_tf_peak_tg_df.head())\n",
    "print(chip_atlas_tf_peak_tg_df.shape)\n",
    "\n",
    "print(\"\\nChIP-Atlas Beeline Shared Peaks\")\n",
    "print(chip_atlas_beeline_shared_peaks_df.head())\n",
    "print(chip_atlas_beeline_shared_peaks_df.shape)\n",
    "\n",
    "print(\"\\nBEAR-GRN\")\n",
    "print(bear_grn_ground_truth_df.head())\n",
    "print(bear_grn_ground_truth_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8b083d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEELINE\n",
      "Edges: 977841\n",
      "\n",
      "KEGG\n",
      "Edges: 90498\n",
      "\n",
      "Overlapping BEELINE x KEGG Edges: \n",
      "394\n",
      "\n",
      "ChIP-Atlas TF-peak-TG\n",
      "Edges: 771359\n",
      "\n",
      "Overlapping KEGG x ChIP-Atlas TF-peak-TG Edges: \n",
      "306\n"
     ]
    }
   ],
   "source": [
    "beeline_df_named = beeline_df.rename(columns={\"Gene1\":\"TF\", \"Gene2\":\"TG\"})\n",
    "kegg_sub = kegg_pkn_df[[\"TF\",\"TG\"]].drop_duplicates()\n",
    "chip_atlas_tf_peak_sub = chip_atlas_tf_peak_tg_df.rename(columns={\"source_id\":\"TF\", \"target_id\":\"TG\"})[[\"TF\",\"TG\"]].drop_duplicates()\n",
    "\n",
    "beeline_df_kegg_merged = pd.merge(beeline_df_named, kegg_sub, how=\"inner\")\n",
    "kegg_chip_atlas_tf_peak_merged = pd.merge(kegg_sub, chip_atlas_tf_peak_sub, how=\"inner\")\n",
    "\n",
    "print(f\"BEELINE\")\n",
    "print(f\"Edges: {len(beeline_df_named)}\")\n",
    "\n",
    "print(f\"\\nKEGG\")\n",
    "print(f\"Edges: {len(kegg_sub)}\")\n",
    "\n",
    "print(f\"\\nOverlapping BEELINE x KEGG Edges: \\n{len(beeline_df_kegg_merged)}\")\n",
    "\n",
    "print(f\"\\nChIP-Atlas TF-peak-TG\")\n",
    "print(f\"Edges: {len(chip_atlas_tf_peak_sub)}\")\n",
    "\n",
    "print(f\"\\nOverlapping KEGG x ChIP-Atlas TF-peak-TG Edges: \\n{len(kegg_chip_atlas_tf_peak_merged)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2736e26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 1: BUILDING MASTER FEATURE DATAFRAME\n",
      "================================================================================\n",
      "\n",
      "Starting with 129,249,390 TF-peak-gene triplets\n",
      "  peak_chrom  peak_start   peak_end                   peak_id gene_chrom  gene_start   gene_end    TG  tss_distance  tss_distance_score    TF  sliding_window_score  is_chip_positive\n",
      "0       chr5   146230649  146231249  chr5:146230649-146231249       chr5   146231249  146231249  CDK8             0                 1.0   AHR              0.952084             False\n",
      "1       chr5   146230649  146231249  chr5:146230649-146231249       chr5   146231249  146231249  CDK8             0                 1.0  ALX1             -0.000000             False\n",
      "2       chr5   146230649  146231249  chr5:146230649-146231249       chr5   146231249  146231249  CDK8             0                 1.0  ALX1             -0.000000             False\n",
      "3       chr5   146230649  146231249  chr5:146230649-146231249       chr5   146231249  146231249  CDK8             0                 1.0  ALX1             -0.000000             False\n",
      "4       chr5   146230649  146231249  chr5:146230649-146231249       chr5   146231249  146231249  CDK8             0                 1.0  ALX1             -0.000000             False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Create Master Feature Dataframe\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 1: BUILDING MASTER FEATURE DATAFRAME\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Start with TF-peak-gene mappings\n",
    "feature_df = pd.read_parquet(\"data/processed_for_modeling/feature_dataframe_with_labels.parquet\")\n",
    "print(f\"\\nStarting with {len(feature_df):,} TF-peak-gene triplets\")\n",
    "print(feature_df.head())\n",
    "\n",
    "# Standardize column names\n",
    "feature_df = feature_df.rename(columns={\n",
    "    'source_id': 'TF',\n",
    "    'target_id': 'gene_name',\n",
    "    'distance': 'tss_distance'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa2410de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 2: ADDING GENE & TF EXPRESSION\n",
      "================================================================================\n",
      "\n",
      "Calculated mean expression for 2925 genes\n",
      "Target gene expression: 15,183,135 non-null\n",
      "TF expression: 58,809,252 non-null\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Add Mean Gene Expression and TF Expression\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 2: ADDING GENE & TF EXPRESSION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculate mean expression across all cells\n",
    "mean_rna_expr = rna_pseudobulk_df.mean(axis=1)\n",
    "print(f\"\\nCalculated mean expression for {len(mean_rna_expr)} genes\")\n",
    "\n",
    "# Add target gene expression\n",
    "feature_df['mean_target_expression'] = feature_df['TG'].map(mean_rna_expr)\n",
    "print(f\"Target gene expression: {feature_df['mean_target_expression'].notna().sum():,} non-null\")\n",
    "\n",
    "# Add TF expression\n",
    "feature_df['mean_tf_expression'] = feature_df['TF'].map(mean_rna_expr)\n",
    "print(f\"TF expression: {feature_df['mean_tf_expression'].notna().sum():,} non-null\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7406d063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 3: ADDING PEAK ACCESSIBILITY\n",
      "================================================================================\n",
      "\n",
      "Calculated mean accessibility for 57324 peaks\n",
      "Peak accessibility: 129,249,390 non-null\n",
      "✓ Successfully matched 129,249,390 peaks\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Add Mean Peak Accessibility\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 3: ADDING PEAK ACCESSIBILITY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculate mean accessibility across all cells\n",
    "mean_peak_acc = atac_pseudobulk_df.mean(axis=1)\n",
    "print(f\"\\nCalculated mean accessibility for {len(mean_peak_acc)} peaks\")\n",
    "\n",
    "# The peak_id format should match between feature_df and atac_df\n",
    "feature_df['mean_peak_accessibility'] = feature_df['peak_id'].map(mean_peak_acc)\n",
    "print(f\"Peak accessibility: {feature_df['mean_peak_accessibility'].notna().sum():,} non-null\")\n",
    "\n",
    "# Check matching\n",
    "if feature_df['mean_peak_accessibility'].isna().all():\n",
    "    print(\"\\n⚠ WARNING: No peaks matched!\")\n",
    "    print(f\"Feature df peak example: {feature_df['peak_id'].iloc[0]}\")\n",
    "    print(f\"ATAC df peak example: {atac_pseudobulk_df.index[0]}\")\n",
    "else:\n",
    "    print(f\"✓ Successfully matched {feature_df['mean_peak_accessibility'].notna().sum():,} peaks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdb8e797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 4: CALCULATING PEAK-GENE CORRELATIONS\n",
      "================================================================================\n",
      "\n",
      "Calculating correlations on 100k sample (this takes a few minutes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Correlations: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100000/100000 [00:37<00:00, 2646.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlations calculated:\n",
      "  Pearson: 11,528 non-null\n",
      "  Spearman: 11,528 non-null\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Calculate Peak-Gene Correlations (SAMPLE FIRST)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 4: CALCULATING PEAK-GENE CORRELATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def calculate_peak_gene_correlation_fast(peak_id, gene_name, atac_df, rna_df):\n",
    "    \"\"\"Fast correlation calculation with error handling\"\"\"\n",
    "    try:\n",
    "        if peak_id not in atac_df.index or gene_name not in rna_df.index:\n",
    "            return np.nan, np.nan\n",
    "        \n",
    "        peak_acc = atac_df.loc[peak_id].values\n",
    "        gene_expr = rna_df.loc[gene_name].values\n",
    "        \n",
    "        # Remove zero variance cases\n",
    "        if peak_acc.std() == 0 or gene_expr.std() == 0:\n",
    "            return 0.0, 0.0\n",
    "        \n",
    "        pearson_corr, _ = pearsonr(peak_acc, gene_expr)\n",
    "        spearman_corr, _ = spearmanr(peak_acc, gene_expr)\n",
    "        \n",
    "        return pearson_corr, spearman_corr\n",
    "    except:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "# Sample 100k rows for testing correlation calculation\n",
    "print(\"\\nCalculating correlations on 100k sample (this takes a few minutes)...\")\n",
    "sample_size = min(100000, len(feature_df))\n",
    "feature_df_sample = feature_df.sample(n=sample_size, random_state=42).copy()\n",
    "\n",
    "correlations = []\n",
    "for idx, row in tqdm(feature_df_sample.iterrows(), total=len(feature_df_sample), desc=\"Correlations\"):\n",
    "    pearson, spearman = calculate_peak_gene_correlation_fast(\n",
    "        row['peak_id'], row['TG'], atac_pseudobulk_df, rna_pseudobulk_df\n",
    "    )\n",
    "    correlations.append({'pearson': pearson, 'spearman': spearman})\n",
    "\n",
    "corr_df = pd.DataFrame(correlations, index=feature_df_sample.index)\n",
    "feature_df_sample['peak_gene_corr_pearson'] = corr_df['pearson']\n",
    "feature_df_sample['peak_gene_corr_spearman'] = corr_df['spearman']\n",
    "\n",
    "print(f\"\\nCorrelations calculated:\")\n",
    "print(f\"  Pearson: {feature_df_sample['peak_gene_corr_pearson'].notna().sum():,} non-null\")\n",
    "print(f\"  Spearman: {feature_df_sample['peak_gene_corr_spearman'].notna().sum():,} non-null\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eafe2fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 4B: CALCULATING CONDITIONAL MUTUAL INFORMATION (robust)\n",
      "================================================================================\n",
      "\n",
      "Calculating CMI on 100k sample (robust & cached)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CMI:   0%|                                                                                                                                                                                                     | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CMI: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100000/100000 [01:29<00:00, 1118.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CMI features added:\n",
      "  Directness score: 3,849 non-null\n",
      "  Mean directness (ignoring NaNs): 0.041\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4B: CALCULATE CONDITIONAL MUTUAL INFORMATION (CMI) -- ROBUST + CACHED\n",
    "# ============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 4B: CALCULATING CONDITIONAL MUTUAL INFORMATION (robust)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ---------------------------\n",
    "# Helpers\n",
    "# ---------------------------\n",
    "def safe_qcut3(x: np.ndarray):\n",
    "    \"\"\"\n",
    "    Discretize into up to 3 bins robustly.\n",
    "    Falls back to equal-width bins or binary split if needed.\n",
    "    Returns:\n",
    "      disc: int array in {0,1,2} (or fewer classes), same length as x\n",
    "      valid_mask: boolean mask of finite entries used\n",
    "      n_bins: number of unique bins actually used\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    valid = np.isfinite(x)\n",
    "    xv = x[valid]\n",
    "    disc = np.full(x.shape, -1, dtype=int)\n",
    "\n",
    "    if xv.size < 5:\n",
    "        # Too few samples to make reliable bins -> all one bin\n",
    "        disc[valid] = 0\n",
    "        return disc, valid, 1\n",
    "\n",
    "    # Try quantile binning first\n",
    "    try:\n",
    "        qdisc = pd.qcut(xv, q=3, labels=False, duplicates='drop')\n",
    "        qdisc = np.asarray(qdisc, dtype=float)  # may contain NaN if duplicates dropped oddly\n",
    "        # If NaNs appeared due to duplicate edges, try equal-width bins\n",
    "        if np.isnan(qdisc).any():\n",
    "            raise ValueError(\"qcut produced NaNs\")\n",
    "        n_bins = int(np.unique(qdisc).size)\n",
    "        disc_vals = qdisc.astype(int)\n",
    "        disc[valid] = disc_vals\n",
    "        return disc, valid, n_bins\n",
    "    except Exception:\n",
    "        # Fallback: equal-width bins\n",
    "        x_min, x_max = np.nanmin(xv), np.nanmax(xv)\n",
    "        if not np.isfinite(x_min) or not np.isfinite(x_max) or x_max <= x_min:\n",
    "            disc[valid] = 0\n",
    "            return disc, valid, 1\n",
    "\n",
    "        # 3 equal-width bins, but we’ll compress empty bins out\n",
    "        edges = np.linspace(x_min, x_max, 4)  # 3 bins -> 4 edges\n",
    "        # Put maximum at last bin\n",
    "        b = np.clip(np.digitize(xv, edges[1:-1], right=False), 0, 2)\n",
    "        # Compress to contiguous labels 0..k-1\n",
    "        uniq = np.unique(b)\n",
    "        remap = {u: i for i, u in enumerate(uniq)}\n",
    "        b2 = np.array([remap[u] for u in b], dtype=int)\n",
    "        n_bins = len(uniq)\n",
    "        disc[valid] = b2\n",
    "        return disc, valid, n_bins\n",
    "\n",
    "def mi_no_nan(x_disc: np.ndarray, y_disc: np.ndarray, mask: np.ndarray):\n",
    "    \"\"\"MI on masked entries; returns np.nan if < 3 samples or < 2 unique per variable.\"\"\"\n",
    "    m = mask & (x_disc >= 0) & (y_disc >= 0)\n",
    "    if m.sum() < 3:\n",
    "        return np.nan\n",
    "    xd = x_disc[m]\n",
    "    yd = y_disc[m]\n",
    "    if np.unique(xd).size < 2 or np.unique(yd).size < 2:\n",
    "        return np.nan\n",
    "    return mutual_info_score(xd, yd)\n",
    "\n",
    "def compute_cmi_from_disc(tf_disc, peak_disc, gene_disc, min_state_count=5):\n",
    "    \"\"\"\n",
    "    Weighted average of MI(TF, Gene) within each peak state.\n",
    "    Returns (cmi, mi_tf_gene, directness).\n",
    "    \"\"\"\n",
    "    # Unconditional MI\n",
    "    mask_all = (tf_disc >= 0) & (gene_disc >= 0)\n",
    "    mi_tf_gene = mi_no_nan(tf_disc, gene_disc, mask_all)\n",
    "\n",
    "    # Conditional MI as weighted across peak states\n",
    "    states = np.unique(peak_disc[peak_disc >= 0])\n",
    "    weights = []\n",
    "    mis = []\n",
    "    for s in states:\n",
    "        m = (peak_disc == s) & (tf_disc >= 0) & (gene_disc >= 0)\n",
    "        if m.sum() >= min_state_count:\n",
    "            mi_s = mi_no_nan(tf_disc, gene_disc, m)\n",
    "            if np.isfinite(mi_s):\n",
    "                mis.append(mi_s)\n",
    "                weights.append(m.sum())\n",
    "\n",
    "    if len(mis) == 0:\n",
    "        return np.nan, mi_tf_gene, np.nan\n",
    "\n",
    "    weights = np.asarray(weights, dtype=float)\n",
    "    cmi = np.average(np.asarray(mis), weights=weights)\n",
    "\n",
    "    if not np.isfinite(mi_tf_gene) or mi_tf_gene <= 0:\n",
    "        directness = np.nan\n",
    "    else:\n",
    "        # 1 - (cond / uncond) ∈ (-inf, 1]; clip to [0,1] for interpretability\n",
    "        directness = float(1.0 - cmi / (mi_tf_gene + 1e-12))\n",
    "        directness = float(np.clip(directness, 0.0, 1.0))\n",
    "\n",
    "    return cmi, mi_tf_gene, directness\n",
    "\n",
    "# ---------------------------\n",
    "# Caches for discretized tracks\n",
    "# ---------------------------\n",
    "disc_cache_tf   = {}  # name -> (disc, valid_mask, n_bins)\n",
    "disc_cache_tg   = {}\n",
    "disc_cache_peak = {}\n",
    "\n",
    "def get_disc_from_cache(name, source_df, cache):\n",
    "    \"\"\"\n",
    "    name: row label to fetch from source_df.index\n",
    "    source_df: rows are entities (TF/TG/peak), columns are metacells\n",
    "    cache: dict for reuse\n",
    "    \"\"\"\n",
    "    v = cache.get(name)\n",
    "    if v is not None:\n",
    "        return v\n",
    "    if name not in source_df.index:\n",
    "        # Missing track → single bin all zeros\n",
    "        arr = np.zeros(source_df.shape[1], dtype=float)\n",
    "        disc, valid, n_bins = safe_qcut3(arr)\n",
    "        cache[name] = (disc, valid, n_bins)\n",
    "        return cache[name]\n",
    "    x = source_df.loc[name].to_numpy(dtype=float, copy=False)\n",
    "    disc, valid, n_bins = safe_qcut3(x)\n",
    "    cache[name] = (disc, valid, n_bins)\n",
    "    return cache[name]\n",
    "\n",
    "# ---------------------------\n",
    "# Main loop with caching\n",
    "# ---------------------------\n",
    "print(\"\\nCalculating CMI on 100k sample (robust & cached)...\")\n",
    "rows = []\n",
    "for idx, row in tqdm(feature_df_sample.iterrows(), total=len(feature_df_sample), desc=\"CMI\"):\n",
    "    tf_name   = row['TF']\n",
    "    tg_name   = row['TG']\n",
    "    peak_name = row['peak_id']\n",
    "\n",
    "    # Discretize (cached)\n",
    "    tf_disc, tf_valid, _     = get_disc_from_cache(tf_name,   rna_pseudobulk_df,  disc_cache_tf)\n",
    "    tg_disc, tg_valid, _     = get_disc_from_cache(tg_name,   rna_pseudobulk_df,  disc_cache_tg)\n",
    "    peak_disc, pk_valid, _   = get_disc_from_cache(peak_name, atac_pseudobulk_df, disc_cache_peak)\n",
    "\n",
    "    # Common valid mask (finite bins across all)\n",
    "    common = (tf_disc >= 0) & (tg_disc >= 0) & (peak_disc >= 0) & tf_valid & tg_valid & pk_valid\n",
    "\n",
    "    if common.sum() < 10:\n",
    "        rows.append({'cmi': np.nan, 'mi_tf_gene': np.nan, 'directness_score': np.nan})\n",
    "        continue\n",
    "\n",
    "    cmi, mi_tf_gene, directness = compute_cmi_from_disc(tf_disc, peak_disc, tg_disc, min_state_count=5)\n",
    "    rows.append({'cmi': cmi, 'mi_tf_gene': mi_tf_gene, 'directness_score': directness})\n",
    "\n",
    "cmi_df = pd.DataFrame(rows, index=feature_df_sample.index)\n",
    "feature_df_sample['cmi']              = cmi_df['cmi']\n",
    "feature_df_sample['mi_tf_gene']       = cmi_df['mi_tf_gene']\n",
    "feature_df_sample['directness_score'] = cmi_df['directness_score']\n",
    "\n",
    "print(f\"\\nCMI features added:\")\n",
    "non_null = feature_df_sample['directness_score'].notna().sum()\n",
    "print(f\"  Directness score: {non_null:,} non-null\")\n",
    "print(f\"  Mean directness (ignoring NaNs): {feature_df_sample['directness_score'].mean():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b26efe2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Promoters] Restricting to genes present in RNA matrix: 2707 rows\n",
      "[Promoters] Genes input: 2707\n",
      "[Promoters] With overlapping peaks: 384\n",
      "[Promoters] Using nearest peak within 5000 bp: 383\n",
      "[Promoters] Total mapped: 767\n",
      "Found promoter accessibility for 767 genes\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple, Optional\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "PROMOTER_WINDOW_BP   = 2000     # ± window around TSS\n",
    "FALLBACK_MAX_DIST_BP = 5000     # if no overlap, accept nearest peak within this distance (set None to disable)\n",
    "AGG_METHOD           = \"mean\"   # one of {\"mean\", \"max\", \"median\"}\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def _std_gene_name(name: str) -> str:\n",
    "    # match your RNA index casing logic\n",
    "    return str(name).upper()\n",
    "\n",
    "def _agg_rows(values: np.ndarray, method: str = \"mean\") -> np.ndarray:\n",
    "    if values.ndim == 1:\n",
    "        return values\n",
    "    if method == \"mean\":\n",
    "        return np.nanmean(values, axis=0)\n",
    "    if method == \"max\":\n",
    "        return np.nanmax(values, axis=0)\n",
    "    if method == \"median\":\n",
    "        return np.nanmedian(values, axis=0)\n",
    "    raise ValueError(f\"Unknown AGG_METHOD: {method}\")\n",
    "\n",
    "def _parse_atac_index(atac_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parse ATAC index like 'chr1:10000-10100' into columns: chrom, start, end.\n",
    "    Returns a DataFrame aligned 1:1 with atac_df.index.\n",
    "    \"\"\"\n",
    "    s = pd.Series(atac_df.index.astype(str), index=atac_df.index)\n",
    "    m = s.str.extract(r'^(?P<chrom>[^:]+):(?P<start>\\d+)-(?P<end>\\d+)$')\n",
    "    if m.isna().any().any():\n",
    "        bad = s[m.isna().any(axis=1)].head()\n",
    "        raise ValueError(\n",
    "            \"Some ATAC index entries could not be parsed as 'chr:start-end'. \"\n",
    "            f\"Examples:\\n{bad}\"\n",
    "        )\n",
    "    m[\"start\"] = m[\"start\"].astype(np.int64)\n",
    "    m[\"end\"]   = m[\"end\"].astype(np.int64)\n",
    "    m[\"i\"]     = np.arange(len(m), dtype=np.int64)  # row index into atac_pseudobulk_df.values\n",
    "    return m.set_index(atac_df.index)\n",
    "\n",
    "def _build_per_chrom_tables(peaks_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    peaks_df columns: chrom, start, end, i\n",
    "    Returns dict chrom -> dict with numpy arrays for fast boolean overlap tests.\n",
    "    \"\"\"\n",
    "    per = {}\n",
    "    for chrom, sub in peaks_df.groupby(\"chrom\", sort=False):\n",
    "        per[chrom] = {\n",
    "            \"start\": sub[\"start\"].to_numpy(np.int64, copy=False),\n",
    "            \"end\":   sub[\"end\"].to_numpy(np.int64, copy=False),\n",
    "            \"i\":     sub[\"i\"].to_numpy(np.int64, copy=False),\n",
    "        }\n",
    "    return per\n",
    "\n",
    "def build_gene_promoter_accessibility(\n",
    "    gene_tss_df: pd.DataFrame,\n",
    "    atac_pseudobulk_df: pd.DataFrame,\n",
    "    rna_index: Optional[pd.Index] = None,\n",
    "    promoter_window_bp: int = PROMOTER_WINDOW_BP,\n",
    "    fallback_max_dist: Optional[int] = FALLBACK_MAX_DIST_BP,\n",
    "    agg_method: str = AGG_METHOD,\n",
    "    verbose: bool = True,\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    gene_tss_df expected columns:\n",
    "      0: chrom (e.g., 'chr1')\n",
    "      1: TSS start (int)\n",
    "      2: TSS end   (int) -- often equal to start\n",
    "      3: gene name (string)\n",
    "    atac_pseudobulk_df index: 'chrom:start-end', rows=peaks, cols=metacells/samples\n",
    "    rna_index: if provided, only return promoters for genes present in RNA data.\n",
    "    \"\"\"\n",
    "    # 1) standardize TSS table columns & names\n",
    "    tss = gene_tss_df.copy()\n",
    "    tss = tss.rename(columns={0: \"chrom\", 1: \"start\", 2: \"end\", 3: \"gene\"})\n",
    "    tss[\"gene\"] = tss[\"gene\"].astype(str).map(_std_gene_name)\n",
    "    # TSS as the midpoint between [start, end] (often identical)\n",
    "    tss[\"tss\"] = ((tss[\"start\"].to_numpy(np.int64) + tss[\"end\"].to_numpy(np.int64)) // 2)\n",
    "\n",
    "    # (Optional) restrict to genes we care about (present in RNA matrix)\n",
    "    if rna_index is not None:\n",
    "        rna_genes = set(map(_std_gene_name, rna_index.astype(str)))\n",
    "        tss = tss[tss[\"gene\"].isin(rna_genes)]\n",
    "        if verbose:\n",
    "            print(f\"[Promoters] Restricting to genes present in RNA matrix: {len(tss)} rows\")\n",
    "\n",
    "    # 2) parse ATAC peaks into intervals\n",
    "    peaks = _parse_atac_index(atac_pseudobulk_df)  # chrom,start,end,i\n",
    "    per_chrom = _build_per_chrom_tables(peaks)\n",
    "    atac_vals = atac_pseudobulk_df.to_numpy(dtype=float)  # shape: [n_peaks, n_samples]\n",
    "\n",
    "    # 3) iterate genes, find overlapping peaks, aggregate signal\n",
    "    gene_promoter_acc = {}\n",
    "    n_total = len(tss)\n",
    "    n_overlapped = 0\n",
    "    n_fallback   = 0\n",
    "\n",
    "    for _, row in tss.iterrows():\n",
    "        chrom = row[\"chrom\"]\n",
    "        if chrom not in per_chrom:\n",
    "            continue  # no peaks on this contig\n",
    "        tss_pos = int(row[\"tss\"])\n",
    "        prom_start = max(0, tss_pos - promoter_window_bp)\n",
    "        prom_end   = tss_pos + promoter_window_bp\n",
    "\n",
    "        # Overlap condition: peak_start <= prom_end AND peak_end >= prom_start\n",
    "        starts = per_chrom[chrom][\"start\"]\n",
    "        ends   = per_chrom[chrom][\"end\"]\n",
    "        idx    = per_chrom[chrom][\"i\"]\n",
    "\n",
    "        mask_overlap = (starts <= prom_end) & (ends >= prom_start)\n",
    "        if mask_overlap.any():\n",
    "            n_overlapped += 1\n",
    "            peak_rows = idx[mask_overlap]\n",
    "            acc = _agg_rows(atac_vals[peak_rows, :], method=agg_method)\n",
    "            gene_promoter_acc[row[\"gene\"]] = acc\n",
    "            continue\n",
    "\n",
    "        # Fallback: nearest peak within distance\n",
    "        if fallback_max_dist is not None and starts.size > 0:\n",
    "            # distance from TSS to peak interval\n",
    "            # dist = 0 for overlapping intervals; otherwise min distance to edge\n",
    "            left_dist  = np.maximum(0, starts - tss_pos)\n",
    "            right_dist = np.maximum(0, tss_pos - ends)\n",
    "            dist = np.maximum(left_dist, right_dist)  # distance outside interval\n",
    "            j = int(np.argmin(dist))\n",
    "            if dist[j] <= fallback_max_dist:\n",
    "                n_fallback += 1\n",
    "                acc = atac_vals[idx[j], :]\n",
    "                gene_promoter_acc[row[\"gene\"]] = acc\n",
    "                continue\n",
    "        # else: no match for this gene\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[Promoters] Genes input: {n_total}\")\n",
    "        print(f\"[Promoters] With overlapping peaks: {n_overlapped}\")\n",
    "        if fallback_max_dist is not None:\n",
    "            print(f\"[Promoters] Using nearest peak within {fallback_max_dist} bp: {n_fallback}\")\n",
    "        print(f\"[Promoters] Total mapped: {len(gene_promoter_acc)}\")\n",
    "\n",
    "    return gene_promoter_acc\n",
    "\n",
    "# ----------------------------\n",
    "# Run it\n",
    "# ----------------------------\n",
    "# Standardize RNA index so keys match (same as _std_gene_name)\n",
    "rna_index_std = pd.Index(map(_std_gene_name, rna_pseudobulk_df.index.astype(str)))\n",
    "rna_pseudobulk_df_std = rna_pseudobulk_df.copy()\n",
    "rna_pseudobulk_df_std.index = rna_index_std\n",
    "\n",
    "gene_promoter_acc = build_gene_promoter_accessibility(\n",
    "    gene_tss_df=gene_tss_location_df,\n",
    "    atac_pseudobulk_df=atac_pseudobulk_df,\n",
    "    rna_index=rna_pseudobulk_df_std.index,\n",
    "    promoter_window_bp=2000,          # TSS ± 2kb\n",
    "    fallback_max_dist=5000,           # nearest if no overlap (optional)\n",
    "    agg_method=\"mean\",                # \"mean\" | \"max\" | \"median\"\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(f\"Found promoter accessibility for {len(gene_promoter_acc)} genes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b7119c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 4D: AGGREGATING MULTI-PEAK SIGNALS\n",
      "================================================================================\n",
      "\n",
      "Aggregating features per TF-gene pair...\n",
      "Found 82775 unique TF-gene pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82775/82775 [13:38<00:00, 101.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aggregated features added:\n",
      "  Max sliding window: 100,000\n",
      "  N peaks per pair: mean=1.5\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4D: MULTI-PEAK AGGREGATION PER TF-GENE PAIR\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 4D: AGGREGATING MULTI-PEAK SIGNALS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def aggregate_tf_gene_peaks(df, tf_name, gene_name):\n",
    "    \"\"\"\n",
    "    Aggregate features across all peaks linking a TF-gene pair.\n",
    "    \"\"\"\n",
    "    # Get all triplets for this TF-gene pair\n",
    "    mask = (df['TF'] == tf_name) & (df['TG'] == gene_name)\n",
    "    triplets = df[mask]\n",
    "    \n",
    "    if len(triplets) == 0:\n",
    "        return None\n",
    "    \n",
    "    agg_features = {\n",
    "        # Max sliding window (strongest binding)\n",
    "        'tf_gene_max_sliding_window': triplets['sliding_window_score'].max(),\n",
    "        \n",
    "        # Mean co-accessibility (consistency across peaks)\n",
    "        'tf_gene_mean_coacc': triplets['coacc_pearson'].mean(),\n",
    "        \n",
    "        # Number of peaks (multiplicity)\n",
    "        'tf_gene_n_peaks': len(triplets),\n",
    "        \n",
    "        # Mean directness (consensus)\n",
    "        'tf_gene_mean_directness': triplets['directness_score'].mean(),\n",
    "        'tf_gene_std_directness': triplets['directness_score'].std(),\n",
    "        \n",
    "        # Closest peak distance\n",
    "        'tf_gene_min_distance': triplets['tss_distance'].min(),\n",
    "        \n",
    "        # Peak spread (genomic distribution)\n",
    "        'tf_gene_distance_std': triplets['tss_distance'].std() if len(triplets) > 1 else 0,\n",
    "    }\n",
    "    \n",
    "    return agg_features\n",
    "\n",
    "# Create TF-gene pair aggregated features\n",
    "print(\"\\nAggregating features per TF-gene pair...\")\n",
    "tf_gene_pairs = feature_df_sample.groupby(['TF', 'TG']).size().reset_index()[['TF', 'TG']]\n",
    "print(f\"Found {len(tf_gene_pairs)} unique TF-gene pairs\")\n",
    "\n",
    "agg_features_list = []\n",
    "for _, row in tqdm(tf_gene_pairs.iterrows(), total=len(tf_gene_pairs), desc=\"Aggregating\"):\n",
    "    agg = aggregate_tf_gene_peaks(feature_df_sample, row['TF'], row['TG'])\n",
    "    if agg:\n",
    "        agg['TF'] = row['TF']\n",
    "        agg['TG'] = row['TG']\n",
    "        agg_features_list.append(agg)\n",
    "\n",
    "tf_gene_agg_df = pd.DataFrame(agg_features_list)\n",
    "\n",
    "# Merge back to feature_df_sample\n",
    "feature_df_sample = feature_df_sample.merge(\n",
    "    tf_gene_agg_df,\n",
    "    on=['TF', 'TG'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"\\nAggregated features added:\")\n",
    "print(f\"  Max sliding window: {feature_df_sample['tf_gene_max_sliding_window'].notna().sum():,}\")\n",
    "print(f\"  N peaks per pair: mean={feature_df_sample['tf_gene_n_peaks'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "89e1600e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 4E: CALCULATING TF-GENE SPECIFICITY\n",
      "================================================================================\n",
      "\n",
      "Calculating node degrees...\n",
      "\n",
      "Specificity features added:\n",
      "  Mean TF out-degree: 3632.9\n",
      "  Mean gene in-degree: 7.9\n",
      "  Mean pair specificity: 0.0006\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4E: TF-GENE SPECIFICITY (HUB PENALTY)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 4E: CALCULATING TF-GENE SPECIFICITY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Count edges per TF and per gene\n",
    "print(\"\\nCalculating node degrees...\")\n",
    "tf_out_degree = feature_df_sample.groupby('TF')['TG'].nunique().to_dict()\n",
    "gene_in_degree = feature_df_sample.groupby('TG')['TF'].nunique().to_dict()\n",
    "\n",
    "# Add specificity scores\n",
    "feature_df_sample['tf_out_degree'] = feature_df_sample['TF'].map(tf_out_degree)\n",
    "feature_df_sample['gene_in_degree'] = feature_df_sample['TG'].map(gene_in_degree)\n",
    "\n",
    "# Specificity = 1 / (degree + 1)\n",
    "feature_df_sample['tf_specificity'] = 1.0 / (feature_df_sample['tf_out_degree'] + 1)\n",
    "feature_df_sample['gene_specificity'] = 1.0 / (feature_df_sample['gene_in_degree'] + 1)\n",
    "feature_df_sample['pair_specificity'] = feature_df_sample['tf_specificity'] * feature_df_sample['gene_specificity']\n",
    "\n",
    "print(f\"\\nSpecificity features added:\")\n",
    "print(f\"  Mean TF out-degree: {feature_df_sample['tf_out_degree'].mean():.1f}\")\n",
    "print(f\"  Mean gene in-degree: {feature_df_sample['gene_in_degree'].mean():.1f}\")\n",
    "print(f\"  Mean pair specificity: {feature_df_sample['pair_specificity'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7ecd4b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 5: ADDING GROUND TRUTH LABELS\n",
      "================================================================================\n",
      "\n",
      "BEELINE shape: (977841, 2)\n",
      "BEELINE columns: ['Gene1', 'Gene2']\n",
      "  Gene1     Gene2\n",
      "0  ADNP  MIS18BP1\n",
      "1  ADNP      EXD1\n",
      "2  ADNP      CHP1\n",
      "3  ADNP     OSCAR\n",
      "4  ADNP    NDUFA3\n",
      "\n",
      "BEAR-GRN shape: (1018410, 2)\n",
      "BEAR-GRN columns: ['Source', 'Target']\n",
      "  Source Target\n",
      "0   AFF3   XKR4\n",
      "1  BTAF1   XKR4\n",
      "2   CBX7   XKR4\n",
      "3   CDK8   XKR4\n",
      "4   CTCF   XKR4\n",
      "\n",
      "BEELINE edges: 977,841\n",
      "BEAR-GRN edges: 1,015,666\n",
      "\n",
      "Overlapping edges: 955,516\n",
      "  97.7% of BEELINE in BEAR-GRN\n",
      "  94.1% of BEAR-GRN in BEELINE\n",
      "  Jaccard similarity: 92.05%\n",
      "\n",
      "Adding ground truth labels to feature dataframe...\n",
      "\n",
      "Ground truth statistics on sample:\n",
      "  Total edges: 100,000\n",
      "  BEELINE positives: 483 (0.483%)\n",
      "  BEAR-GRN positives: 556 (0.556%)\n",
      "  CHIP-ATLAS positives: 903 (0.903%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Add Ground Truth Labels\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 5: ADDING GROUND TRUTH LABELS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load ground truths\n",
    "beeline_df = pd.read_csv(beeline_raw_file)\n",
    "bear_grn_df = bear_grn_ground_truth_df.copy()\n",
    "\n",
    "print(f\"\\nBEELINE shape: {beeline_df.shape}\")\n",
    "print(f\"BEELINE columns: {beeline_df.columns.tolist()}\")\n",
    "print(beeline_df.head())\n",
    "\n",
    "print(f\"\\nBEAR-GRN shape: {bear_grn_df.shape}\")\n",
    "print(f\"BEAR-GRN columns: {bear_grn_df.columns.tolist()}\")\n",
    "print(bear_grn_df.head())\n",
    "\n",
    "# Create edge sets (TF, Target) tuples\n",
    "# Adjust column names based on what you see above\n",
    "def create_edge_set(df):\n",
    "    \"\"\"Create set of (TF, Target) tuples from dataframe\"\"\"\n",
    "    cols = df.columns.tolist()\n",
    "    if 'Gene1' in cols and 'Gene2' in cols:\n",
    "        edges = set(zip(df['Gene1'].str.upper(), df['Gene2'].str.upper()))\n",
    "    elif 'TF' in cols and 'Target' in cols:\n",
    "        edges = set(zip(df['TF'].str.upper(), df['Target'].str.upper()))\n",
    "    elif 'Source' in cols and 'Target' in cols:\n",
    "        edges = set(zip(df['Source'].str.upper(), df['Target'].str.upper()))\n",
    "    else:\n",
    "        # Assume first two columns\n",
    "        edges = set(zip(df.iloc[:, 0].str.upper(), df.iloc[:, 1].str.upper()))\n",
    "    return edges\n",
    "\n",
    "beeline_edges = create_edge_set(beeline_df)\n",
    "bear_edges = create_edge_set(bear_grn_df)\n",
    "chip_atlas_edges = create_edge_set(chip_atlas_tf_peak_sub)\n",
    "\n",
    "print(f\"\\nBEELINE edges: {len(beeline_edges):,}\")\n",
    "print(f\"BEAR-GRN edges: {len(bear_edges):,}\")\n",
    "\n",
    "# Overlap analysis\n",
    "overlap_edges = beeline_edges & bear_edges\n",
    "print(f\"\\nOverlapping edges: {len(overlap_edges):,}\")\n",
    "print(f\"  {len(overlap_edges)/len(beeline_edges)*100:.1f}% of BEELINE in BEAR-GRN\")\n",
    "print(f\"  {len(overlap_edges)/len(bear_edges)*100:.1f}% of BEAR-GRN in BEELINE\")\n",
    "print(f\"  Jaccard similarity: {len(overlap_edges)/len(beeline_edges | bear_edges)*100:.2f}%\")\n",
    "\n",
    "# Add labels to feature dataframe\n",
    "print(\"\\nAdding ground truth labels to feature dataframe...\")\n",
    "feature_df_sample['is_beeline_positive'] = feature_df_sample.apply(\n",
    "    lambda row: (row['TF'].upper(), row['TG'].upper()) in beeline_edges, \n",
    "    axis=1\n",
    ")\n",
    "feature_df_sample['is_bear_positive'] = feature_df_sample.apply(\n",
    "    lambda row: (row['TF'].upper(), row['TG'].upper()) in bear_edges, \n",
    "    axis=1\n",
    ")\n",
    "feature_df_sample['is_chip_atlas_positive'] = feature_df_sample.apply(\n",
    "    lambda row: (row['TF'].upper(), row['TG'].upper()) in chip_atlas_edges, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nGround truth statistics on sample:\")\n",
    "print(f\"  Total edges: {len(feature_df_sample):,}\")\n",
    "print(f\"  BEELINE positives: {feature_df_sample['is_beeline_positive'].sum():,} ({feature_df_sample['is_beeline_positive'].mean()*100:.3f}%)\")\n",
    "print(f\"  BEAR-GRN positives: {feature_df_sample['is_bear_positive'].sum():,} ({feature_df_sample['is_bear_positive'].mean()*100:.3f}%)\")\n",
    "print(f\"  CHIP-ATLAS positives: {feature_df_sample['is_chip_atlas_positive'].sum():,} ({feature_df_sample['is_chip_atlas_positive'].mean()*100:.3f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "44b2aa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 7: FEATURE DISCRIMINATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "tss_distance - BEELINE\n",
      "======================================================================\n",
      "Positive edges: n=483, mean=9501.1408, median=9084.0000\n",
      "Negative edges: n=99,517, mean=9982.2559, median=10041.0000\n",
      "Mann-Whitney p-value: 7.16e-02\n",
      "Cohen's d: -0.0825\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "tss_distance - BEAR-GRN\n",
      "======================================================================\n",
      "Positive edges: n=556, mean=9669.6547, median=9162.5000\n",
      "Negative edges: n=99,444, mean=9981.6669, median=10041.0000\n",
      "Mann-Whitney p-value: 2.12e-01\n",
      "Cohen's d: -0.0535\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "tss_distance - CHIP-ATLAS\n",
      "======================================================================\n",
      "Positive edges: n=903, mean=10060.5648, median=10095.0000\n",
      "Negative edges: n=99,097, mean=9979.1973, median=10035.0000\n",
      "Mann-Whitney p-value: 6.81e-01\n",
      "Cohen's d: 0.0140\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "sliding_window_score - BEELINE\n",
      "======================================================================\n",
      "Positive edges: n=483, mean=0.2876, median=0.0000\n",
      "Negative edges: n=99,517, mean=0.2646, median=0.0000\n",
      "Mann-Whitney p-value: 1.59e-02\n",
      "Cohen's d: 0.0090\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "sliding_window_score - BEAR-GRN\n",
      "======================================================================\n",
      "Positive edges: n=556, mean=0.2809, median=0.0000\n",
      "Negative edges: n=99,444, mean=0.2646, median=0.0000\n",
      "Mann-Whitney p-value: 4.58e-03\n",
      "Cohen's d: 0.0064\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "sliding_window_score - CHIP-ATLAS\n",
      "======================================================================\n",
      "Positive edges: n=903, mean=0.2495, median=0.0000\n",
      "Negative edges: n=99,097, mean=0.2649, median=0.0000\n",
      "Mann-Whitney p-value: 1.95e-06\n",
      "Cohen's d: -0.0060\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "mean_target_expression - BEELINE\n",
      "======================================================================\n",
      "Positive edges: n=82, mean=0.3017, median=0.1472\n",
      "Negative edges: n=11,446, mean=0.2256, median=0.1090\n",
      "Mann-Whitney p-value: 2.07e-02\n",
      "Cohen's d: 0.2444\n",
      "Effect size: small ⚠️\n",
      "\n",
      "======================================================================\n",
      "mean_target_expression - BEAR-GRN\n",
      "======================================================================\n",
      "Positive edges: n=96, mean=0.2926, median=0.1472\n",
      "Negative edges: n=11,432, mean=0.2256, median=0.1087\n",
      "Mann-Whitney p-value: 5.04e-03\n",
      "Cohen's d: 0.2153\n",
      "Effect size: small ⚠️\n",
      "\n",
      "======================================================================\n",
      "mean_target_expression - CHIP-ATLAS\n",
      "======================================================================\n",
      "Positive edges: n=135, mean=0.2703, median=0.1943\n",
      "Negative edges: n=11,393, mean=0.2256, median=0.1085\n",
      "Mann-Whitney p-value: 3.46e-03\n",
      "Cohen's d: 0.1435\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "mean_tf_expression - BEELINE\n",
      "======================================================================\n",
      "Positive edges: n=341, mean=0.3361, median=0.2661\n",
      "Negative edges: n=45,005, mean=0.3011, median=0.0937\n",
      "Mann-Whitney p-value: 1.19e-34\n",
      "Cohen's d: 0.0729\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "mean_tf_expression - BEAR-GRN\n",
      "======================================================================\n",
      "Positive edges: n=406, mean=0.3168, median=0.1962\n",
      "Negative edges: n=44,940, mean=0.3012, median=0.0937\n",
      "Mann-Whitney p-value: 4.29e-45\n",
      "Cohen's d: 0.0324\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "mean_tf_expression - CHIP-ATLAS\n",
      "======================================================================\n",
      "Positive edges: n=638, mean=0.3825, median=0.2067\n",
      "Negative edges: n=44,708, mean=0.3002, median=0.0937\n",
      "Mann-Whitney p-value: 8.45e-34\n",
      "Cohen's d: 0.1716\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "mean_peak_accessibility - BEELINE\n",
      "======================================================================\n",
      "Positive edges: n=483, mean=0.0867, median=0.0391\n",
      "Negative edges: n=99,517, mean=0.0933, median=0.0439\n",
      "Mann-Whitney p-value: 1.23e-01\n",
      "Cohen's d: -0.0543\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "mean_peak_accessibility - BEAR-GRN\n",
      "======================================================================\n",
      "Positive edges: n=556, mean=0.0858, median=0.0402\n",
      "Negative edges: n=99,444, mean=0.0933, median=0.0439\n",
      "Mann-Whitney p-value: 3.44e-01\n",
      "Cohen's d: -0.0616\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "mean_peak_accessibility - CHIP-ATLAS\n",
      "======================================================================\n",
      "Positive edges: n=903, mean=0.0835, median=0.0394\n",
      "Negative edges: n=99,097, mean=0.0934, median=0.0440\n",
      "Mann-Whitney p-value: 2.44e-02\n",
      "Cohen's d: -0.0806\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "peak_gene_corr_pearson - BEELINE\n",
      "======================================================================\n",
      "Positive edges: n=82, mean=0.0855, median=0.0561\n",
      "Negative edges: n=11,446, mean=0.0826, median=0.0432\n",
      "Mann-Whitney p-value: 6.98e-01\n",
      "Cohen's d: 0.0144\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "peak_gene_corr_pearson - BEAR-GRN\n",
      "======================================================================\n",
      "Positive edges: n=96, mean=0.0785, median=0.0331\n",
      "Negative edges: n=11,432, mean=0.0826, median=0.0433\n",
      "Mann-Whitney p-value: 8.04e-01\n",
      "Cohen's d: -0.0206\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "peak_gene_corr_pearson - CHIP-ATLAS\n",
      "======================================================================\n",
      "Positive edges: n=135, mean=0.1022, median=0.0587\n",
      "Negative edges: n=11,393, mean=0.0824, median=0.0432\n",
      "Mann-Whitney p-value: 3.55e-01\n",
      "Cohen's d: 0.0990\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "peak_gene_corr_spearman - BEELINE\n",
      "======================================================================\n",
      "Positive edges: n=82, mean=0.0950, median=0.0614\n",
      "Negative edges: n=11,446, mean=0.0940, median=0.0699\n",
      "Mann-Whitney p-value: 9.68e-01\n",
      "Cohen's d: 0.0058\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "peak_gene_corr_spearman - BEAR-GRN\n",
      "======================================================================\n",
      "Positive edges: n=96, mean=0.0858, median=0.0549\n",
      "Negative edges: n=11,432, mean=0.0940, median=0.0699\n",
      "Mann-Whitney p-value: 5.53e-01\n",
      "Cohen's d: -0.0454\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "peak_gene_corr_spearman - CHIP-ATLAS\n",
      "======================================================================\n",
      "Positive edges: n=135, mean=0.1098, median=0.0868\n",
      "Negative edges: n=11,393, mean=0.0938, median=0.0698\n",
      "Mann-Whitney p-value: 3.62e-01\n",
      "Cohen's d: 0.0881\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "directness_score - BEELINE\n",
      "======================================================================\n",
      "Positive edges: n=50, mean=0.0614, median=0.0000\n",
      "Negative edges: n=3,799, mean=0.0404, median=0.0000\n",
      "Mann-Whitney p-value: 2.40e-01\n",
      "Cohen's d: 0.1955\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "directness_score - BEAR-GRN\n",
      "======================================================================\n",
      "Positive edges: n=63, mean=0.0548, median=0.0000\n",
      "Negative edges: n=3,786, mean=0.0404, median=0.0000\n",
      "Mann-Whitney p-value: 4.10e-01\n",
      "Cohen's d: 0.1334\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "directness_score - CHIP-ATLAS\n",
      "======================================================================\n",
      "Positive edges: n=79, mean=0.0423, median=0.0000\n",
      "Negative edges: n=3,770, mean=0.0406, median=0.0000\n",
      "Mann-Whitney p-value: 7.37e-01\n",
      "Cohen's d: 0.0155\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "mi_tf_gene - BEELINE\n",
      "======================================================================\n",
      "Positive edges: n=50, mean=0.0579, median=0.0283\n",
      "Negative edges: n=3,799, mean=0.0310, median=0.0137\n",
      "Mann-Whitney p-value: 1.38e-04\n",
      "Cohen's d: 0.5015\n",
      "Effect size: medium ✓\n",
      "\n",
      "======================================================================\n",
      "mi_tf_gene - BEAR-GRN\n",
      "======================================================================\n",
      "Positive edges: n=63, mean=0.0501, median=0.0268\n",
      "Negative edges: n=3,786, mean=0.0310, median=0.0137\n",
      "Mann-Whitney p-value: 1.23e-03\n",
      "Cohen's d: 0.3565\n",
      "Effect size: small ⚠️\n",
      "\n",
      "======================================================================\n",
      "mi_tf_gene - CHIP-ATLAS\n",
      "======================================================================\n",
      "Positive edges: n=79, mean=0.0568, median=0.0345\n",
      "Negative edges: n=3,770, mean=0.0308, median=0.0136\n",
      "Mann-Whitney p-value: 3.68e-05\n",
      "Cohen's d: 0.4845\n",
      "Effect size: small ⚠️\n",
      "\n",
      "⚠ Skipping coacc_pearson for BEELINE: insufficient data\n",
      "\n",
      "⚠ Skipping coacc_pearson for BEAR-GRN: insufficient data\n",
      "\n",
      "⚠ Skipping coacc_pearson for CHIP-ATLAS: insufficient data\n",
      "\n",
      "⚠ Skipping coacc_spearman for BEELINE: insufficient data\n",
      "\n",
      "⚠ Skipping coacc_spearman for BEAR-GRN: insufficient data\n",
      "\n",
      "⚠ Skipping coacc_spearman for CHIP-ATLAS: insufficient data\n",
      "\n",
      "======================================================================\n",
      "tf_gene_max_sliding_window - BEELINE\n",
      "======================================================================\n",
      "Positive edges: n=483, mean=0.2876, median=0.0000\n",
      "Negative edges: n=99,517, mean=0.3142, median=0.0000\n",
      "Mann-Whitney p-value: 7.26e-01\n",
      "Cohen's d: -0.0097\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "tf_gene_max_sliding_window - BEAR-GRN\n",
      "======================================================================\n",
      "Positive edges: n=556, mean=0.2861, median=0.0000\n",
      "Negative edges: n=99,444, mean=0.3142, median=0.0000\n",
      "Mann-Whitney p-value: 3.47e-01\n",
      "Cohen's d: -0.0102\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "tf_gene_max_sliding_window - CHIP-ATLAS\n",
      "======================================================================\n",
      "Positive edges: n=903, mean=0.2495, median=0.0000\n",
      "Negative edges: n=99,097, mean=0.3147, median=0.0000\n",
      "Mann-Whitney p-value: 8.40e-02\n",
      "Cohen's d: -0.0237\n",
      "Effect size: negligible ❌\n",
      "\n",
      "⚠ Skipping tf_gene_mean_coacc for BEELINE: insufficient data\n",
      "\n",
      "⚠ Skipping tf_gene_mean_coacc for BEAR-GRN: insufficient data\n",
      "\n",
      "⚠ Skipping tf_gene_mean_coacc for CHIP-ATLAS: insufficient data\n",
      "\n",
      "======================================================================\n",
      "tf_gene_n_peaks - BEELINE\n",
      "======================================================================\n",
      "Positive edges: n=483, mean=1.0083, median=1.0000\n",
      "Negative edges: n=99,517, mean=1.4756, median=1.0000\n",
      "Mann-Whitney p-value: 3.30e-43\n",
      "Cohen's d: -0.5284\n",
      "Effect size: medium ✓\n",
      "\n",
      "======================================================================\n",
      "tf_gene_n_peaks - BEAR-GRN\n",
      "======================================================================\n",
      "Positive edges: n=556, mean=1.0144, median=1.0000\n",
      "Negative edges: n=99,444, mean=1.4759, median=1.0000\n",
      "Mann-Whitney p-value: 9.58e-48\n",
      "Cohen's d: -0.5219\n",
      "Effect size: medium ✓\n",
      "\n",
      "======================================================================\n",
      "tf_gene_n_peaks - CHIP-ATLAS\n",
      "======================================================================\n",
      "Positive edges: n=903, mean=1.0044, median=1.0000\n",
      "Negative edges: n=99,097, mean=1.4776, median=1.0000\n",
      "Mann-Whitney p-value: 2.29e-81\n",
      "Cohen's d: -0.5354\n",
      "Effect size: medium ✓\n",
      "\n",
      "======================================================================\n",
      "tf_gene_mean_directness - BEELINE\n",
      "======================================================================\n",
      "Positive edges: n=50, mean=0.0614, median=0.0000\n",
      "Negative edges: n=3,799, mean=0.0404, median=0.0000\n",
      "Mann-Whitney p-value: 5.82e-01\n",
      "Cohen's d: 0.2041\n",
      "Effect size: small ⚠️\n",
      "\n",
      "======================================================================\n",
      "tf_gene_mean_directness - BEAR-GRN\n",
      "======================================================================\n",
      "Positive edges: n=63, mean=0.0548, median=0.0000\n",
      "Negative edges: n=3,786, mean=0.0404, median=0.0000\n",
      "Mann-Whitney p-value: 8.96e-01\n",
      "Cohen's d: 0.1393\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "tf_gene_mean_directness - CHIP-ATLAS\n",
      "======================================================================\n",
      "Positive edges: n=79, mean=0.0423, median=0.0000\n",
      "Negative edges: n=3,770, mean=0.0406, median=0.0000\n",
      "Mann-Whitney p-value: 8.74e-01\n",
      "Cohen's d: 0.0162\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "tf_gene_min_distance - BEELINE\n",
      "======================================================================\n",
      "Positive edges: n=483, mean=9499.5673, median=9084.0000\n",
      "Negative edges: n=99,517, mean=9171.4879, median=8796.0000\n",
      "Mann-Whitney p-value: 1.83e-01\n",
      "Cohen's d: 0.0565\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "tf_gene_min_distance - BEAR-GRN\n",
      "======================================================================\n",
      "Positive edges: n=556, mean=9641.1259, median=9153.0000\n",
      "Negative edges: n=99,444, mean=9170.4556, median=8792.0000\n",
      "Mann-Whitney p-value: 4.85e-02\n",
      "Cohen's d: 0.0810\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "tf_gene_min_distance - CHIP-ATLAS\n",
      "======================================================================\n",
      "Positive edges: n=903, mean=10056.7519, median=10095.0000\n",
      "Negative edges: n=99,097, mean=9165.0201, median=8784.0000\n",
      "Mann-Whitney p-value: 5.00e-06\n",
      "Cohen's d: 0.1535\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "tf_specificity - BEELINE\n",
      "======================================================================\n",
      "Positive edges: n=483, mean=0.0127, median=0.0116\n",
      "Negative edges: n=99,517, mean=0.0046, median=0.0003\n",
      "Mann-Whitney p-value: 2.15e-158\n",
      "Cohen's d: 0.8272\n",
      "Effect size: large ✓✓\n",
      "\n",
      "======================================================================\n",
      "tf_specificity - BEAR-GRN\n",
      "======================================================================\n",
      "Positive edges: n=556, mean=0.0129, median=0.0111\n",
      "Negative edges: n=99,444, mean=0.0046, median=0.0003\n",
      "Mann-Whitney p-value: 1.09e-182\n",
      "Cohen's d: 0.8495\n",
      "Effect size: large ✓✓\n",
      "\n",
      "======================================================================\n",
      "tf_specificity - CHIP-ATLAS\n",
      "======================================================================\n",
      "Positive edges: n=903, mean=0.0159, median=0.0128\n",
      "Negative edges: n=99,097, mean=0.0046, median=0.0003\n",
      "Mann-Whitney p-value: 0.00e+00\n",
      "Cohen's d: 1.1623\n",
      "Effect size: large ✓✓\n",
      "\n",
      "======================================================================\n",
      "gene_specificity - BEELINE\n",
      "======================================================================\n",
      "Positive edges: n=483, mean=0.1328, median=0.1111\n",
      "Negative edges: n=99,517, mean=0.1397, median=0.1250\n",
      "Mann-Whitney p-value: 1.22e-01\n",
      "Cohen's d: -0.0913\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "gene_specificity - BEAR-GRN\n",
      "======================================================================\n",
      "Positive edges: n=556, mean=0.1320, median=0.1111\n",
      "Negative edges: n=99,444, mean=0.1397, median=0.1250\n",
      "Mann-Whitney p-value: 1.76e-02\n",
      "Cohen's d: -0.1024\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "gene_specificity - CHIP-ATLAS\n",
      "======================================================================\n",
      "Positive edges: n=903, mean=0.1330, median=0.1111\n",
      "Negative edges: n=99,097, mean=0.1397, median=0.1250\n",
      "Mann-Whitney p-value: 7.09e-04\n",
      "Cohen's d: -0.0883\n",
      "Effect size: negligible ❌\n",
      "\n",
      "======================================================================\n",
      "pair_specificity - BEELINE\n",
      "======================================================================\n",
      "Positive edges: n=483, mean=0.0017, median=0.0013\n",
      "Negative edges: n=99,517, mean=0.0006, median=0.0000\n",
      "Mann-Whitney p-value: 1.88e-160\n",
      "Cohen's d: 0.6907\n",
      "Effect size: medium ✓\n",
      "\n",
      "======================================================================\n",
      "pair_specificity - BEAR-GRN\n",
      "======================================================================\n",
      "Positive edges: n=556, mean=0.0017, median=0.0012\n",
      "Negative edges: n=99,444, mean=0.0006, median=0.0000\n",
      "Mann-Whitney p-value: 3.76e-183\n",
      "Cohen's d: 0.7037\n",
      "Effect size: medium ✓\n",
      "\n",
      "======================================================================\n",
      "pair_specificity - CHIP-ATLAS\n",
      "======================================================================\n",
      "Positive edges: n=903, mean=0.0021, median=0.0016\n",
      "Negative edges: n=99,097, mean=0.0006, median=0.0000\n",
      "Mann-Whitney p-value: 0.00e+00\n",
      "Cohen's d: 0.9626\n",
      "Effect size: large ✓✓\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# STEP 7: Feature Discrimination Analysis\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 7: FEATURE DISCRIMINATION ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def analyze_feature_discrimination(df, feature_col, label_col, dataset_name):\n",
    "    \"\"\"Analyze how well a feature discriminates positive from negative edges\"\"\"\n",
    "    positive = df[df[label_col] == True][feature_col].dropna()\n",
    "    negative = df[df[label_col] == False][feature_col].dropna()\n",
    "    \n",
    "    if len(positive) < 2 or len(negative) < 2:\n",
    "        print(f\"\\n⚠ Skipping {feature_col} for {dataset_name}: insufficient data\")\n",
    "        return None\n",
    "    \n",
    "    # Statistical tests\n",
    "    mann_whitney = stats.mannwhitneyu(positive, negative, alternative='two-sided')\n",
    "    \n",
    "    # Cohen's d effect size\n",
    "    pooled_std = np.sqrt(\n",
    "        ((len(positive)-1)*positive.std()**2 + (len(negative)-1)*negative.std()**2) / \n",
    "        (len(positive) + len(negative) - 2)\n",
    "    )\n",
    "    \n",
    "    cohens_d = (positive.mean() - negative.mean()) / pooled_std if pooled_std > 0 else 0.0\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\"{feature_col} - {dataset_name}\")\n",
    "    print('=' * 70)\n",
    "    print(f\"Positive edges: n={len(positive):,}, mean={positive.mean():.4f}, median={positive.median():.4f}\")\n",
    "    print(f\"Negative edges: n={len(negative):,}, mean={negative.mean():.4f}, median={negative.median():.4f}\")\n",
    "    print(f\"Mann-Whitney p-value: {mann_whitney.pvalue:.2e}\")\n",
    "    print(f\"Cohen's d: {cohens_d:.4f}\")\n",
    "    \n",
    "    # Effect size interpretation\n",
    "    if abs(cohens_d) < 0.2:\n",
    "        effect = \"negligible ❌\"\n",
    "    elif abs(cohens_d) < 0.5:\n",
    "        effect = \"small ⚠️\"\n",
    "    elif abs(cohens_d) < 0.8:\n",
    "        effect = \"medium ✓\"\n",
    "    else:\n",
    "        effect = \"large ✓✓\"\n",
    "    print(f\"Effect size: {effect}\")\n",
    "    \n",
    "    return {\n",
    "        'feature': feature_col,\n",
    "        'dataset': dataset_name,\n",
    "        'n_positive': len(positive),\n",
    "        'n_negative': len(negative),\n",
    "        'p_value': mann_whitney.pvalue,\n",
    "        'cohens_d': cohens_d,\n",
    "        'effect_size': effect,\n",
    "        'pos_mean': positive.mean(),\n",
    "        'neg_mean': negative.mean(),\n",
    "        'pos_median': positive.median(),\n",
    "        'neg_median': negative.median()\n",
    "    }\n",
    "\n",
    "# Test all features\n",
    "features_to_test = [\n",
    "    # Original features\n",
    "    'tss_distance',\n",
    "    'sliding_window_score',\n",
    "    'mean_target_expression',\n",
    "    'mean_tf_expression',\n",
    "    'mean_peak_accessibility',\n",
    "    'peak_gene_corr_pearson',\n",
    "    'peak_gene_corr_spearman',\n",
    "    'directness_score',\n",
    "    'mi_tf_gene',\n",
    "    'coacc_pearson',\n",
    "    'coacc_spearman',\n",
    "    'tf_gene_max_sliding_window',\n",
    "    'tf_gene_mean_coacc',\n",
    "    'tf_gene_n_peaks',\n",
    "    'tf_gene_mean_directness',\n",
    "    'tf_gene_min_distance',\n",
    "    'tf_specificity',\n",
    "    'gene_specificity',\n",
    "    'pair_specificity'\n",
    "]\n",
    "\n",
    "results = []\n",
    "for feature in features_to_test:\n",
    "    if feature in feature_df_sample.columns:\n",
    "        # BEELINE\n",
    "        result = analyze_feature_discrimination(\n",
    "            feature_df_sample, feature, 'is_beeline_positive', 'BEELINE'\n",
    "        )\n",
    "        if result:\n",
    "            results.append(result)\n",
    "        \n",
    "        # BEAR-GRN\n",
    "        result = analyze_feature_discrimination(\n",
    "            feature_df_sample, feature, 'is_bear_positive', 'BEAR-GRN'\n",
    "        )\n",
    "        if result:\n",
    "            results.append(result)\n",
    "        # CHIP-ATLAS\n",
    "        result = analyze_feature_discrimination(\n",
    "            feature_df_sample, feature, 'is_chip_atlas_positive', 'CHIP-ATLAS'\n",
    "        )\n",
    "        if result:\n",
    "            results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1a484567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FEATURE DISCRIMINATION SUMMARY\n",
      "================================================================================\n",
      "                       feature     dataset  n_positive  n_negative        p_value  cohens_d   effect_size      pos_mean     neg_mean    pos_median    neg_median\n",
      "0                 tss_distance     BEELINE         483       99517   7.163874e-02 -0.082507  negligible ❌   9501.140787  9982.255866  9.084000e+03  1.004100e+04\n",
      "1                 tss_distance    BEAR-GRN         556       99444   2.116865e-01 -0.053507  negligible ❌   9669.654676  9981.666868  9.162500e+03  1.004100e+04\n",
      "2                 tss_distance  CHIP-ATLAS         903       99097   6.809707e-01  0.013954  negligible ❌  10060.564784  9979.197332  1.009500e+04  1.003500e+04\n",
      "3         sliding_window_score     BEELINE         483       99517   1.591008e-02  0.008994  negligible ❌      0.287610     0.264612  0.000000e+00  0.000000e+00\n",
      "4         sliding_window_score    BEAR-GRN         556       99444   4.576722e-03  0.006377  negligible ❌      0.280939     0.264633  0.000000e+00  0.000000e+00\n",
      "5         sliding_window_score  CHIP-ATLAS         903       99097   1.947153e-06 -0.006005  negligible ❌      0.249508     0.264862  0.000000e+00  0.000000e+00\n",
      "6       mean_target_expression     BEELINE          82       11446   2.070020e-02  0.244373      small ⚠️      0.301661     0.225598  1.471580e-01  1.090433e-01\n",
      "7       mean_target_expression    BEAR-GRN          96       11432   5.035706e-03  0.215330      small ⚠️      0.292605     0.225581  1.471580e-01  1.087211e-01\n",
      "8       mean_target_expression  CHIP-ATLAS         135       11393   3.460706e-03  0.143493  negligible ❌      0.270283     0.225616  1.942935e-01  1.085430e-01\n",
      "9           mean_tf_expression     BEELINE         341       45005   1.191558e-34  0.072933  negligible ❌      0.336094     0.301105  2.660883e-01  9.366021e-02\n",
      "10          mean_tf_expression    BEAR-GRN         406       44940   4.285373e-45  0.032390  negligible ❌      0.316768     0.301229  1.962282e-01  9.366021e-02\n",
      "11          mean_tf_expression  CHIP-ATLAS         638       44708   8.452299e-34  0.171566  negligible ❌      0.382501     0.300211  2.066521e-01  9.366021e-02\n",
      "12     mean_peak_accessibility     BEELINE         483       99517   1.229580e-01 -0.054329  negligible ❌      0.086659     0.093340  3.914081e-02  4.393247e-02\n",
      "13     mean_peak_accessibility    BEAR-GRN         556       99444   3.440622e-01 -0.061566  negligible ❌      0.085779     0.093349  4.022336e-02  4.390976e-02\n",
      "14     mean_peak_accessibility  CHIP-ATLAS         903       99097   2.444868e-02 -0.080574  negligible ❌      0.083489     0.093397  3.943824e-02  4.395277e-02\n",
      "15      peak_gene_corr_pearson     BEELINE          82       11446   6.980210e-01  0.014369  negligible ❌      0.085455     0.082573  5.612542e-02  4.322161e-02\n",
      "16      peak_gene_corr_pearson    BEAR-GRN          96       11432   8.035608e-01 -0.020641  negligible ❌      0.078488     0.082628  3.313626e-02  4.330960e-02\n",
      "17      peak_gene_corr_pearson  CHIP-ATLAS         135       11393   3.554483e-01  0.099013  negligible ❌      0.102218     0.082361  5.870584e-02  4.322161e-02\n",
      "18     peak_gene_corr_spearman     BEELINE          82       11446   9.683893e-01  0.005773  negligible ❌      0.095015     0.093964  6.142034e-02  6.991738e-02\n",
      "19     peak_gene_corr_spearman    BEAR-GRN          96       11432   5.529046e-01 -0.045409  negligible ❌      0.085779     0.094040  5.486229e-02  6.991738e-02\n",
      "20     peak_gene_corr_spearman  CHIP-ATLAS         135       11393   3.615894e-01  0.088127  negligible ❌      0.109817     0.093784  8.678579e-02  6.975387e-02\n",
      "21            directness_score     BEELINE          50        3799   2.401792e-01  0.195538  negligible ❌      0.061412     0.040369  1.372030e-11  0.000000e+00\n",
      "22            directness_score    BEAR-GRN          63        3786   4.101915e-01  0.133437  negligible ❌      0.054769     0.040407  6.317391e-12  0.000000e+00\n",
      "23            directness_score  CHIP-ATLAS          79        3770   7.369487e-01  0.015527  negligible ❌      0.042280     0.040608  0.000000e+00  0.000000e+00\n",
      "24                  mi_tf_gene     BEELINE          50        3799   1.375673e-04  0.501529      medium ✓      0.057887     0.030969  2.831269e-02  1.370293e-02\n",
      "25                  mi_tf_gene    BEAR-GRN          63        3786   1.227052e-03  0.356479      small ⚠️      0.050150     0.031005  2.677581e-02  1.371040e-02\n",
      "26                  mi_tf_gene  CHIP-ATLAS          79        3770   3.676230e-05  0.484498      small ⚠️      0.056770     0.030785  3.454720e-02  1.362079e-02\n",
      "27  tf_gene_max_sliding_window     BEELINE         483       99517   7.256773e-01 -0.009675  negligible ❌      0.287610     0.314217  0.000000e+00  0.000000e+00\n",
      "28  tf_gene_max_sliding_window    BEAR-GRN         556       99444   3.473665e-01 -0.010235  negligible ❌      0.286097     0.314245  0.000000e+00  0.000000e+00\n",
      "29  tf_gene_max_sliding_window  CHIP-ATLAS         903       99097   8.404406e-02 -0.023696  negligible ❌      0.249508     0.314677  0.000000e+00  0.000000e+00\n",
      "30             tf_gene_n_peaks     BEELINE         483       99517   3.302299e-43 -0.528390      medium ✓      1.008282     1.475617  1.000000e+00  1.000000e+00\n",
      "31             tf_gene_n_peaks    BEAR-GRN         556       99444   9.578977e-48 -0.521877      medium ✓      1.014388     1.475926  1.000000e+00  1.000000e+00\n",
      "32             tf_gene_n_peaks  CHIP-ATLAS         903       99097   2.287970e-81 -0.535351      medium ✓      1.004430     1.477633  1.000000e+00  1.000000e+00\n",
      "33     tf_gene_mean_directness     BEELINE          50        3799   5.819331e-01  0.204105      small ⚠️      0.061412     0.040369  1.372030e-11  1.067502e-11\n",
      "34     tf_gene_mean_directness    BEAR-GRN          63        3786   8.963417e-01  0.139283  negligible ❌      0.054769     0.040407  6.317391e-12  1.067502e-11\n",
      "35     tf_gene_mean_directness  CHIP-ATLAS          79        3770   8.740973e-01  0.016207  negligible ❌      0.042280     0.040608  4.207745e-12  1.067502e-11\n",
      "36        tf_gene_min_distance     BEELINE         483       99517   1.827972e-01  0.056453  negligible ❌   9499.567288  9171.487856  9.084000e+03  8.796000e+03\n",
      "37        tf_gene_min_distance    BEAR-GRN         556       99444   4.845333e-02  0.080989  negligible ❌   9641.125899  9170.455553  9.153000e+03  8.792000e+03\n",
      "38        tf_gene_min_distance  CHIP-ATLAS         903       99097   5.002139e-06  0.153455  negligible ❌  10056.751938  9165.020142  1.009500e+04  8.784000e+03\n",
      "39              tf_specificity     BEELINE         483       99517  2.146750e-158  0.827161      large ✓✓      0.012741     0.004634  1.162791e-02  2.693240e-04\n",
      "40              tf_specificity    BEAR-GRN         556       99444  1.088768e-182  0.849463      large ✓✓      0.012949     0.004627  1.111111e-02  2.693240e-04\n",
      "41              tf_specificity  CHIP-ATLAS         903       99097   0.000000e+00  1.162312      large ✓✓      0.015912     0.004571  1.282051e-02  2.693240e-04\n",
      "42            gene_specificity     BEELINE         483       99517   1.221445e-01 -0.091294  negligible ❌      0.132792     0.139691  1.111111e-01  1.250000e-01\n",
      "43            gene_specificity    BEAR-GRN         556       99444   1.761822e-02 -0.102389  negligible ❌      0.131963     0.139701  1.111111e-01  1.250000e-01\n",
      "44            gene_specificity  CHIP-ATLAS         903       99097   7.091804e-04 -0.088301  negligible ❌      0.133045     0.139718  1.111111e-01  1.250000e-01\n",
      "45            pair_specificity     BEELINE         483       99517  1.876102e-160  0.690712      medium ✓      0.001693     0.000626  1.291990e-03  4.063059e-05\n",
      "46            pair_specificity    BEAR-GRN         556       99444  3.764366e-183  0.703687      medium ✓      0.001712     0.000626  1.234568e-03  4.063059e-05\n",
      "47            pair_specificity  CHIP-ATLAS         903       99097   0.000000e+00  0.962586      large ✓✓      0.002100     0.000618  1.636661e-03  4.063059e-05\n",
      "\n",
      "✓ Results saved to:\n",
      "  - feature_discrimination_results.csv\n",
      "  - feature_dataframe_sample.csv\n",
      "\n",
      "================================================================================\n",
      "FEATURES RANKED BY DISCRIMINATION POWER\n",
      "================================================================================\n",
      "                       feature     dataset  cohens_d   effect_size        p_value\n",
      "41              tf_specificity  CHIP-ATLAS  1.162312      large ✓✓   0.000000e+00\n",
      "47            pair_specificity  CHIP-ATLAS  0.962586      large ✓✓   0.000000e+00\n",
      "40              tf_specificity    BEAR-GRN  0.849463      large ✓✓  1.088768e-182\n",
      "39              tf_specificity     BEELINE  0.827161      large ✓✓  2.146750e-158\n",
      "46            pair_specificity    BEAR-GRN  0.703687      medium ✓  3.764366e-183\n",
      "45            pair_specificity     BEELINE  0.690712      medium ✓  1.876102e-160\n",
      "32             tf_gene_n_peaks  CHIP-ATLAS -0.535351      medium ✓   2.287970e-81\n",
      "30             tf_gene_n_peaks     BEELINE -0.528390      medium ✓   3.302299e-43\n",
      "31             tf_gene_n_peaks    BEAR-GRN -0.521877      medium ✓   9.578977e-48\n",
      "24                  mi_tf_gene     BEELINE  0.501529      medium ✓   1.375673e-04\n",
      "26                  mi_tf_gene  CHIP-ATLAS  0.484498      small ⚠️   3.676230e-05\n",
      "25                  mi_tf_gene    BEAR-GRN  0.356479      small ⚠️   1.227052e-03\n",
      "6       mean_target_expression     BEELINE  0.244373      small ⚠️   2.070020e-02\n",
      "7       mean_target_expression    BEAR-GRN  0.215330      small ⚠️   5.035706e-03\n",
      "33     tf_gene_mean_directness     BEELINE  0.204105      small ⚠️   5.819331e-01\n",
      "21            directness_score     BEELINE  0.195538  negligible ❌   2.401792e-01\n",
      "11          mean_tf_expression  CHIP-ATLAS  0.171566  negligible ❌   8.452299e-34\n",
      "38        tf_gene_min_distance  CHIP-ATLAS  0.153455  negligible ❌   5.002139e-06\n",
      "8       mean_target_expression  CHIP-ATLAS  0.143493  negligible ❌   3.460706e-03\n",
      "34     tf_gene_mean_directness    BEAR-GRN  0.139283  negligible ❌   8.963417e-01\n",
      "22            directness_score    BEAR-GRN  0.133437  negligible ❌   4.101915e-01\n",
      "43            gene_specificity    BEAR-GRN -0.102389  negligible ❌   1.761822e-02\n",
      "17      peak_gene_corr_pearson  CHIP-ATLAS  0.099013  negligible ❌   3.554483e-01\n",
      "42            gene_specificity     BEELINE -0.091294  negligible ❌   1.221445e-01\n",
      "44            gene_specificity  CHIP-ATLAS -0.088301  negligible ❌   7.091804e-04\n",
      "20     peak_gene_corr_spearman  CHIP-ATLAS  0.088127  negligible ❌   3.615894e-01\n",
      "0                 tss_distance     BEELINE -0.082507  negligible ❌   7.163874e-02\n",
      "37        tf_gene_min_distance    BEAR-GRN  0.080989  negligible ❌   4.845333e-02\n",
      "14     mean_peak_accessibility  CHIP-ATLAS -0.080574  negligible ❌   2.444868e-02\n",
      "9           mean_tf_expression     BEELINE  0.072933  negligible ❌   1.191558e-34\n",
      "13     mean_peak_accessibility    BEAR-GRN -0.061566  negligible ❌   3.440622e-01\n",
      "36        tf_gene_min_distance     BEELINE  0.056453  negligible ❌   1.827972e-01\n",
      "12     mean_peak_accessibility     BEELINE -0.054329  negligible ❌   1.229580e-01\n",
      "1                 tss_distance    BEAR-GRN -0.053507  negligible ❌   2.116865e-01\n",
      "19     peak_gene_corr_spearman    BEAR-GRN -0.045409  negligible ❌   5.529046e-01\n",
      "10          mean_tf_expression    BEAR-GRN  0.032390  negligible ❌   4.285373e-45\n",
      "29  tf_gene_max_sliding_window  CHIP-ATLAS -0.023696  negligible ❌   8.404406e-02\n",
      "16      peak_gene_corr_pearson    BEAR-GRN -0.020641  negligible ❌   8.035608e-01\n",
      "35     tf_gene_mean_directness  CHIP-ATLAS  0.016207  negligible ❌   8.740973e-01\n",
      "23            directness_score  CHIP-ATLAS  0.015527  negligible ❌   7.369487e-01\n",
      "15      peak_gene_corr_pearson     BEELINE  0.014369  negligible ❌   6.980210e-01\n",
      "2                 tss_distance  CHIP-ATLAS  0.013954  negligible ❌   6.809707e-01\n",
      "28  tf_gene_max_sliding_window    BEAR-GRN -0.010235  negligible ❌   3.473665e-01\n",
      "27  tf_gene_max_sliding_window     BEELINE -0.009675  negligible ❌   7.256773e-01\n",
      "3         sliding_window_score     BEELINE  0.008994  negligible ❌   1.591008e-02\n",
      "4         sliding_window_score    BEAR-GRN  0.006377  negligible ❌   4.576722e-03\n",
      "5         sliding_window_score  CHIP-ATLAS -0.006005  negligible ❌   1.947153e-06\n",
      "18     peak_gene_corr_spearman     BEELINE  0.005773  negligible ❌   9.683893e-01\n",
      "\n",
      "================================================================================\n",
      "FINAL ASSESSMENT\n",
      "================================================================================\n",
      "\n",
      "✓ Found 14 discriminative features:\n",
      "  • mean_target_expression         (BEELINE   ): Cohen's d =  0.244\n",
      "  • mean_target_expression         (BEAR-GRN  ): Cohen's d =  0.215\n",
      "  • mi_tf_gene                     (BEELINE   ): Cohen's d =  0.502\n",
      "  • mi_tf_gene                     (BEAR-GRN  ): Cohen's d =  0.356\n",
      "  • mi_tf_gene                     (CHIP-ATLAS): Cohen's d =  0.484\n",
      "  • tf_gene_n_peaks                (BEELINE   ): Cohen's d = -0.528\n",
      "  • tf_gene_n_peaks                (BEAR-GRN  ): Cohen's d = -0.522\n",
      "  • tf_gene_n_peaks                (CHIP-ATLAS): Cohen's d = -0.535\n",
      "  • tf_specificity                 (BEELINE   ): Cohen's d =  0.827\n",
      "  • tf_specificity                 (BEAR-GRN  ): Cohen's d =  0.849\n",
      "  • tf_specificity                 (CHIP-ATLAS): Cohen's d =  1.162\n",
      "  • pair_specificity               (BEELINE   ): Cohen's d =  0.691\n",
      "  • pair_specificity               (BEAR-GRN  ): Cohen's d =  0.704\n",
      "  • pair_specificity               (CHIP-ATLAS): Cohen's d =  0.963\n",
      "\n",
      "Expected AUROC: 0.70-0.80\n",
      "Task feasibility: ✓✓ HIGHLY FEASIBLE\n",
      "(Based on max Cohen's d = 1.162)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# STEP 8: Summary and Recommendations\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FEATURE DISCRIMINATION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.to_string())\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('feature_discrimination_results.csv', index=False)\n",
    "feature_df_sample.to_csv('feature_dataframe_sample.csv', index=False)\n",
    "print(\"\\n✓ Results saved to:\")\n",
    "print(\"  - feature_discrimination_results.csv\")\n",
    "print(\"  - feature_dataframe_sample.csv\")\n",
    "\n",
    "# Rank features\n",
    "results_df['abs_cohens_d'] = results_df['cohens_d'].abs()\n",
    "results_df_sorted = results_df.sort_values('abs_cohens_d', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FEATURES RANKED BY DISCRIMINATION POWER\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df_sorted[['feature', 'dataset', 'cohens_d', 'effect_size', 'p_value']])\n",
    "\n",
    "# Final recommendations\n",
    "good_features = results_df[(results_df['abs_cohens_d'] > 0.2) & (results_df['p_value'] < 0.05)]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL ASSESSMENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if len(good_features) == 0:\n",
    "    print(\"\\n❌ NO DISCRIMINATIVE FEATURES FOUND\")\n",
    "    print(\"\\nExpected AUROC: 0.50-0.55 (random)\")\n",
    "    print(\"\\nYour task is NOT feasible with current features.\")\n",
    "else:\n",
    "    print(f\"\\n✓ Found {len(good_features)} discriminative features:\")\n",
    "    for _, row in good_features.iterrows():\n",
    "        print(f\"  • {row['feature']:30s} ({row['dataset']:10s}): Cohen's d = {row['cohens_d']:6.3f}\")\n",
    "    \n",
    "    best_cohens_d = results_df['abs_cohens_d'].max()\n",
    "    \n",
    "    if best_cohens_d > 0.8:\n",
    "        expected_auroc = \"0.70-0.80\"\n",
    "        feasibility = \"✓✓ HIGHLY FEASIBLE\"\n",
    "    elif best_cohens_d > 0.5:\n",
    "        expected_auroc = \"0.65-0.75\"\n",
    "        feasibility = \"✓ FEASIBLE\"\n",
    "    elif best_cohens_d > 0.2:\n",
    "        expected_auroc = \"0.58-0.68\"\n",
    "        feasibility = \"⚠ MODERATELY FEASIBLE\"\n",
    "    else:\n",
    "        expected_auroc = \"0.50-0.55\"\n",
    "        feasibility = \"✗ NOT FEASIBLE\"\n",
    "    \n",
    "    print(f\"\\nExpected AUROC: {expected_auroc}\")\n",
    "    print(f\"Task feasibility: {feasibility}\")\n",
    "    print(f\"(Based on max Cohen's d = {best_cohens_d:.3f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ce56ca76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enhanced Model - Validation AUROC: 0.960\n",
      "Enhanced Model - BEAR-GRN Test AUROC: 0.659\n"
     ]
    }
   ],
   "source": [
    "# 1. Train on BEELINE with all features (even weak ones)\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve\n",
    "\n",
    "# Prepare data\n",
    "feature_cols = [\n",
    "    # Original\n",
    "    'tss_distance',\n",
    "    'sliding_window_score',\n",
    "    'mean_target_expression',\n",
    "    'mean_tf_expression',\n",
    "    'mean_peak_accessibility',\n",
    "    'peak_gene_corr_pearson',\n",
    "    'peak_gene_corr_spearman',\n",
    "    \n",
    "    # New features\n",
    "    'directness_score',\n",
    "    'mi_tf_gene',\n",
    "    'coacc_pearson',\n",
    "    'tf_gene_max_sliding_window',\n",
    "    'tf_gene_mean_coacc',\n",
    "    'tf_gene_n_peaks',\n",
    "    'tf_gene_mean_directness',\n",
    "    'tf_gene_min_distance',\n",
    "    'tf_specificity',\n",
    "    'gene_specificity',\n",
    "    'pair_specificity'\n",
    "]\n",
    "\n",
    "X_enhanced = feature_df_sample[feature_cols].fillna(0)\n",
    "y_chip_atlas = feature_df_sample['is_chip_atlas_positive']\n",
    "\n",
    "# Re-train and evaluate\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_enhanced, y_chip_atlas, test_size=0.2, random_state=42, stratify=y_chip_atlas\n",
    ")\n",
    "\n",
    "rf_enhanced = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf_enhanced.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "val_auroc = roc_auc_score(y_val, rf_enhanced.predict_proba(X_val)[:, 1])\n",
    "print(f\"\\nEnhanced Model - Validation AUROC: {val_auroc:.3f}\")\n",
    "\n",
    "# Test on BEAR-GRN\n",
    "y_bear = feature_df_sample['is_bear_positive']\n",
    "bear_auroc = roc_auc_score(y_bear, rf_enhanced.predict_proba(X_enhanced)[:, 1])\n",
    "print(f\"Enhanced Model - BEAR-GRN Test AUROC: {bear_auroc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "21c8f945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full BEELINE AUROC (enhanced): 0.666\n",
      "CHIP-ATLAS AUROC   (enhanced): 0.993\n",
      "BEAR-GRN AUROC   (enhanced): 0.659\n",
      "Difference (BEAR - BEELINE): -0.006\n",
      "\n",
      "================================================================================\n",
      "EDGE OVERLAP ANALYSIS\n",
      "================================================================================\n",
      "BEELINE positive edges: 483\n",
      "BEAR-GRN positive edges: 556\n",
      "Overlapping edges: 461\n",
      "Overlap % (relative to smaller set): 95.4%\n",
      "\n",
      "BEAR-GRN-only edges (novel):\n",
      "  Mean prob:   0.057\n",
      "  Median prob: 0.000\n",
      "  % prob > 0.5: 5.3%\n",
      "\n",
      "Overlapping edges (present in both GTs):\n",
      "  Mean prob:   0.043\n",
      "  Median prob: 0.000\n",
      "  % prob > 0.5: 3.7%\n",
      "\n",
      "Difference in confidence (overlap - novel): -0.015\n",
      "\n",
      "================================================================================\n",
      "FEATURE IMPORTANCE IN RANDOM FOREST (Enhanced Feature Set)\n",
      "================================================================================\n",
      "\n",
      "Feature ranking:\n",
      " 1. tf_specificity                 Importance: 0.3888  (Cohen's d: 1.162)\n",
      " 2. pair_specificity               Importance: 0.3322  (Cohen's d: 0.963)\n",
      " 3. mean_tf_expression             Importance: 0.0897  (Cohen's d: 0.172)\n",
      " 4. tf_gene_n_peaks                Importance: 0.0462  (Cohen's d: 0.535)\n",
      " 5. mean_peak_accessibility        Importance: 0.0325  (Cohen's d: 0.081)\n",
      " 6. tf_gene_min_distance           Importance: 0.0276  (Cohen's d: 0.153)\n",
      " 7. tss_distance                   Importance: 0.0270  (Cohen's d: 0.083)\n",
      " 8. gene_specificity               Importance: 0.0204  (Cohen's d: 0.102)\n",
      " 9. sliding_window_score           Importance: 0.0077  (Cohen's d: 0.009)\n",
      "10. tf_gene_max_sliding_window     Importance: 0.0076  (Cohen's d: 0.024)\n",
      "11. mean_target_expression         Importance: 0.0049  (Cohen's d: 0.244)\n",
      "12. peak_gene_corr_spearman        Importance: 0.0048  (Cohen's d: 0.088)\n",
      "13. peak_gene_corr_pearson         Importance: 0.0046  (Cohen's d: 0.099)\n",
      "14. mi_tf_gene                     Importance: 0.0039  (Cohen's d: 0.502)\n",
      "15. directness_score               Importance: 0.0012  (Cohen's d: 0.196)\n",
      "16. tf_gene_mean_directness        Importance: 0.0007  (Cohen's d: 0.204)\n",
      "17. coacc_pearson                  Importance: 0.0000  (Cohen's d: NA)\n",
      "18. tf_gene_mean_coacc             Importance: 0.0000  (Cohen's d: NA)\n",
      "\n",
      "================================================================================\n",
      "FEATURE DISTRIBUTIONS: BEELINE vs BEAR-GRN POSITIVES (Enhanced)\n",
      "================================================================================\n",
      "\n",
      "tss_distance:\n",
      "  BEELINE positives: mean=9501.1408, median=9084.0000\n",
      "  BEAR-GRN positives: mean=9669.6547, median=9162.5000\n",
      "  Difference (BEAR - BEELINE): 168.5139\n",
      "\n",
      "sliding_window_score:\n",
      "  BEELINE positives: mean=0.2876, median=0.0000\n",
      "  BEAR-GRN positives: mean=0.2809, median=0.0000\n",
      "  Difference (BEAR - BEELINE): -0.0067\n",
      "\n",
      "mean_target_expression:\n",
      "  BEELINE positives: mean=0.0512, median=0.0000\n",
      "  BEAR-GRN positives: mean=0.0505, median=0.0000\n",
      "  Difference (BEAR - BEELINE): -0.0007\n",
      "\n",
      "mean_tf_expression:\n",
      "  BEELINE positives: mean=0.2373, median=0.1437\n",
      "  BEAR-GRN positives: mean=0.2313, median=0.1437\n",
      "  Difference (BEAR - BEELINE): -0.0060\n",
      "\n",
      "mean_peak_accessibility:\n",
      "  BEELINE positives: mean=0.0867, median=0.0391\n",
      "  BEAR-GRN positives: mean=0.0858, median=0.0402\n",
      "  Difference (BEAR - BEELINE): -0.0009\n",
      "\n",
      "peak_gene_corr_pearson:\n",
      "  BEELINE positives: mean=0.0145, median=0.0000\n",
      "  BEAR-GRN positives: mean=0.0136, median=0.0000\n",
      "  Difference (BEAR - BEELINE): -0.0010\n",
      "\n",
      "peak_gene_corr_spearman:\n",
      "  BEELINE positives: mean=0.0161, median=0.0000\n",
      "  BEAR-GRN positives: mean=0.0148, median=0.0000\n",
      "  Difference (BEAR - BEELINE): -0.0013\n",
      "\n",
      "directness_score:\n",
      "  BEELINE positives: mean=0.0064, median=0.0000\n",
      "  BEAR-GRN positives: mean=0.0062, median=0.0000\n",
      "  Difference (BEAR - BEELINE): -0.0002\n",
      "\n",
      "mi_tf_gene:\n",
      "  BEELINE positives: mean=0.0060, median=0.0000\n",
      "  BEAR-GRN positives: mean=0.0057, median=0.0000\n",
      "  Difference (BEAR - BEELINE): -0.0003\n",
      "\n",
      "coacc_pearson:\n",
      "  BEELINE positives: mean=0.0000, median=0.0000\n",
      "  BEAR-GRN positives: mean=0.0000, median=0.0000\n",
      "  Difference (BEAR - BEELINE): 0.0000\n",
      "\n",
      "tf_gene_max_sliding_window:\n",
      "  BEELINE positives: mean=0.2876, median=0.0000\n",
      "  BEAR-GRN positives: mean=0.2861, median=0.0000\n",
      "  Difference (BEAR - BEELINE): -0.0015\n",
      "\n",
      "tf_gene_mean_coacc:\n",
      "  BEELINE positives: mean=0.0000, median=0.0000\n",
      "  BEAR-GRN positives: mean=0.0000, median=0.0000\n",
      "  Difference (BEAR - BEELINE): 0.0000\n",
      "\n",
      "tf_gene_n_peaks:\n",
      "  BEELINE positives: mean=1.0083, median=1.0000\n",
      "  BEAR-GRN positives: mean=1.0144, median=1.0000\n",
      "  Difference (BEAR - BEELINE): 0.0061\n",
      "\n",
      "tf_gene_mean_directness:\n",
      "  BEELINE positives: mean=0.0064, median=0.0000\n",
      "  BEAR-GRN positives: mean=0.0062, median=0.0000\n",
      "  Difference (BEAR - BEELINE): -0.0002\n",
      "\n",
      "tf_gene_min_distance:\n",
      "  BEELINE positives: mean=9499.5673, median=9084.0000\n",
      "  BEAR-GRN positives: mean=9641.1259, median=9153.0000\n",
      "  Difference (BEAR - BEELINE): 141.5586\n",
      "\n",
      "tf_specificity:\n",
      "  BEELINE positives: mean=0.0127, median=0.0116\n",
      "  BEAR-GRN positives: mean=0.0129, median=0.0111\n",
      "  Difference (BEAR - BEELINE): 0.0002\n",
      "\n",
      "gene_specificity:\n",
      "  BEELINE positives: mean=0.1328, median=0.1111\n",
      "  BEAR-GRN positives: mean=0.1320, median=0.1111\n",
      "  Difference (BEAR - BEELINE): -0.0008\n",
      "\n",
      "pair_specificity:\n",
      "  BEELINE positives: mean=0.0017, median=0.0013\n",
      "  BEAR-GRN positives: mean=0.0017, median=0.0012\n",
      "  Difference (BEAR - BEELINE): 0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 0) Assumptions / inputs from your training cell:\n",
    "#   - rf_enhanced : fitted classifier (RandomForestClassifier here)\n",
    "#   - X_enhanced  : feature_df_sample[feature_cols].fillna(0)\n",
    "#   - feature_df_sample has boolean columns:\n",
    "#         'is_beeline_positive' and 'is_bear_positive'\n",
    "#   - feature_cols is the full list of features used to train rf_enhanced\n",
    "# ---------------------------------------------------------------------\n",
    "assert 'is_beeline_positive' in feature_df_sample.columns\n",
    "assert 'is_bear_positive' in feature_df_sample.columns\n",
    "\n",
    "# Align labels to X_enhanced\n",
    "y_beeline = feature_df_sample.loc[X_enhanced.index, 'is_beeline_positive'].astype(bool)\n",
    "y_bear    = feature_df_sample.loc[X_enhanced.index, 'is_bear_positive'].astype(bool)\n",
    "y_chip_atlas = feature_df_sample.loc[X_enhanced.index, 'is_chip_atlas_positive'].astype(bool)\n",
    "\n",
    "# Get predictions\n",
    "if hasattr(rf_enhanced, \"predict_proba\"):\n",
    "    all_probs = rf_enhanced.predict_proba(X_enhanced)[:, 1]\n",
    "else:\n",
    "    # fallback (e.g., some linear models); decision_function → min-max to [0,1]\n",
    "    scores = rf_enhanced.decision_function(X_enhanced)\n",
    "    smin, smax = np.min(scores), np.max(scores)\n",
    "    all_probs = (scores - smin) / (smax - smin + 1e-12)\n",
    "\n",
    "# AUROC comparisons\n",
    "beeline_full_auroc = roc_auc_score(y_beeline, all_probs)\n",
    "bear_auroc         = roc_auc_score(y_bear, all_probs)\n",
    "chip_atlas_auroc   = roc_auc_score(y_chip_atlas, all_probs)\n",
    "\n",
    "print(f\"\\nFull BEELINE AUROC (enhanced): {beeline_full_auroc:.3f}\")\n",
    "\n",
    "print(f\"CHIP-ATLAS AUROC   (enhanced): {chip_atlas_auroc:.3f}\")\n",
    "print(f\"BEAR-GRN AUROC   (enhanced): {bear_auroc:.3f}\")\n",
    "print(f\"Difference (BEAR - BEELINE): {bear_auroc - beeline_full_auroc:.3f}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Overlap analysis (use boolean masks to avoid index misalignment)\n",
    "# ---------------------------------------------------------------------\n",
    "mask_beeline_pos = y_beeline.values.astype(bool)\n",
    "mask_bear_pos    = y_bear.values.astype(bool)\n",
    "mask_overlap     = mask_beeline_pos & mask_bear_pos\n",
    "mask_bear_only   = mask_bear_pos & (~mask_beeline_pos)\n",
    "mask_both_neg    = (~mask_beeline_pos) & (~mask_bear_pos)\n",
    "\n",
    "n_beeline = int(mask_beeline_pos.sum())\n",
    "n_bear    = int(mask_bear_pos.sum())\n",
    "n_overlap = int(mask_overlap.sum())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EDGE OVERLAP ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"BEELINE positive edges: {n_beeline}\")\n",
    "print(f\"BEAR-GRN positive edges: {n_bear}\")\n",
    "print(f\"Overlapping edges: {n_overlap}\")\n",
    "print(f\"Overlap % (relative to smaller set): \"\n",
    "      f\"{(n_overlap / max(1, min(n_beeline, n_bear)) * 100):.1f}%\")\n",
    "\n",
    "# Compare model confidence on overlap vs. BEAR-only (novel) edges\n",
    "if n_bear_only := int(mask_bear_only.sum()):\n",
    "    probs_bear_only = all_probs[mask_bear_only]\n",
    "    print(f\"\\nBEAR-GRN-only edges (novel):\")\n",
    "    print(f\"  Mean prob:   {probs_bear_only.mean():.3f}\")\n",
    "    print(f\"  Median prob: {np.median(probs_bear_only):.3f}\")\n",
    "    print(f\"  % prob > 0.5: {(probs_bear_only > 0.5).mean() * 100:.1f}%\")\n",
    "\n",
    "if n_overlap > 0:\n",
    "    probs_overlap = all_probs[mask_overlap]\n",
    "    print(f\"\\nOverlapping edges (present in both GTs):\")\n",
    "    print(f\"  Mean prob:   {probs_overlap.mean():.3f}\")\n",
    "    print(f\"  Median prob: {np.median(probs_overlap):.3f}\")\n",
    "    print(f\"  % prob > 0.5: {(probs_overlap > 0.5).mean() * 100:.1f}%\")\n",
    "\n",
    "if (n_bear_only > 0) and (n_overlap > 0):\n",
    "    print(f\"\\nDifference in confidence (overlap - novel): \"\n",
    "          f\"{(probs_overlap.mean() - probs_bear_only.mean()):.3f}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Feature importance (enhanced features)\n",
    "# ---------------------------------------------------------------------\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(\"FEATURE IMPORTANCE IN RANDOM FOREST (Enhanced Feature Set)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "feature_names = list(feature_cols)  # same order as X_enhanced columns\n",
    "\n",
    "if hasattr(rf_enhanced, \"feature_importances_\"):\n",
    "    importances = rf_enhanced.feature_importances_\n",
    "    # guard against length mismatch\n",
    "    if len(importances) != len(feature_names):\n",
    "        print(\"Warning: feature_importances_ length mismatch; skipping ranking.\")\n",
    "    else:\n",
    "        order = np.argsort(importances)[::-1]\n",
    "        print(\"\\nFeature ranking:\")\n",
    "        for rank, j in enumerate(order, 1):\n",
    "            fname = feature_names[j]\n",
    "            imp   = importances[j]\n",
    "            # Optional: if you computed Cohen's d per feature elsewhere\n",
    "            try:\n",
    "                cohen_val = (results_df[results_df['feature'] == fname]['cohens_d']\n",
    "                             .abs().max())\n",
    "                cohen_txt = f\"{cohen_val:.3f}\" if pd.notna(cohen_val) else \"NA\"\n",
    "            except Exception:\n",
    "                cohen_txt = \"NA\"\n",
    "            print(f\"{rank:2d}. {fname:30s} Importance: {imp:.4f}  (Cohen's d: {cohen_txt})\")\n",
    "else:\n",
    "    print(\"Model has no feature_importances_; skipping ranking.\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Compare feature distributions between BEELINE and BEAR-GRN positives\n",
    "# (uses X_enhanced so the columns match the trained model exactly)\n",
    "# ---------------------------------------------------------------------\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(\"FEATURE DISTRIBUTIONS: BEELINE vs BEAR-GRN POSITIVES (Enhanced)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "X_beeline_pos = X_enhanced[mask_beeline_pos]\n",
    "X_bear_pos    = X_enhanced[mask_bear_pos]\n",
    "\n",
    "for feature in feature_names:\n",
    "    if feature not in X_enhanced.columns:\n",
    "        continue\n",
    "    beeline_vals = X_beeline_pos[feature]\n",
    "    bear_vals    = X_bear_pos[feature]\n",
    "\n",
    "    # robust stats\n",
    "    b_mean = float(beeline_vals.mean())\n",
    "    b_med  = float(beeline_vals.median())\n",
    "    g_mean = float(bear_vals.mean())\n",
    "    g_med  = float(bear_vals.median())\n",
    "\n",
    "    print(f\"\\n{feature}:\")\n",
    "    print(f\"  BEELINE positives: mean={b_mean:.4f}, median={b_med:.4f}\")\n",
    "    print(f\"  BEAR-GRN positives: mean={g_mean:.4f}, median={g_med:.4f}\")\n",
    "    print(f\"  Difference (BEAR - BEELINE): {g_mean - b_mean:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9114cfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRUE GENERALIZATION TEST: BEAR-GRN-ONLY EDGES (Enhanced Model)\n",
      "================================================================================\n",
      "\n",
      "Edge breakdown:\n",
      "  Overlapping (in both):     460 (trained on these)\n",
      "  BEELINE-only:              21 (trained on these)\n",
      "  BEAR-GRN-only:             92 (NEVER seen during training)\n",
      "\n",
      "BEAR-GRN-only positive samples: 95\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE ON TRULY NOVEL EDGES (NEVER SEEN DURING TRAINING)\n",
      "================================================================================\n",
      "BEAR-GRN-only edges AUROC: 0.694\n",
      "Overlapping edges AUROC: 0.990 (model saw these during training)\n",
      "\n",
      "Difference (Overlap - BEAR-only): 0.296\n",
      "\n",
      "✓ GOOD: Model shows moderate generalization to novel edges.\n",
      "\n",
      "================================================================================\n",
      "PREDICTION SCORE DISTRIBUTIONS (Enhanced Model)\n",
      "================================================================================\n",
      "\n",
      "BEAR-GRN-only edges (novel):\n",
      "  Mean prob:   0.029\n",
      "  Median prob: 0.000\n",
      "  % prob > 0.5:0.0%\n",
      "\n",
      "Overlapping edges (present in both GTs):\n",
      "  Mean prob:   0.617\n",
      "  Median prob: 0.680\n",
      "  % prob > 0.5:81.8%\n",
      "\n",
      "Difference in confidence (overlap - novel): 0.588\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TRUE GENERALIZATION TEST: BEAR-GRN-ONLY EDGES  (Enhanced model version)\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TRUE GENERALIZATION TEST: BEAR-GRN-ONLY EDGES (Enhanced Model)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Assumptions / inputs:\n",
    "#   - rf_enhanced  : fitted classifier on X_enhanced\n",
    "#   - X_enhanced   : feature_df_sample[feature_cols].fillna(0)\n",
    "#   - feature_df_sample has columns: 'TF','TG','is_beeline_positive','is_bear_positive'\n",
    "# ---------------------------------------------------------------------\n",
    "assert 'is_beeline_positive' in feature_df_sample.columns\n",
    "assert 'is_bear_positive'    in feature_df_sample.columns\n",
    "assert len(X_enhanced) == len(feature_df_sample), \"Row alignment mismatch.\"\n",
    "\n",
    "# Align GT labels to X_enhanced's row order\n",
    "y_beeline = feature_df_sample.loc[X_enhanced.index, 'is_beeline_positive'].astype(bool)\n",
    "y_bear    = feature_df_sample.loc[X_enhanced.index, 'is_bear_positive'].astype(bool)\n",
    "\n",
    "# Masks (numpy bool arrays aligned to rows of X_enhanced / feature_df_sample)\n",
    "mask_beeline_pos = y_beeline.values\n",
    "mask_bear_pos    = y_bear.values\n",
    "mask_overlap     = mask_beeline_pos & mask_bear_pos\n",
    "mask_beeline_only= mask_beeline_pos & (~mask_bear_pos)\n",
    "mask_bear_only   = mask_bear_pos & (~mask_beeline_pos)\n",
    "mask_both_neg    = (~mask_beeline_pos) & (~mask_bear_pos)\n",
    "\n",
    "# Counts\n",
    "n_beeline  = int(mask_beeline_pos.sum())\n",
    "n_bear     = int(mask_bear_pos.sum())\n",
    "n_overlap  = int(mask_overlap.sum())\n",
    "n_bear_only= int(mask_bear_only.sum())\n",
    "\n",
    "# Optional: edge breakdown by (TF, TG) pairs (using positions, not labels)\n",
    "def _pairs_from_positions(pos_idx):\n",
    "    if len(pos_idx) == 0:\n",
    "        return set()\n",
    "    sub = feature_df_sample.iloc[pos_idx][['TF','TG']].astype(str)\n",
    "    return set(zip(sub['TF'].str.upper(), sub['TG'].str.upper()))\n",
    "\n",
    "pos_overlap   = np.flatnonzero(mask_overlap)\n",
    "pos_beeline   = np.flatnonzero(mask_beeline_pos)\n",
    "pos_bear      = np.flatnonzero(mask_bear_pos)\n",
    "overlap_edges = _pairs_from_positions(pos_overlap)\n",
    "beeline_edges = _pairs_from_positions(pos_beeline)\n",
    "bear_edges    = _pairs_from_positions(pos_bear)\n",
    "beeline_only_edges = beeline_edges - overlap_edges\n",
    "bear_only_edges    = bear_edges - overlap_edges\n",
    "\n",
    "print(\"\\nEdge breakdown:\")\n",
    "print(f\"  Overlapping (in both):     {len(overlap_edges)} (trained on these)\")\n",
    "print(f\"  BEELINE-only:              {len(beeline_only_edges)} (trained on these)\")\n",
    "print(f\"  BEAR-GRN-only:             {len(bear_only_edges)} (NEVER seen during training)\")\n",
    "\n",
    "# Predictions (probabilities) aligned to X_enhanced\n",
    "if hasattr(rf_enhanced, \"predict_proba\"):\n",
    "    all_probs = rf_enhanced.predict_proba(X_enhanced)[:, 1]\n",
    "else:\n",
    "    # fallback for models without predict_proba\n",
    "    scores = rf_enhanced.decision_function(X_enhanced)\n",
    "    smin, smax = np.min(scores), np.max(scores)\n",
    "    all_probs = (scores - smin) / (smax - smin + 1e-12)\n",
    "\n",
    "print(f\"\\nBEAR-GRN-only positive samples: {n_bear_only}\")\n",
    "\n",
    "# Build a balanced test: all BEAR-only positives + up to 100× negatives that are negative in both GTs\n",
    "if n_bear_only >= 10:\n",
    "    rng = np.random.default_rng(0)\n",
    "\n",
    "    pos_idx = np.flatnonzero(mask_bear_only)\n",
    "    neg_pool_idx = np.flatnonzero(mask_both_neg)\n",
    "    k = min(len(pos_idx) * 100, len(neg_pool_idx))\n",
    "    neg_idx = neg_pool_idx[:k]  # deterministic slice; or rng.choice(neg_pool_idx, size=k, replace=False)\n",
    "\n",
    "    test_idx = np.concatenate([pos_idx, neg_idx])\n",
    "\n",
    "    X_test_bear_only = X_enhanced.iloc[test_idx]\n",
    "    y_test_bear_only = y_bear.values[test_idx].astype(int)\n",
    "\n",
    "    if hasattr(rf_enhanced, \"predict_proba\"):\n",
    "        probs_bear_only = rf_enhanced.predict_proba(X_test_bear_only)[:, 1]\n",
    "    else:\n",
    "        scores = rf_enhanced.decision_function(X_test_bear_only)\n",
    "        smin, smax = scores.min(), scores.max()\n",
    "        probs_bear_only = (scores - smin) / (smax - smin + 1e-12)\n",
    "\n",
    "    auroc_bear_only = roc_auc_score(y_test_bear_only, probs_bear_only)\n",
    "\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"PERFORMANCE ON TRULY NOVEL EDGES (NEVER SEEN DURING TRAINING)\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    print(f\"BEAR-GRN-only edges AUROC: {auroc_bear_only:.3f}\")\n",
    "\n",
    "    # Compare with overlapping edges (positives in both GTs)\n",
    "    if n_overlap >= 10:\n",
    "        pos_overlap_idx = np.flatnonzero(mask_overlap)\n",
    "        k2 = min(len(pos_overlap_idx) * 100, len(neg_pool_idx))\n",
    "        neg_idx2 = neg_pool_idx[:k2]\n",
    "        test_idx_overlap = np.concatenate([pos_overlap_idx, neg_idx2])\n",
    "\n",
    "        X_test_overlap = X_enhanced.iloc[test_idx_overlap]\n",
    "        y_test_overlap = y_bear.values[test_idx_overlap].astype(int)\n",
    "\n",
    "        if hasattr(rf_enhanced, \"predict_proba\"):\n",
    "            probs_overlap = rf_enhanced.predict_proba(X_test_overlap)[:, 1]\n",
    "        else:\n",
    "            scores = rf_enhanced.decision_function(X_test_overlap)\n",
    "            smin, smax = scores.min(), scores.max()\n",
    "            probs_overlap = (scores - smin) / (smax - smin + 1e-12)\n",
    "\n",
    "        auroc_overlap = roc_auc_score(y_test_overlap, probs_overlap)\n",
    "        print(f\"Overlapping edges AUROC: {auroc_overlap:.3f} (model saw these during training)\")\n",
    "        print(f\"\\nDifference (Overlap - BEAR-only): {auroc_overlap - auroc_bear_only:.3f}\")\n",
    "\n",
    "        if auroc_bear_only < 0.65:\n",
    "            print(\"\\n⚠️  WARNING: Performance on novel edges is substantially lower.\")\n",
    "            print(\"   High AUROC on overlapping edges may reflect memorization.\")\n",
    "        elif auroc_bear_only >= 0.75:\n",
    "            print(\"\\n✓ EXCELLENT: Model genuinely generalizes to novel edges!\")\n",
    "        else:\n",
    "            print(\"\\n✓ GOOD: Model shows moderate generalization to novel edges.\")\n",
    "    else:\n",
    "        print(\"\\n⚠️  Not enough overlapping positives for a robust comparison.\")\n",
    "else:\n",
    "    print(f\"\\n⚠️  Only {n_bear_only} BEAR-GRN-only positives; too few for reliable testing.\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Prediction score distributions for BEAR-only vs Overlap (using masks, not labels)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"PREDICTION SCORE DISTRIBUTIONS (Enhanced Model)\")\n",
    "print(f\"{'=' * 80}\")\n",
    "\n",
    "if n_bear_only > 0:\n",
    "    bear_only_probs = all_probs[mask_bear_only]\n",
    "    print(\"\\nBEAR-GRN-only edges (novel):\")\n",
    "    print(f\"  Mean prob:   {bear_only_probs.mean():.3f}\")\n",
    "    print(f\"  Median prob: {np.median(bear_only_probs):.3f}\")\n",
    "    print(f\"  % prob > 0.5:{(bear_only_probs > 0.5).mean() * 100:.1f}%\")\n",
    "\n",
    "if n_overlap > 0:\n",
    "    overlap_probs = all_probs[mask_overlap]\n",
    "    print(\"\\nOverlapping edges (present in both GTs):\")\n",
    "    print(f\"  Mean prob:   {overlap_probs.mean():.3f}\")\n",
    "    print(f\"  Median prob: {np.median(overlap_probs):.3f}\")\n",
    "    print(f\"  % prob > 0.5:{(overlap_probs > 0.5).mean() * 100:.1f}%\")\n",
    "\n",
    "if (n_bear_only > 0) and (n_overlap > 0):\n",
    "    print(\"\\nDifference in confidence (overlap - novel): \"\n",
    "          f\"{(overlap_probs.mean() - bear_only_probs.mean()):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ea202de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Bio-only | Group=TF ===\n",
      "     Subset     AUPRC  Recall@P≥0.90  Precision@100  Precision@1000\n",
      "0  Bio-only  0.015114            0.0          0.012           0.017\n",
      "\n",
      "=== Bio+Priors | Group=TF ===\n",
      "       Subset    AUPRC  Recall@P≥0.90  Precision@100  Precision@1000\n",
      "0  Bio+Priors  0.02297            0.0           0.01          0.0198\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# TF→TG CLASSIFIER (robust)\n",
    "# =========================\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import GroupKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "# --- Utilities ---\n",
    "def build_xy(df, cols, label_col):\n",
    "    X = df[cols].copy().replace([np.inf, -np.inf], np.nan)\n",
    "    X = X.fillna(X.median(numeric_only=True))\n",
    "    y = df[label_col].astype(bool).values\n",
    "    return X, y\n",
    "\n",
    "def recall_at_precision(y_true, y_prob, p_target=0.90):\n",
    "    p, r, _ = precision_recall_curve(y_true, y_prob)\n",
    "    return float(r[p >= p_target].max()) if (p >= p_target).any() else 0.0\n",
    "\n",
    "def eval_fold(y_true, y_prob, topk=(100,1000)):\n",
    "    ap = average_precision_score(y_true, y_prob)\n",
    "    out = {\"AUPRC\": ap, \"Recall@P≥0.90\": recall_at_precision(y_true, y_prob, 0.90)}\n",
    "    order = np.argsort(-y_prob)\n",
    "    for k in topk:\n",
    "        k = min(k, len(y_true))\n",
    "        out[f\"Precision@{k}\"] = float(y_true[order[:k]].mean()) if k>0 else 0.0\n",
    "    return out\n",
    "\n",
    "# --- One row per TF–TG pair is assumed (you already merged aggregates). ---\n",
    "df = feature_df_sample.copy()\n",
    "\n",
    "LABEL = \"is_union_positive\" if \"is_union_positive\" in df.columns else \"is_beeline_positive\"\n",
    "if \"is_union_positive\" not in df.columns:\n",
    "    df[\"is_union_positive\"] = df[\"is_beeline_positive\"] | df[\"is_bear_positive\"]\n",
    "\n",
    "BIO_FEATURES = [c for c in [\n",
    "    \"tss_distance\",\"sliding_window_score\",\n",
    "    \"mean_target_expression\",\"mean_tf_expression\",\n",
    "    \"mean_peak_accessibility\",\"mi_tf_gene\",\"directness_score\",\n",
    "    \"tf_gene_n_peaks\",\"tf_gene_max_sliding_window\",\n",
    "    \"tf_gene_mean_directness\",\"tf_gene_min_distance\",\n",
    "] if c in df.columns]\n",
    "\n",
    "PRIORS = [c for c in [\"tf_specificity\",\"pair_specificity\",\"gene_specificity\"] if c in df.columns]\n",
    "\n",
    "SUBSETS = {\n",
    "    \"Bio-only\": BIO_FEATURES,\n",
    "    \"Bio+Priors\": BIO_FEATURES + PRIORS,\n",
    "}\n",
    "\n",
    "# Optional: negative downsampling for speed in training (not in evaluation)\n",
    "def downsample_negatives(d, label_col, ratio=20, seed=0):\n",
    "    pos = d[d[label_col]]\n",
    "    neg = d[~d[label_col]]\n",
    "    n_keep = min(len(neg), ratio*len(pos)) if len(pos)>0 else len(neg)\n",
    "    neg_keep = neg.sample(n=n_keep, random_state=seed) if n_keep < len(neg) else neg\n",
    "    return pd.concat([pos, neg_keep], axis=0).sample(frac=1, random_state=seed)\n",
    "\n",
    "# --- Models ---\n",
    "def make_lr():\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "        (\"clf\", LogisticRegression(solver=\"liblinear\", penalty=\"l2\",\n",
    "                                   class_weight=\"balanced\", max_iter=500))\n",
    "    ])\n",
    "\n",
    "def make_hgb():\n",
    "    return HistGradientBoostingClassifier(\n",
    "        learning_rate=0.08, max_iter=400, min_samples_leaf=20, early_stopping=True,\n",
    "        validation_fraction=0.1\n",
    "    )\n",
    "\n",
    "# Simple hyperparam grids\n",
    "HGB_PARAM_DIST = {\n",
    "    \"learning_rate\":  np.linspace(0.03, 0.15, 5),\n",
    "    \"max_iter\":       [200, 300, 400, 600],\n",
    "    \"min_samples_leaf\":[10, 20, 30, 50],\n",
    "    \"max_depth\":      [None, 4, 8, 12],\n",
    "    \"l2_regularization\": [0.0, 0.1, 0.5, 1.0],\n",
    "}\n",
    "\n",
    "GROUP_BY = \"TF\"   # try also \"TG\" or \"peak_chrom\"\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "groups = df[GROUP_BY].astype(str).values\n",
    "\n",
    "results = []\n",
    "for subset_name, feats in SUBSETS.items():\n",
    "    X_all, y_all = build_xy(df, feats, LABEL)\n",
    "\n",
    "    fold_metrics = []\n",
    "    for fold, (tr, te) in enumerate(gkf.split(X_all, y_all, groups), 1):\n",
    "        # Optional downsampling ON TRAIN ONLY for speed\n",
    "        fold_df = df.iloc[tr].copy()\n",
    "        fold_df = downsample_negatives(fold_df, LABEL, ratio=20, seed=fold)\n",
    "        X_tr, y_tr = build_xy(fold_df, feats, LABEL)\n",
    "\n",
    "        # Class weights for imbalance (used by LR; for HGB we pass sample_weight)\n",
    "        sw_tr = compute_sample_weight(class_weight=\"balanced\", y=y_tr)\n",
    "\n",
    "        # Model = tuned HGB (strong); keep LR as baseline if desired\n",
    "        base = make_hgb()\n",
    "        search = RandomizedSearchCV(\n",
    "            base, HGB_PARAM_DIST, n_iter=20, cv=3, n_jobs=-1, random_state=fold,\n",
    "            scoring=\"average_precision\", refit=True, verbose=0\n",
    "        )\n",
    "        search.fit(X_tr, y_tr, sample_weight=sw_tr)\n",
    "\n",
    "        # Calibrate on train (CV inside) and evaluate on untouched TEST fold\n",
    "        cal = CalibratedClassifierCV(search.best_estimator_, method=\"isotonic\", cv=3)\n",
    "        cal.fit(X_tr, y_tr, sample_weight=sw_tr)\n",
    "\n",
    "        X_te, y_te = X_all.iloc[te], y_all[te]\n",
    "        y_prob = cal.predict_proba(X_te)[:,1]\n",
    "        m = eval_fold(y_te, y_prob, topk=(100,1000))\n",
    "        m.update({\"Subset\": subset_name, \"Fold\": fold, \"Positives\": int(y_te.sum())})\n",
    "        fold_metrics.append(m)\n",
    "\n",
    "    fold_df = pd.DataFrame(fold_metrics)\n",
    "    agg = fold_df.groupby(\"Subset\", as_index=False).mean(numeric_only=True)\n",
    "    print(f\"\\n=== {subset_name} | Group={GROUP_BY} ===\")\n",
    "    print(agg[[\"Subset\",\"AUPRC\",\"Recall@P≥0.90\",\"Precision@100\",\"Precision@1000\"]])\n",
    "    results.append(agg)\n",
    "\n",
    "all_results = pd.concat(results, axis=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
