{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f932679",
   "metadata": {},
   "source": [
    "## Define the inputs and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "518fa90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_ewc_adapt_then_eval.py\n",
    "import os, sys, json, joblib\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Paths / config\n",
    "# ---------------------------------------------------------------------\n",
    "PROJECT_DIR = \"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER\"\n",
    "DEV_DIR     = os.path.join(PROJECT_DIR, \"dev/transformer\")\n",
    "sys.path.append(DEV_DIR)\n",
    "\n",
    "from transformer import MultiomicTransformer\n",
    "from transformer_dataset import MultiomicTransformerDataset\n",
    "from transformer_training import prepare_dataloader\n",
    "import ewc_utils  # your separate module\n",
    "\n",
    "TRAINED_MODEL_SAMPLE_NAME = \"mESC\"\n",
    "EVAL_SAMPLE_NAME          = \"mESC_holdout\"\n",
    "CHROM_ID                  = \"chr1\"\n",
    "\n",
    "OUTPUT_DIR                = os.path.join(PROJECT_DIR, \"output/transformer_testing_output\")\n",
    "TRAINED_MODEL_DIR         = os.path.join(OUTPUT_DIR, \"model_0.77_corr\")\n",
    "COMMON_DATA_DIR           = os.path.join(DEV_DIR, \"transformer_data\", \"common\")\n",
    "\n",
    "TRAINED_MODEL_DATASET_DIR = os.path.join(DEV_DIR, f\"transformer_data/{TRAINED_MODEL_SAMPLE_NAME}\")\n",
    "EVAL_DATASET_DIR          = os.path.join(DEV_DIR, f\"transformer_data/{EVAL_SAMPLE_NAME}\")\n",
    "\n",
    "CAL_SPLIT_FRAC = 0.5\n",
    "CAL_ALPHAS     = [0.1, 0.3, 1.0, 3.0, 10.0]\n",
    "BATCH_SIZE_FALLBACK = 64\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d123896",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d27dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=SEED):\n",
    "    import random\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "set_seed()\n",
    "\n",
    "def inverse_transform(X, mean, scale):\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    if scale is not None: X = X * scale\n",
    "    if mean  is not None: X = X + mean\n",
    "    return X\n",
    "\n",
    "def run_model(model, loader, device, zscore_tf=True):\n",
    "    \"\"\"Return (preds, true) where preds are in TRAIN z-space; true in EVAL z-space.\"\"\"\n",
    "    preds_all, true_all = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for atac_wins, tf_tensor, tg_true, bias, tf_ids, tg_ids in loader:\n",
    "            atac_wins = atac_wins.to(device)\n",
    "            tf_tensor = tf_tensor.to(device)\n",
    "            tg_true   = tg_true.to(device)\n",
    "            bias      = bias.to(device)\n",
    "            tf_ids    = tf_ids.to(device)\n",
    "            tg_ids    = tg_ids.to(device)\n",
    "\n",
    "            if zscore_tf:\n",
    "                mu = tf_tensor.mean(dim=1, keepdim=True)\n",
    "                sd = tf_tensor.std(dim=1, keepdim=True).clamp_min(1e-6)\n",
    "                tf_tensor = (tf_tensor - mu) / sd\n",
    "\n",
    "            preds = model(atac_wins, tf_tensor, tf_ids=tf_ids, tg_ids=tg_ids, bias=bias)\n",
    "            preds_all.append(preds.cpu().numpy())\n",
    "            true_all.append(tg_true.cpu().numpy())\n",
    "    return np.vstack(preds_all), np.vstack(true_all)\n",
    "\n",
    "def build_overlap_and_spaces(preds, true, dataset, train_dataset_dir, chrom_id):\n",
    "    \"\"\"Align gene order, inverse-transform to raw spaces, and map truth to TRAIN z-space.\"\"\"\n",
    "    train_scaler = joblib.load(Path(train_dataset_dir) / f\"{chrom_id}/tg_scaler_{chrom_id}.pkl\")\n",
    "    eval_scaler  = dataset.scaler\n",
    "\n",
    "    with open(Path(train_dataset_dir) / f\"{chrom_id}/tg_names_{chrom_id}.json\") as f:\n",
    "        train_tg_names = json.load(f)\n",
    "    \n",
    "    # Find the index for each gene name in the training and target datasets\n",
    "    train_name_to_idx = {g:i for i,g in enumerate(train_tg_names)}\n",
    "    eval_name_to_idx  = {g:i for i,g in enumerate(dataset.tg_names)}\n",
    "\n",
    "    # Only use target genes that are present in both datasets\n",
    "    overlap_genes = [g for g in dataset.tg_names if g in train_name_to_idx]\n",
    "    mask_eval = np.array([g in train_name_to_idx for g in dataset.tg_names], dtype=bool)\n",
    "    train_idx = np.array([train_name_to_idx[g] for g in overlap_genes])\n",
    "    eval_idx  = np.array([eval_name_to_idx[g]  for g in overlap_genes])\n",
    "\n",
    "    preds_ov = preds[:, mask_eval]  # TRAIN z-space\n",
    "    true_ov  = true[:,  mask_eval]  # EVAL  z-space\n",
    "\n",
    "    # inverse transform the predictions and true values using their own scaler for each gene\n",
    "    preds_raw = inverse_transform(preds_ov, train_scaler.mean_[train_idx], train_scaler.scale_[train_idx])\n",
    "    true_raw  = inverse_transform(true_ov,  eval_scaler.mean_[eval_idx],   eval_scaler.scale_[eval_idx])\n",
    "\n",
    "    # Re-standardize the target raw truth using the training scaler\n",
    "    true_in_train_z = (true_raw - train_scaler.mean_[train_idx]) / train_scaler.scale_[train_idx]\n",
    "\n",
    "    return {\n",
    "        \"overlap_genes\": overlap_genes,\n",
    "        \"preds_ov\": preds_ov,\n",
    "        \"true_in_train_z\": true_in_train_z,\n",
    "        \"preds_raw\": preds_raw,\n",
    "        \"true_raw\": true_raw,\n",
    "        \"train_scaler\": train_scaler,\n",
    "        \"train_idx\": train_idx\n",
    "    }\n",
    "\n",
    "def split_for_calibration(X, Y, frac=CAL_SPLIT_FRAC, seed=SEED):\n",
    "    n = X.shape[0]\n",
    "    rng = np.random.RandomState(seed)\n",
    "    idx = rng.permutation(n)\n",
    "    k  = int(np.floor(frac * n))\n",
    "    return (X[idx[:k]], Y[idx[:k]]), (X[idx[k:]], Y[idx[k:]])\n",
    "\n",
    "def fit_ridge_calibrator(X_cal, Y_cal, alphas=CAL_ALPHAS):\n",
    "\n",
    "    best_alpha, best_r = None, -np.inf\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    for a in alphas:\n",
    "        rs = []\n",
    "        for tr, va in kf.split(X_cal):\n",
    "            rr = Ridge(alpha=a, fit_intercept=True)\n",
    "            rr.fit(X_cal[tr], Y_cal[tr])\n",
    "            yhat = rr.predict(X_cal[va])\n",
    "            rs.append(np.corrcoef(Y_cal[va].ravel(), yhat.ravel())[0,1])\n",
    "        r_mean = float(np.mean(rs))\n",
    "        if r_mean > best_r:\n",
    "            best_r, best_alpha = r_mean, a\n",
    "    ridge = Ridge(alpha=best_alpha, fit_intercept=True)\n",
    "    ridge.fit(X_cal, Y_cal)\n",
    "    return ridge, best_alpha, best_r\n",
    "\n",
    "def metrics_block(y, yhat):\n",
    "    r_p = pearsonr(y.ravel(), yhat.ravel())[0]\n",
    "    r_s = spearmanr(y.ravel(), yhat.ravel()).correlation\n",
    "    mae = np.mean(np.abs(y - yhat))\n",
    "    return dict(pearson=float(r_p), spearman=float(r_s), mae=float(mae))\n",
    "\n",
    "def scatter_plot(y, yhat, title, out_png, max_points=5000, seed=SEED):\n",
    "    n = min(max_points, y.shape[0])\n",
    "    idx = np.random.RandomState(seed).choice(y.shape[0], n, replace=False)\n",
    "    plt.figure(figsize=(6.5,6.5))\n",
    "    plt.scatter(y[idx].ravel(), yhat[idx].ravel(), alpha=0.25, s=12)\n",
    "    lims = [min(y.min(), yhat.min()), max(y.max(), yhat.max())]\n",
    "    plt.plot(lims, lims, 'r--', linewidth=1)\n",
    "    rp = pearsonr(y.ravel(), yhat.ravel())[0]\n",
    "    plt.title(f\"{title}\\nPearson r = {rp:.2f}\")\n",
    "    plt.xlabel(\"Actual\"); plt.ylabel(\"Predicted\")\n",
    "    plt.tight_layout(); plt.savefig(out_png, dpi=150); plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e056089",
   "metadata": {},
   "source": [
    "## Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19a1e515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_sizes(common_dir, chrom_id):\n",
    "    with open(os.path.join(common_dir, \"tf_vocab.json\")) as f: tf_vocab = json.load(f)\n",
    "    with open(os.path.join(common_dir, \"tg_vocab.json\")) as f: tg_vocab = json.load(f)  # single file for all CHRs\n",
    "    return len(tf_vocab), len(tg_vocab)\n",
    "\n",
    "def get_loaders(data_dir, chrom_id, common_dir, batch):\n",
    "    ds = MultiomicTransformerDataset(\n",
    "        data_dir=data_dir,\n",
    "        chrom_id=chrom_id,\n",
    "        tf_vocab_path=os.path.join(common_dir, \"tf_vocab.json\"),\n",
    "        tg_vocab_path=os.path.join(common_dir, \"tg_vocab.json\"),\n",
    "    )\n",
    "    return ds, prepare_dataloader(ds, batch_size=batch, world_size=1, rank=0)\n",
    "\n",
    "def build_model(run_params, tf_vocab_size, tg_vocab_size, ckpt_path, device):\n",
    "    d_model   = run_params[\"d_model\"]\n",
    "    num_heads = run_params[\"Attention Heads\"]\n",
    "    num_layers= run_params[\"Model Layers\"]\n",
    "    d_ff      = run_params[\"d_feedforward\"]\n",
    "    dropout   = run_params[\"Dropout\"]\n",
    "\n",
    "    state_dict = torch.load(ckpt_path, map_location=device)\n",
    "    use_shortcut = (\"shortcut_scale\" in state_dict)\n",
    "\n",
    "    model = MultiomicTransformer(\n",
    "        d_model=d_model, num_heads=num_heads, num_layers=num_layers,\n",
    "        d_ff=d_ff, dropout=dropout,\n",
    "        tf_vocab_size=tf_vocab_size, tg_vocab_size=tg_vocab_size,\n",
    "        use_shortcut=use_shortcut\n",
    "    ).to(device)\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06477166",
   "metadata": {},
   "source": [
    "## Elastic Weight Consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a03cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ewc_adaptation(model, device, source_loader, target_train_loader,\n",
    "                       include_strong, include_weak, lambda_strong=1000.0, lambda_weak=50.0,\n",
    "                       epochs=5, lr=1e-4, weight_decay=1e-4):\n",
    "    # Fisher on source (protect knowledge)\n",
    "    fisher_diag = ewc_utils.compute_fisher_diag(model, source_loader, device, n_batches=100, loss_fn=\"mse\")\n",
    "    ref_params  = ewc_utils.clone_params(model)\n",
    "\n",
    "    opt = torch.optim.Adam([p for p in model.parameters() if p.requires_grad], lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        for atac_wins, tf_tensor, tg_true, bias, tf_ids, tg_ids in target_train_loader:\n",
    "            atac_wins, tf_tensor, tg_true, bias = [x.to(device) for x in (atac_wins, tf_tensor, tg_true, bias)]\n",
    "            tf_ids, tg_ids = tf_ids.to(device), tg_ids.to(device)\n",
    "\n",
    "            # per-cell TF z-score\n",
    "            mu = tf_tensor.mean(dim=1, keepdim=True)\n",
    "            sd = tf_tensor.std(dim=1, keepdim=True).clamp_min(1e-6)\n",
    "            tf_norm = (tf_tensor - mu) / sd\n",
    "\n",
    "            preds = model(atac_wins, tf_norm, tf_ids=tf_ids, tg_ids=tg_ids, bias=bias)\n",
    "            data_loss = F.mse_loss(preds, tg_true)\n",
    "\n",
    "            pen_head   = ewc_utils.ewc_penalty(model, fisher_diag, ref_params, lambda_weak,   include=include_weak)\n",
    "            pen_strong = ewc_utils.ewc_penalty(model, fisher_diag, ref_params, lambda_strong, include=include_strong)\n",
    "\n",
    "            loss = data_loss + pen_head + pen_strong\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "    return model, fisher_diag, ref_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5510cd2",
   "metadata": {},
   "source": [
    "## Main Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1919a9",
   "metadata": {},
   "source": [
    "### Load training model, dataset, and run parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1255ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run params + vocab sizes\n",
    "with open(os.path.join(TRAINED_MODEL_DIR, \"run_parameters.json\")) as f:\n",
    "    run_params = json.load(f)\n",
    "batch = run_params.get(\"Batch Size\", BATCH_SIZE_FALLBACK)\n",
    "\n",
    "tf_vocab_size, tg_vocab_size = get_vocab_sizes(COMMON_DATA_DIR, CHROM_ID)\n",
    "source_ds, (src_train_loader, _, src_test_loader) = get_loaders(TRAINED_MODEL_DATASET_DIR, CHROM_ID, COMMON_DATA_DIR, batch)\n",
    "\n",
    "# Build the trained model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "ckpt_path = os.path.join(TRAINED_MODEL_DIR, \"checkpoint.pt\")\n",
    "model = build_model(run_params, tf_vocab_size, tg_vocab_size, ckpt_path, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b343a6e",
   "metadata": {},
   "source": [
    "### Load the target dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "069d12b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets/loaders\n",
    "target_ds, (tgt_train_loader, _, tgt_test_loader) = get_loaders(EVAL_DATASET_DIR, CHROM_ID, COMMON_DATA_DIR, batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52217e4d",
   "metadata": {},
   "source": [
    "### Baseline evaluation (no scaler alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c2c39a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, true = run_model(model, tgt_test_loader, device, zscore_tf=True)\n",
    "spaces = build_overlap_and_spaces(preds, true, target_ds, TRAINED_MODEL_DATASET_DIR, CHROM_ID)\n",
    "\n",
    "overlap_genes   = spaces[\"overlap_genes\"]\n",
    "preds_ov        = spaces[\"preds_ov\"]\n",
    "true_in_train_z = spaces[\"true_in_train_z\"]\n",
    "preds_raw       = spaces[\"preds_raw\"]\n",
    "true_raw        = spaces[\"true_raw\"]\n",
    "train_scaler    = spaces[\"train_scaler\"]\n",
    "train_idx       = spaces[\"train_idx\"]\n",
    "\n",
    "base_train = metrics_block(true_in_train_z, preds_ov)\n",
    "base_raw   = metrics_block(true_raw,       preds_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e44dcb1",
   "metadata": {},
   "source": [
    "### Align scaler and fit ridge calibrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af730fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_cal, Y_cal), (X_test, Y_test) = split_for_calibration(preds_ov, true_in_train_z, frac=CAL_SPLIT_FRAC, seed=SEED)\n",
    "ridge, best_alpha, cv_r = fit_ridge_calibrator(X_cal, Y_cal, alphas=CAL_ALPHAS)\n",
    "\n",
    "preds_test_cal = ridge.predict(X_test)  # TRAIN z-space\n",
    "cal_train = metrics_block(Y_test, preds_test_cal)\n",
    "\n",
    "preds_test_cal_raw = inverse_transform(preds_test_cal, train_scaler.mean_[train_idx], train_scaler.scale_[train_idx])\n",
    "Y_test_raw         = inverse_transform(Y_test,         train_scaler.mean_[train_idx], train_scaler.scale_[train_idx])\n",
    "cal_raw = metrics_block(Y_test_raw, preds_test_cal_raw)\n",
    "\n",
    "out_dir = os.path.join(OUTPUT_DIR, f\"infer_{EVAL_SAMPLE_NAME}_{CHROM_ID}\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "joblib.dump(ridge, os.path.join(out_dir, f\"ridge_calibrator_alpha{best_alpha}.pkl\"))\n",
    "\n",
    "scatter_plot(Y_test_raw, preds_test_cal_raw,\n",
    "                f\"{EVAL_SAMPLE_NAME} {CHROM_ID}: Predicted vs Actual (calibrated, test split, pre-EWC)\",\n",
    "                os.path.join(out_dir, \"scatter_calibrated_test_pre_ewc.png\"))\n",
    "\n",
    "# Per-gene corr (pre-EWC, calibrated)\n",
    "gene_corr = []\n",
    "for j, g in enumerate(overlap_genes):\n",
    "    y, yhat = Y_test_raw[:, j], preds_test_cal_raw[:, j]\n",
    "    r = pearsonr(y, yhat)[0] if np.std(y) > 1e-8 else 0.0\n",
    "    gene_corr.append((g, r))\n",
    "pd.DataFrame(gene_corr, columns=[\"gene\",\"pearson\"]).sort_values(\"pearson\", ascending=False)\\\n",
    "    .to_csv(os.path.join(out_dir, \"per_gene_pearson_test_pre_ewc.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c8b79b",
   "metadata": {},
   "source": [
    "### Run Elastic Weight Consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fa7b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== EWC adaptation =====\n",
    "# include_strong is a set of model layers to keep stable\n",
    "# include_weak is a set of model layers that can change more easily to new data\n",
    "include_strong = {\"encoder\", \"tf_emb_table\", \"tg_emb_table\", \"tg_decoder_table\"}\n",
    "include_weak   = {\"out_dense\", \"shortcut_scale\"}\n",
    "\n",
    "ewc_model, fisher_diag_src, _ = run_ewc_adaptation(\n",
    "    model, device,\n",
    "    source_loader=src_train_loader,\n",
    "    target_train_loader=tgt_train_loader,\n",
    "    include_strong=include_strong,\n",
    "    include_weak=include_weak,\n",
    "    lambda_strong=1000.0,\n",
    "    lambda_weak=50.0,\n",
    "    epochs=5, lr=1e-4, weight_decay=1e-4\n",
    ")\n",
    "\n",
    "# Save adapted model & EWC bundle for target (optional future chaining)\n",
    "torch.save(ewc_model.state_dict(), os.path.join(out_dir, f\"model_ewc_{EVAL_SAMPLE_NAME}_{CHROM_ID}.ckpt\"))\n",
    "fisher_ds011 = ewc_utils.compute_fisher_diag(ewc_model, tgt_train_loader, device, n_batches=100, loss_fn=\"mse\")\n",
    "ewc_utils.save_ewc_bundle(os.path.join(out_dir, f\"ewc_{EVAL_SAMPLE_NAME}_{CHROM_ID}.pt\"), ewc_model, fisher_ds011)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec20747",
   "metadata": {},
   "source": [
    "### Evaluate EWC-Trained Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef7e48d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Post-EWC evaluation =====\n",
    "preds_post, true_post = run_model(ewc_model, tgt_test_loader, device, zscore_tf=True)\n",
    "spaces_post = build_overlap_and_spaces(preds_post, true_post, target_ds, TRAINED_MODEL_DATASET_DIR, CHROM_ID)\n",
    "\n",
    "preds_ov_post        = spaces_post[\"preds_ov\"]\n",
    "true_in_train_z_post = spaces_post[\"true_in_train_z\"]\n",
    "preds_raw_post       = spaces_post[\"preds_raw\"]\n",
    "true_raw_post        = spaces_post[\"true_raw\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375dc752",
   "metadata": {},
   "source": [
    "### Re-fit ridge calibrator (post-EWC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "998dfcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_cal2, Y_cal2), (X_test2, Y_test2) = split_for_calibration(preds_ov_post, true_in_train_z_post, frac=CAL_SPLIT_FRAC, seed=SEED)\n",
    "ridge2, best_alpha2, cv_r2 = fit_ridge_calibrator(X_cal2, Y_cal2, alphas=CAL_ALPHAS)\n",
    "joblib.dump(ridge2, os.path.join(out_dir, f\"ridge_calibrator_post_ewc_alpha{best_alpha2}.pkl\"))\n",
    "\n",
    "preds_test_cal2 = ridge2.predict(X_test2)\n",
    "cal_train_post = metrics_block(Y_test2, preds_test_cal2)\n",
    "\n",
    "preds_test_cal2_raw = inverse_transform(preds_test_cal2, train_scaler.mean_[train_idx], train_scaler.scale_[train_idx])\n",
    "Y_test2_raw         = inverse_transform(Y_test2,       train_scaler.mean_[train_idx], train_scaler.scale_[train_idx])\n",
    "cal_raw_post = metrics_block(Y_test2_raw, preds_test_cal2_raw)\n",
    "\n",
    "# Save metrics summary\n",
    "pd.DataFrame({\n",
    "    \"metric\":     [\"pearson\",\"spearman\",\"mae\"],\n",
    "    \"pre_train\":  [base_train[\"pearson\"], base_train[\"spearman\"], base_train[\"mae\"]],\n",
    "    \"pre_raw\":    [base_raw[\"pearson\"],   base_raw[\"spearman\"],   base_raw[\"mae\"]],\n",
    "    \"post_train\": [cal_train_post[\"pearson\"], cal_train_post[\"spearman\"], cal_train_post[\"mae\"]],\n",
    "    \"post_raw\":   [cal_raw_post[\"pearson\"],   cal_raw_post[\"spearman\"],   cal_raw_post[\"mae\"]],\n",
    "}).to_csv(os.path.join(out_dir, \"metrics_pre_post_ewc.csv\"), index=False)\n",
    "\n",
    "scatter_plot(Y_test2_raw, preds_test_cal2_raw,\n",
    "                f\"{EVAL_SAMPLE_NAME} {CHROM_ID}: Predicted vs Actual (calibrated, test split, post-EWC)\",\n",
    "                os.path.join(out_dir, \"scatter_calibrated_test_post_ewc.png\"))\n",
    "\n",
    "# Per-gene corr (post-EWC, calibrated)\n",
    "gene_corr2 = []\n",
    "for j, g in enumerate(spaces_post[\"overlap_genes\"]):\n",
    "    y, yhat = Y_test2_raw[:, j], preds_test_cal2_raw[:, j]\n",
    "    r = pearsonr(y, yhat)[0] if np.std(y) > 1e-8 else 0.0\n",
    "    gene_corr2.append((g, r))\n",
    "pd.DataFrame(gene_corr2, columns=[\"gene\",\"pearson\"]).sort_values(\"pearson\", ascending=False)\\\n",
    "    .to_csv(os.path.join(out_dir, \"per_gene_pearson_test_post_ewc.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12372387",
   "metadata": {},
   "source": [
    "## Output Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9657868d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Summary ==\n",
      "Pre-EWC (train z): r=0.346 | Pre-EWC (raw): r=0.340\n",
      "Post-EWC (train z): r=0.428 | Post-EWC (raw): r=0.441\n",
      "(Pre ridge α=10.0, CV r=0.514)  (Post ridge α=3.0, CV r=0.488)\n",
      "Artifacts in: /gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/output/transformer_testing_output/infer_mESC_holdout_chr1\n"
     ]
    }
   ],
   "source": [
    "# Save matrices for reproducibility\n",
    "pd.DataFrame(preds_test_cal2_raw, columns=spaces_post[\"overlap_genes\"])\\\n",
    "    .to_csv(os.path.join(out_dir, \"predictions_calibrated_test_post_ewc.csv\"), index=False)\n",
    "pd.DataFrame(Y_test2_raw, columns=spaces_post[\"overlap_genes\"])\\\n",
    "    .to_csv(os.path.join(out_dir, \"truth_raw_test_post_ewc.csv\"), index=False)\n",
    "\n",
    "# Console summary\n",
    "print(\"\\n== Summary ==\")\n",
    "print(f\"Pre-EWC (train z): r={base_train['pearson']:.3f} | Pre-EWC (raw): r={base_raw['pearson']:.3f}\")\n",
    "print(f\"Post-EWC (train z): r={cal_train_post['pearson']:.3f} | Post-EWC (raw): r={cal_raw_post['pearson']:.3f}\")\n",
    "print(f\"(Pre ridge α={best_alpha}, CV r={cv_r:.3f})  (Post ridge α={best_alpha2}, CV r={cv_r2:.3f})\")\n",
    "print(f\"Artifacts in: {out_dir}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
