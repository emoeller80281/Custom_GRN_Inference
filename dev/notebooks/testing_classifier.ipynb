{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24529589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TF       TG  reg_potential  motif_density  mean_tf_expr  mean_tg_expr  \\\n",
      "0    RORB  TAMALIN            0.0       0.000000      0.013821      0.024140   \n",
      "1  ZFP711    RAB39            0.0       3.737670      0.045856      0.018254   \n",
      "2   TRP73    CYYR1            0.0       3.555348      0.014798      0.045602   \n",
      "3    HHEX    CPED1            0.0       3.218876      0.020696      0.021737   \n",
      "4    ZEB1  GM16126            0.0       0.000000      0.075492      0.008900   \n",
      "\n",
      "   expr_product  log_reg_pot  motif_present  label  ...  \\\n",
      "0      0.000334          0.0              0      0  ...   \n",
      "1      0.000837          0.0              1      0  ...   \n",
      "2      0.000675          0.0              1      0  ...   \n",
      "3      0.000450          0.0              1      0  ...   \n",
      "4      0.000672          0.0              0      0  ...   \n",
      "\n",
      "   string_database_score  string_textmining_score  string_combined_score  \\\n",
      "0                    NaN                      NaN                    NaN   \n",
      "1                    NaN                      NaN                    NaN   \n",
      "2                    NaN                      NaN                    NaN   \n",
      "3                    NaN                      NaN                    NaN   \n",
      "4                    NaN                      NaN                    NaN   \n",
      "\n",
      "   trrust_sign  trrust_regulation  trrust_pmids  trrust_support_n  \\\n",
      "0          NaN               None          None               NaN   \n",
      "1          NaN               None          None               NaN   \n",
      "2          NaN               None          None               NaN   \n",
      "3          NaN               None          None               NaN   \n",
      "4          NaN               None          None               NaN   \n",
      "\n",
      "   kegg_signal  kegg_n_pathways kegg_pathways  \n",
      "0          NaN              NaN          None  \n",
      "1          NaN              NaN          None  \n",
      "2          NaN              NaN          None  \n",
      "3          NaN              NaN          None  \n",
      "4          NaN              NaN          None  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "mesc_sample_dir = \"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/data/processed/mESC\"\n",
    "\n",
    "mesc_first_sample_data_df = pd.read_parquet(os.path.join(mesc_sample_dir, \"E7.5_rep1/tf_tg_data.parquet\"))\n",
    "print(mesc_first_sample_data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6abbc03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TF', 'TG', 'reg_potential', 'motif_density', 'mean_tf_expr',\n",
      "       'mean_tg_expr', 'expr_product', 'log_reg_pot', 'motif_present', 'label',\n",
      "       'in_STRING', 'in_TRRUST', 'in_KEGG', 'n_sources',\n",
      "       'string_experimental_score', 'string_database_score',\n",
      "       'string_textmining_score', 'string_combined_score', 'trrust_sign',\n",
      "       'trrust_regulation', 'trrust_pmids', 'trrust_support_n', 'kegg_signal',\n",
      "       'kegg_n_pathways', 'kegg_pathways'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(mesc_first_sample_data_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9304d5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TF', 'TG', 'reg_potential', 'motif_density', 'mean_tf_expr',\n",
      "       'mean_tg_expr', 'expr_product', 'log_reg_pot', 'motif_present'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "edge_columns = ['TF', 'TG']\n",
    "score_columns = ['reg_potential', 'motif_density', 'mean_tf_expr', 'mean_tg_expr', 'expr_product', 'log_reg_pot', 'motif_present']\n",
    "\n",
    "mesc_first_sample_data_df = mesc_first_sample_data_df[edge_columns + score_columns]\n",
    "print(mesc_first_sample_data_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c3a989b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emb remap] TF matched 256/256; TG matched 21/2669\n",
      "[Emb remap] TF matched 256/256; TG matched 21/2669\n"
     ]
    }
   ],
   "source": [
    "import torch, csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "PRETRAINED_EMB_DIR = \"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/experiments/mESC/MULTI/model_training_011\"\n",
    "\n",
    "def _norm_gene(n):\n",
    "    return str(n).strip().upper() if n is not None else None\n",
    "\n",
    "def load_and_align_pretrained(embeddings_pt, vocab_pt, tf_classes, tg_classes, init=\"zeros\"):\n",
    "    \"\"\"\n",
    "    Align pretrained TF/TG vectors to the TF/TG label spaces defined by your ChIP-seq file.\n",
    "    Returns (tf_init, tg_init, D, stats_dict).\n",
    "    \"\"\"\n",
    "    emb_bundle = torch.load(embeddings_pt, map_location=\"cpu\")\n",
    "    lab_bundle = torch.load(vocab_pt, map_location=\"cpu\")\n",
    "\n",
    "    tf_src = emb_bundle[\"tf_emb\"]  # [T_src, D]\n",
    "    tg_src = emb_bundle[\"tg_emb\"]  # [G_src, D]\n",
    "    D = tf_src.shape[1]\n",
    "\n",
    "    src_tf_id2name = lab_bundle[\"tf_id2name\"]\n",
    "    src_tg_id2name = lab_bundle[\"tg_id2name\"]\n",
    "    name_to_old_tf = { _norm_gene(n): i for i, n in enumerate(src_tf_id2name) if n is not None }\n",
    "    name_to_old_tg = { _norm_gene(n): i for i, n in enumerate(src_tg_id2name) if n is not None }\n",
    "\n",
    "    def _align(classes, name_to_old, src_vecs):\n",
    "        out = torch.zeros(len(classes), D)\n",
    "        if init == \"normal\":\n",
    "            torch.nn.init.normal_(out, mean=0.0, std=0.02)\n",
    "        hits = 0\n",
    "        for j, name in enumerate(classes):\n",
    "            i = name_to_old.get(_norm_gene(name), None)\n",
    "            if i is None or i < 0 or i >= src_vecs.shape[0]:\n",
    "                continue\n",
    "            out[j] = src_vecs[i]\n",
    "            hits += 1\n",
    "        return out, hits, len(classes) - hits\n",
    "\n",
    "    tf_init, tf_hits, tf_miss = _align(tf_classes, name_to_old_tf, tf_src)\n",
    "    tg_init, tg_hits, tg_miss = _align(tg_classes, name_to_old_tg, tg_src)\n",
    "    stats = {\"tf_hits\": tf_hits, \"tf_total\": len(tf_classes), \"tg_hits\": tg_hits, \"tg_total\": len(tg_classes)}\n",
    "    print(f\"[Emb remap] TF matched {tf_hits}/{len(tf_classes)}; TG matched {tg_hits}/{len(tg_classes)}\")\n",
    "    return tf_init, tg_init, D, stats\n",
    "\n",
    "def read_edges_name_indexed_tsv(path, chipseq_sep, tf_col_name, tg_col_name):\n",
    "    # expects columns: tf, tg, optional weight\n",
    "    rows = []\n",
    "    with open(path) as f:\n",
    "        r = csv.DictReader(f, delimiter=chipseq_sep)\n",
    "        for row in r:\n",
    "            tf = row.get(tf_col_name)\n",
    "            tg = row.get(tg_col_name)\n",
    "            if tf is None or tg is None:\n",
    "                continue\n",
    "            w = 1.0\n",
    "            ws = row.get(\"weight\", \"\")\n",
    "            if ws not in (\"\", None):\n",
    "                try: w = float(ws)\n",
    "                except: pass\n",
    "            rows.append((str(tf), str(tg), w))\n",
    "    return rows\n",
    "\n",
    "def build_encoders_from_edges(name_edges):\n",
    "    tf_names = [tf for tf, _, _ in name_edges]\n",
    "    tg_names = [tg for _, tg, _ in name_edges]\n",
    "    tf_enc = LabelEncoder().fit(tf_names)\n",
    "    tg_enc = LabelEncoder().fit(tg_names)\n",
    "    return tf_enc, tg_enc\n",
    "\n",
    "def map_edges_to_local_indices(name_edges, tf_enc, tg_enc):\n",
    "    tf_ids = tf_enc.transform([tf for tf, _, _ in name_edges]).tolist()\n",
    "    tg_ids = tg_enc.transform([tg for _, tg, _ in name_edges]).tolist()\n",
    "    weights = [w for _, _, w in name_edges]\n",
    "    edges = list(zip(tf_ids, tg_ids, weights))  # TG indices are 0..n_tg-1 (NO offset)\n",
    "    return edges\n",
    "\n",
    "def verify_vocab_alignment(tf_mat, tg_mat, tf_id2name, tg_id2name):\n",
    "    n_tf_tensor = tf_mat.shape[0]\n",
    "    n_tg_tensor = tg_mat.shape[0]\n",
    "    n_tf_vocab  = len(tf_id2name)\n",
    "    n_tg_vocab  = len(tg_id2name)\n",
    "\n",
    "    # Hard fail if clear mismatch\n",
    "    if n_tf_tensor != n_tf_vocab or n_tg_tensor != n_tg_vocab:\n",
    "        raise RuntimeError(\n",
    "            f\"Vocab/embedding mismatch:\\n\"\n",
    "            f\"  TF: tensor rows={n_tf_tensor}, vocab len={n_tf_vocab}\\n\"\n",
    "            f\"  TG: tensor rows={n_tg_tensor}, vocab len={n_tg_vocab}\\n\"\n",
    "            f\"Make sure tf_tg_embeddings.pt and tf_tg_vocab_id2name.pt come from the SAME run.\"\n",
    "        )\n",
    "\n",
    "    # Optional: check for Nones in id2name (holes)\n",
    "    bad_tf = [i for i, n in enumerate(tf_id2name) if n is None]\n",
    "    bad_tg = [i for i, n in enumerate(tg_id2name) if n is None]\n",
    "    if bad_tf or bad_tg:\n",
    "        raise RuntimeError(\n",
    "            f\"id2name contains holes (None). \"\n",
    "            f\"Bad TF idx: {bad_tf[:10]}...  Bad TG idx: {bad_tg[:10]}...\\n\"\n",
    "            f\"Rebuild id2name from the exact vocab used to train/save the embeddings.\"\n",
    "        )\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1) Normalize TF/TG names the same way everywhere (matches _norm_gene)\n",
    "df = mesc_first_sample_data_df.copy()\n",
    "df[\"TF\"] = df[\"TF\"].astype(str).str.upper().str.strip()\n",
    "df[\"TG\"] = df[\"TG\"].astype(str).str.upper().str.strip()\n",
    "\n",
    "# 2) Choose a weight column if you want edges to carry strength; else default 1.0\n",
    "#    Common choices you have available: 'reg_potential', 'log_reg_pot', or a binary like 'motif_present'.\n",
    "WEIGHT_COL = \"reg_potential\" if \"reg_potential\" in df.columns else None\n",
    "\n",
    "if WEIGHT_COL:\n",
    "    df[\"weight\"] = pd.to_numeric(df[WEIGHT_COL], errors=\"coerce\").fillna(1.0)\n",
    "else:\n",
    "    df[\"weight\"] = 1.0\n",
    "\n",
    "# 3) Make unique (TF,TG) pairs and keep one weight per pair (first occurrence)\n",
    "df_unique = df[[\"TF\", \"TG\", \"weight\"]].dropna().drop_duplicates(subset=[\"TF\", \"TG\"], keep=\"first\")\n",
    "\n",
    "# 4) Build the triplet list your downstream functions expect\n",
    "name_edges = list(map(tuple, df_unique.itertuples(index=False, name=None)))\n",
    "\n",
    "# 5) Proceed as before\n",
    "tf_enc, tg_enc = build_encoders_from_edges(name_edges)\n",
    "tf_classes = list(tf_enc.classes_)\n",
    "tg_classes = list(tg_enc.classes_)\n",
    "\n",
    "from pathlib import Path\n",
    "embeddings_pt = Path(PRETRAINED_EMB_DIR) / \"tf_tg_embeddings.pt\"\n",
    "vocab_pt = Path(PRETRAINED_EMB_DIR) / \"tf_tg_vocab_id2name.pt\"\n",
    "\n",
    "tf_init, tg_init, D, _stats = load_and_align_pretrained(\n",
    "    embeddings_pt, vocab_pt, tf_classes, tg_classes, init=\"zeros\"\n",
    ")\n",
    "\n",
    "edges = map_edges_to_local_indices(name_edges, tf_enc, tg_enc)\n",
    "\n",
    "# Optional sanity checks\n",
    "n_tf, n_tg = tf_init.shape[0], tg_init.shape[0]\n",
    "for k, (i, j, _) in enumerate(edges[:1000]):\n",
    "    assert 0 <= i < n_tf and 0 <= j < n_tg, f\"Edge {k} out of range: tf={i}, tg={j}, n_tf={n_tf}, n_tg={n_tg}\"\n",
    "\n",
    "\n",
    "tf_enc, tg_enc = build_encoders_from_edges(name_edges)\n",
    "tf_classes = list(tf_enc.classes_)  # strings\n",
    "tg_classes = list(tg_enc.classes_)\n",
    "\n",
    "embeddings_pt = Path(PRETRAINED_EMB_DIR) / \"tf_tg_embeddings.pt\"\n",
    "vocab_pt = Path(PRETRAINED_EMB_DIR) / \"tf_tg_vocab_id2name.pt\"\n",
    "\n",
    "# --- 3) Load pretrained tensors and ALIGN by name to these classes\n",
    "tf_init, tg_init, D, _stats = load_and_align_pretrained(\n",
    "    embeddings_pt, vocab_pt, tf_classes, tg_classes, init=\"zeros\"\n",
    ")\n",
    "\n",
    "# --- 4) Map edges to local integer indices (NO TG offset)\n",
    "edges = map_edges_to_local_indices(name_edges, tf_enc, tg_enc)\n",
    "\n",
    "# Optional sanity checks (prevents IndexError by construction)\n",
    "n_tf, n_tg = tf_init.shape[0], tg_init.shape[0]\n",
    "for k, (i, j, _) in enumerate(edges[:1000]):  # spot check a slice\n",
    "    assert 0 <= i < n_tf and 0 <= j < n_tg, f\"Edge {k} out of range: tf={i}, tg={j}, n_tf={n_tf}, n_tg={n_tg}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f806aaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TF             TG  pseudo_label  pseudo_prob_true\n",
      "0  ZFP521  2610035D17RIK             1               1.0\n",
      "1  ZBTB40  2210408I21RIK             1               1.0\n",
      "2  ZFP423  2610035D17RIK             1               1.0\n",
      "3  ZFP521  1700034P13RIK             1               1.0\n",
      "4   SALL3  2310040G24RIK             1               1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def _to_numpy(t):\n",
    "    try:\n",
    "        import torch\n",
    "        if isinstance(t, torch.Tensor):\n",
    "            return t.detach().cpu().numpy()\n",
    "    except ImportError:\n",
    "        pass\n",
    "    return np.asarray(t)\n",
    "\n",
    "def build_feature_matrix(df, tf_enc, tg_enc, tf_init, tg_init, verbose=True):\n",
    "    if verbose:\n",
    "        print(\"\\n[build_feature_matrix] Starting...\")\n",
    "        print(f\"[build_feature_matrix] Incoming df shape: {df.shape}\")\n",
    "        print(f\"[build_feature_matrix] Incoming columns: {list(df.columns)}\")\n",
    "    # Normalize TF/TG the same way as earlier code\n",
    "    df = df.copy()\n",
    "    df[\"TF\"] = df[\"TF\"].astype(str).str.upper().str.strip()\n",
    "    df[\"TG\"] = df[\"TG\"].astype(str).str.upper().str.strip()\n",
    "\n",
    "    # Keep only necessary columns\n",
    "    cols = [\n",
    "        \"reg_potential\", \"motif_density\", \"mean_tf_expr\", \"mean_tg_expr\",\n",
    "        \"expr_product\", \"log_reg_pot\", \"motif_present\"\n",
    "    ]\n",
    "    present = [c for c in cols if c in df.columns]\n",
    "    use_df = df[[\"TF\", \"TG\"] + present].dropna(subset=[\"TF\", \"TG\"]).copy()\n",
    "\n",
    "    # Map names -> local indices used by the embedding matrices\n",
    "    tf_ids = tf_enc.transform(use_df[\"TF\"])\n",
    "    tg_ids = tg_enc.transform(use_df[\"TG\"])\n",
    "\n",
    "    # Convert embeddings to numpy\n",
    "    TF = _to_numpy(tf_init)\n",
    "    TG = _to_numpy(tg_init)\n",
    "\n",
    "    # Dot product similarity between TF/TG embeddings (shape: [N])\n",
    "    dot_sim = np.einsum(\"nd,nd->n\", TF[tf_ids], TG[tg_ids])\n",
    "\n",
    "    # Numeric features—ensure numeric dtype\n",
    "    X_extra = use_df[present].copy()\n",
    "    if \"motif_present\" in X_extra.columns:\n",
    "        # Coerce to 0/1 (handles True/False, '0'/'1', etc.)\n",
    "        X_extra[\"motif_present\"] = pd.to_numeric(X_extra[\"motif_present\"], errors=\"coerce\").fillna(0.0).clip(0, 1)\n",
    "\n",
    "    X = np.column_stack([dot_sim, X_extra.to_numpy(dtype=float)])\n",
    "    feature_names = [\"dot_sim\"] + list(X_extra.columns)\n",
    "    return use_df[[\"TF\",\"TG\"]].reset_index(drop=True), X, feature_names\n",
    "\n",
    "def unsupervised_svm_two_groups(df, tf_enc, tg_enc, tf_init, tg_init, kernel=\"rbf\", C=1.0, gamma=\"scale\", random_state=42):\n",
    "    # 1) Build features\n",
    "    pairs, X_raw, feature_names = build_feature_matrix(df, tf_enc, tg_enc, tf_init, tg_init)\n",
    "\n",
    "    # 2) Impute + scale\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(imputer.fit_transform(X_raw))\n",
    "\n",
    "    # 3) Unsupervised 2-component model → pseudo-labels\n",
    "    gmm = GaussianMixture(n_components=2, covariance_type=\"full\", random_state=random_state)\n",
    "    cluster = gmm.fit_predict(X)\n",
    "\n",
    "    # 4) Orient labels so that the component with higher mean dot_sim = True(=1)\n",
    "    dot_idx = feature_names.index(\"dot_sim\")\n",
    "    mean_dot_by_cluster = [X_raw[cluster==k, dot_idx].mean() if np.any(cluster==k) else -np.inf for k in (0,1)]\n",
    "    true_label = int(np.argmax(mean_dot_by_cluster))   # which cluster looks more \"True\"\n",
    "    y_pseudo = (cluster == true_label).astype(int)\n",
    "\n",
    "    # 5) Train an SVM on the pseudo-labels\n",
    "    svm = SVC(kernel=kernel, C=C, gamma=gamma, class_weight=\"balanced\", probability=True, random_state=random_state)\n",
    "    svm.fit(X, y_pseudo)\n",
    "\n",
    "    # 6) Return everything useful\n",
    "    out = pd.DataFrame({\n",
    "        \"TF\": pairs[\"TF\"],\n",
    "        \"TG\": pairs[\"TG\"],\n",
    "        \"pseudo_label\": y_pseudo,\n",
    "        \"pseudo_prob_true\": svm.predict_proba(X)[:, 1]\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        \"svm\": svm,\n",
    "        \"scaler\": scaler,\n",
    "        \"imputer\": imputer,\n",
    "        \"gmm\": gmm,\n",
    "        \"feature_names\": feature_names,\n",
    "        \"assignments\": out.sort_values(\"pseudo_prob_true\", ascending=False).reset_index(drop=True)\n",
    "    }\n",
    "\n",
    "# --- Example usage ---\n",
    "result = unsupervised_svm_two_groups(\n",
    "    mesc_first_sample_data_df,\n",
    "    tf_enc=tf_enc,\n",
    "    tg_enc=tg_enc,\n",
    "    tf_init=tf_init,\n",
    "    tg_init=tg_init,\n",
    "    kernel=\"rbf\",         # you can switch to \"linear\"\n",
    "    C=1.0,\n",
    "    gamma=\"scale\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "assignments = result[\"assignments\"]\n",
    "print(assignments.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c9e13cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assignments['pseudo_prob_true'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de3a7c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_df = assignments[[\"TF\", \"TG\", \"pseudo_prob_true\"]].rename(columns={\"TF\":\"Source\", \"TG\":\"Target\", \"pseudo_prob_true\": \"Score\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea267366",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_df.to_csv(\"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/outputs/inferred_grn_svm.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
