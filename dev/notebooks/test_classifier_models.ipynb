{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd304243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/Home/esm5360/.conda/envs/my_env/lib/python3.9/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /lib64/libm.so.6: version `GLIBC_2.29' not found (required by /gpfs/Home/esm5360/.conda/envs/my_env/lib/python3.9/site-packages/libpyg.so)\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/gpfs/Home/esm5360/.conda/envs/my_env/lib/python3.9/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /lib64/libc.so.6: version `GLIBC_2.32' not found (required by /gpfs/Home/esm5360/.conda/envs/my_env/lib/python3.9/site-packages/torch_scatter/_version_cuda.so)\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/gpfs/Home/esm5360/.conda/envs/my_env/lib/python3.9/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /lib64/libc.so.6: version `GLIBC_2.32' not found (required by /gpfs/Home/esm5360/.conda/envs/my_env/lib/python3.9/site-packages/torch_cluster/_version_cuda.so)\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "/gpfs/Home/esm5360/.conda/envs/my_env/lib/python3.9/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /lib64/libc.so.6: version `GLIBC_2.32' not found (required by /gpfs/Home/esm5360/.conda/envs/my_env/lib/python3.9/site-packages/torch_spline_conv/_version_cuda.so)\n",
      "  warnings.warn(\n",
      "/gpfs/Home/esm5360/.conda/envs/my_env/lib/python3.9/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /lib64/libc.so.6: version `GLIBC_2.32' not found (required by /gpfs/Home/esm5360/.conda/envs/my_env/lib/python3.9/site-packages/torch_sparse/_version_cuda.so)\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'type' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 30\u001b[0m\n\u001b[1;32m     23\u001b[0m logging\u001b[38;5;241m.\u001b[39mbasicConfig(level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mINFO, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(message)s\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Paths / config\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmultiomic_transformer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiomicTransformer\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmultiomic_transformer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiChromosomeDataset, SimpleScaler, fit_simple_scalers\n\u001b[1;32m     33\u001b[0m experiment \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m256_4_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/src/multiomic_transformer/models/model.py:126\u001b[0m\n\u001b[1;32m    123\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(res)\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mTFtoTGShortcut\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    129\u001b[0m         d_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m         motif_prior_scale: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m,             \u001b[38;5;66;03m# >0 to use soft prior\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     ):\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "File \u001b[0;32m/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/src/multiomic_transformer/models/model.py:133\u001b[0m, in \u001b[0;36mTFtoTGShortcut\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mTFtoTGShortcut\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    129\u001b[0m         d_model,\n\u001b[1;32m    130\u001b[0m         use_motif_mask: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    131\u001b[0m         lambda_l1: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-4\u001b[39m,\n\u001b[1;32m    132\u001b[0m         lambda_l2: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m--> 133\u001b[0m         topk: \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    134\u001b[0m         dropout_p: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m    135\u001b[0m         motif_mask_threshold: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# in -log10(p)\u001b[39;00m\n\u001b[1;32m    136\u001b[0m         motif_prior_scale: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m,             \u001b[38;5;66;03m# >0 to use soft prior\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     ):\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.1\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'type' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# transformer_testing.py\n",
    "import os, sys, json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from matplotlib.ticker import FuncFormatter, MultipleLocator\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "PROJECT_DIR = \"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER\"\n",
    "SRC_DIR = str(Path(PROJECT_DIR) / \"src\")\n",
    "if SRC_DIR not in sys.path:\n",
    "    sys.path.insert(0, SRC_DIR)\n",
    "\n",
    "from datetime import datetime\n",
    "from config.settings_hpc import *\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Paths / config\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "from multiomic_transformer.models.model import MultiomicTransformer\n",
    "from multiomic_transformer.datasets.dataset import MultiChromosomeDataset, SimpleScaler, fit_simple_scalers\n",
    "\n",
    "experiment = \"256_4_layers\"\n",
    "SELECTED_EXPERIMENT_DIR = OUTPUT_DIR / \"all_chroms_model_size_testing\" / experiment\n",
    "gpu_log_file = Path(PROJECT_DIR) / \"LOGS\" / \"transformer_logs\" / \"03_training\" / \"gpu_usage_transformer_training_3409891.20251107_155906.csv\"\n",
    "\n",
    "GROUND_TRUTH_DIR = os.path.join(PROJECT_DIR, \"data/ground_truth_files\")\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH  = 32\n",
    "TG_CHUNK = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4135c154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TF",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TG",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reg_potential",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "motif_density",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_tf_expr",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "mean_tg_expr",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "expr_product",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "log_reg_pot",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "motif_present",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "in_STRING",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "in_TRRUST",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "in_KEGG",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_sources",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "string_experimental_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "string_database_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "string_textmining_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "string_combined_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trrust_sign",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trrust_regulation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "trrust_pmids",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "trrust_support_n",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "kegg_signal",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "kegg_n_pathways",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "kegg_pathways",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "9f9c71c2-e496-4498-9a47-7bcbea07c459",
       "rows": [
        [
         "0",
         "RORB",
         "TAMALIN",
         "0.0",
         "0.0",
         "0.009336619",
         "0.012839624",
         "0.00011987867",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "1",
         "ZFP711",
         "RAB39",
         "0.0",
         "0.0",
         "0.04585585",
         "0.012976407",
         "0.00059504417",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2",
         "TRP73",
         "CYYR1",
         "0.0",
         "0.6931471805599453",
         "0.008033529",
         "0.045601826",
         "0.0003663436",
         "0.0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "3",
         "HHEX",
         "CPED1",
         "0.0",
         "1.0986122886681098",
         "0.017146219",
         "0.016808927",
         "0.00028820953",
         "0.0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "4",
         "ZEB1",
         "GM16126",
         "0.0",
         "0.0",
         "0.07549221",
         "0.00453549",
         "0.00034239417",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 25,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>TG</th>\n",
       "      <th>reg_potential</th>\n",
       "      <th>motif_density</th>\n",
       "      <th>mean_tf_expr</th>\n",
       "      <th>mean_tg_expr</th>\n",
       "      <th>expr_product</th>\n",
       "      <th>log_reg_pot</th>\n",
       "      <th>motif_present</th>\n",
       "      <th>label</th>\n",
       "      <th>...</th>\n",
       "      <th>string_database_score</th>\n",
       "      <th>string_textmining_score</th>\n",
       "      <th>string_combined_score</th>\n",
       "      <th>trrust_sign</th>\n",
       "      <th>trrust_regulation</th>\n",
       "      <th>trrust_pmids</th>\n",
       "      <th>trrust_support_n</th>\n",
       "      <th>kegg_signal</th>\n",
       "      <th>kegg_n_pathways</th>\n",
       "      <th>kegg_pathways</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RORB</td>\n",
       "      <td>TAMALIN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009337</td>\n",
       "      <td>0.012840</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZFP711</td>\n",
       "      <td>RAB39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045856</td>\n",
       "      <td>0.012976</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRP73</td>\n",
       "      <td>CYYR1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.045602</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HHEX</td>\n",
       "      <td>CPED1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.017146</td>\n",
       "      <td>0.016809</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZEB1</td>\n",
       "      <td>GM16126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075492</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TF       TG  reg_potential  motif_density  mean_tf_expr  mean_tg_expr  \\\n",
       "0    RORB  TAMALIN            0.0       0.000000      0.009337      0.012840   \n",
       "1  ZFP711    RAB39            0.0       0.000000      0.045856      0.012976   \n",
       "2   TRP73    CYYR1            0.0       0.693147      0.008034      0.045602   \n",
       "3    HHEX    CPED1            0.0       1.098612      0.017146      0.016809   \n",
       "4    ZEB1  GM16126            0.0       0.000000      0.075492      0.004535   \n",
       "\n",
       "   expr_product  log_reg_pot  motif_present  label  ...  \\\n",
       "0      0.000120          0.0              0      0  ...   \n",
       "1      0.000595          0.0              0      0  ...   \n",
       "2      0.000366          0.0              1      0  ...   \n",
       "3      0.000288          0.0              1      0  ...   \n",
       "4      0.000342          0.0              0      0  ...   \n",
       "\n",
       "   string_database_score  string_textmining_score  string_combined_score  \\\n",
       "0                    NaN                      NaN                    NaN   \n",
       "1                    NaN                      NaN                    NaN   \n",
       "2                    NaN                      NaN                    NaN   \n",
       "3                    NaN                      NaN                    NaN   \n",
       "4                    NaN                      NaN                    NaN   \n",
       "\n",
       "   trrust_sign  trrust_regulation  trrust_pmids  trrust_support_n  \\\n",
       "0          NaN               None          None               NaN   \n",
       "1          NaN               None          None               NaN   \n",
       "2          NaN               None          None               NaN   \n",
       "3          NaN               None          None               NaN   \n",
       "4          NaN               None          None               NaN   \n",
       "\n",
       "   kegg_signal  kegg_n_pathways kegg_pathways  \n",
       "0          NaN              NaN          None  \n",
       "1          NaN              NaN          None  \n",
       "2          NaN              NaN          None  \n",
       "3          NaN              NaN          None  \n",
       "4          NaN              NaN          None  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dfs = []\n",
    "data_dir = \"data/processed/mESC_no_scale_linear\"\n",
    "for sample in SAMPLE_NAMES:\n",
    "    sample_dir = os.path.join(data_dir, sample)\n",
    "    file = os.path.join(sample_dir, \"tf_tg_data.parquet\")\n",
    "    if os.path.isfile(file):\n",
    "        data_dfs.append(pd.read_parquet(file))\n",
    "total_tf_tg_data = pd.concat(data_dfs)\n",
    "total_tf_tg_data.head()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a454a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total candidate pairs (universe): 597760\n",
      "Strict positives: 18804, strict neg candidates: 7056\n",
      "Pseudo-labeled training set size: 25860 (pos=18804, neg=7056, pos_frac=0.727)\n",
      "Epoch 01: train_loss=0.3912, val_loss=0.3793\n",
      "Epoch 02: train_loss=0.3649, val_loss=0.3549\n",
      "Epoch 03: train_loss=0.3410, val_loss=0.3322\n",
      "Epoch 04: train_loss=0.3184, val_loss=0.3102\n",
      "Epoch 05: train_loss=0.2965, val_loss=0.2882\n",
      "Epoch 06: train_loss=0.2746, val_loss=0.2663\n",
      "Epoch 07: train_loss=0.2528, val_loss=0.2444\n",
      "Epoch 08: train_loss=0.2312, val_loss=0.2227\n",
      "Epoch 09: train_loss=0.2100, val_loss=0.2016\n",
      "Epoch 10: train_loss=0.1894, val_loss=0.1813\n",
      "Epoch 11: train_loss=0.1698, val_loss=0.1621\n",
      "Epoch 12: train_loss=0.1515, val_loss=0.1443\n",
      "Epoch 13: train_loss=0.1346, val_loss=0.1281\n",
      "Epoch 14: train_loss=0.1194, val_loss=0.1136\n",
      "Epoch 15: train_loss=0.1058, val_loss=0.1007\n",
      "\n",
      "=== ChIP eval on full universe (all TFs) ===\n",
      "Total pairs: 597760\n",
      "GT pairs:    11423\n",
      "GT fraction: 0.019110\n",
      "\n",
      "[All TFs] GT enrichment in high-score pairs vs rest:\n",
      " quantile  threshold  top_n  top_gt_frac  bottom_n  bottom_gt_frac  enrichment_fold\n",
      " 0.900000   0.909535  59777     0.029075    537983        0.018002         1.615045\n",
      " 0.950000   0.926344  29888     0.031819    567872        0.018441         1.725458\n",
      " 0.990000   0.948934   5978     0.040482    591782        0.018894         2.142597\n",
      " 0.995000   0.955209   2989     0.039478    594771        0.019007         2.076994\n",
      "\n",
      "[All TFs] Mann–Whitney (GT > non-GT): p=1.821e-284, GT mean=0.6810, non-GT mean=0.5925\n",
      "[All TFs] AUROC=0.5982, AUPR=0.0260\n",
      "\n",
      "=== ChIP eval (ChIP TFs only) ===\n",
      "Pairs with TF in ChIP set: 53705\n",
      "GT pairs in this subset:   11423\n",
      "GT fraction:               0.212699\n",
      "\n",
      "[ChIP TFs only] GT enrichment in high-score pairs vs rest:\n",
      " quantile  threshold  top_n  top_gt_frac  bottom_n  bottom_gt_frac  enrichment_fold\n",
      " 0.900000   0.914513   5371     0.274064     48334        0.205880         1.331186\n",
      " 0.950000   0.929776   2686     0.298585     51019        0.208177         1.434283\n",
      " 0.990000   0.950702    538     0.373606     53167        0.211071         1.770051\n",
      " 0.995000   0.956492    269     0.382900     53436        0.211842         1.807476\n",
      "\n",
      "[ChIP TFs only] Mann–Whitney (GT > non-GT): p=1.325e-69, GT mean=0.6810, non-GT mean=0.6480\n",
      "[ChIP TFs only] AUROC=0.5536, AUPR=0.2485\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    "    accuracy_score,\n",
    ")\n",
    "from scipy.stats import mannwhitneyu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# =========================\n",
    "# 1) Build pseudo-labeled set\n",
    "# =========================\n",
    "\n",
    "# --- Load embeddings & vocab ---\n",
    "emb = torch.load(SELECTED_EXPERIMENT_DIR / \"tf_tg_embeddings.pt\", map_location=\"cpu\")\n",
    "tf_emb = emb[\"tf_emb\"]   # [T, D]\n",
    "tg_emb = emb[\"tg_emb\"]   # [G, D]\n",
    "\n",
    "id2name = torch.load(SELECTED_EXPERIMENT_DIR / \"tf_tg_vocab_id2name.pt\", map_location=\"cpu\")\n",
    "tf_id2name = id2name[\"tf_id2name\"]\n",
    "tg_id2name = id2name[\"tg_id2name\"]\n",
    "\n",
    "tf_name2id = {n: i for i, n in enumerate(tf_id2name)}\n",
    "tg_name2id = {n: i for i, n in enumerate(tg_id2name)}\n",
    "\n",
    "tf_norm = torch.nn.functional.normalize(tf_emb, p=2, dim=1)\n",
    "tg_norm = torch.nn.functional.normalize(tg_emb, p=2, dim=1)\n",
    "\n",
    "# --- Load prior TF-TG scores ---\n",
    "df_all = total_tf_tg_data\n",
    "\n",
    "# Keep only pairs that exist in embedding vocab\n",
    "mask = df_all[\"TF\"].isin(tf_name2id) & df_all[\"TG\"].isin(tg_name2id)\n",
    "df_all = df_all[mask].copy()\n",
    "\n",
    "# Map to indices\n",
    "df_all[\"tf_id\"] = df_all[\"TF\"].map(tf_name2id)\n",
    "df_all[\"tg_id\"] = df_all[\"TG\"].map(tg_name2id)\n",
    "\n",
    "# Cosine similarity feature from embeddings\n",
    "tf_vec = tf_norm[df_all[\"tf_id\"].values]       # [N, D]\n",
    "tg_vec = tg_norm[df_all[\"tg_id\"].values]       # [N, D]\n",
    "cos_sim = (tf_vec * tg_vec).sum(dim=1).numpy()\n",
    "df_all[\"cos_sim\"] = cos_sim\n",
    "\n",
    "feat_cols = [\n",
    "    \"cos_sim\",\n",
    "    \"log_reg_pot\",\n",
    "    \"motif_density\",\n",
    "    \"motif_present\",\n",
    "    \"mean_tf_expr\",\n",
    "    \"mean_tg_expr\",\n",
    "    \"expr_product\",\n",
    "]\n",
    "\n",
    "df_all = df_all.copy()\n",
    "for c in feat_cols:\n",
    "    df_all[c] = pd.to_numeric(df_all[c], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "X_all = df_all[feat_cols].values.astype(\"float32\")\n",
    "N_all = X_all.shape[0]\n",
    "print(f\"Total candidate pairs (universe): {N_all}\")\n",
    "\n",
    "# ---------- 1. Build stricter pseudo-labels ----------\n",
    "\n",
    "# Use stricter highs/lows\n",
    "hi_logreg = df_all[\"log_reg_pot\"].quantile(0.95)\n",
    "hi_cos    = df_all[\"cos_sim\"].quantile(0.95)\n",
    "hi_expr   = df_all[\"expr_product\"].quantile(0.95)\n",
    "\n",
    "lo_logreg = df_all[\"log_reg_pot\"].quantile(0.10)\n",
    "lo_cos    = df_all[\"cos_sim\"].quantile(0.10)\n",
    "lo_expr   = df_all[\"expr_product\"].quantile(0.25)\n",
    "\n",
    "# Strong positives:\n",
    "#   motif present\n",
    "#   AND (high log_reg OR high cos)\n",
    "#   AND high-ish expr product\n",
    "pos_mask = (\n",
    "    (df_all[\"motif_present\"] == 1) &\n",
    "    ((df_all[\"log_reg_pot\"] >= hi_logreg) |\n",
    "     (df_all[\"cos_sim\"]     >= hi_cos)) &\n",
    "    (df_all[\"expr_product\"] >= hi_expr)\n",
    ")\n",
    "\n",
    "# Candidate negatives:\n",
    "#   no motif\n",
    "#   AND all signals low\n",
    "neg_strict_mask = (\n",
    "    (df_all[\"motif_present\"] == 0) &\n",
    "    (df_all[\"log_reg_pot\"] <= lo_logreg) &\n",
    "    (df_all[\"cos_sim\"]     <= lo_cos) &\n",
    "    (df_all[\"expr_product\"]<= lo_expr)\n",
    ")\n",
    "\n",
    "pos_df = df_all[pos_mask].copy()\n",
    "neg_candidates = df_all[neg_strict_mask].copy()\n",
    "\n",
    "print(f\"Strict positives: {len(pos_df)}, strict neg candidates: {len(neg_candidates)}\")\n",
    "\n",
    "if len(pos_df) == 0 or len(neg_candidates) == 0:\n",
    "    raise RuntimeError(\"No strong pos or neg with current thresholds; adjust them.\")\n",
    "\n",
    "# Sample negatives to get ~1:3 pos:neg (tunable)\n",
    "rng = np.random.default_rng(42)\n",
    "pos_n = len(pos_df)\n",
    "neg_target = min(len(neg_candidates), pos_n * 3)\n",
    "neg_df = neg_candidates.sample(neg_target, random_state=42)\n",
    "\n",
    "# Build pseudo-labeled set\n",
    "pseudo_df = pd.concat([pos_df.assign(label=1.0),\n",
    "                       neg_df.assign(label=0.0)],\n",
    "                      axis=0)\n",
    "pseudo_df = pseudo_df.sample(frac=1.0, random_state=42)\n",
    "\n",
    "X_pseudo = pseudo_df[feat_cols].values.astype(\"float32\")\n",
    "y_pseudo = pseudo_df[\"label\"].values.astype(\"float32\")\n",
    "\n",
    "N = X_pseudo.shape[0]\n",
    "print(\n",
    "    f\"Pseudo-labeled training set size: {N} \"\n",
    "    f\"(pos={int(y_pseudo.sum())}, neg={N-int(y_pseudo.sum())}, \"\n",
    "    f\"pos_frac={y_pseudo.mean():.3f})\"\n",
    ")\n",
    "\n",
    "# ---------- 2. Train/val split ----------\n",
    "idx = np.arange(N)\n",
    "rng.shuffle(idx)\n",
    "\n",
    "train_frac = 0.8\n",
    "n_train = int(train_frac * N)\n",
    "train_idx = idx[:n_train]\n",
    "val_idx   = idx[n_train:]\n",
    "\n",
    "def make_loader(X, y, idxs, batch_size=2048, shuffle=False):\n",
    "    X_t = torch.from_numpy(X[idxs]).float()\n",
    "    y_t = torch.from_numpy(y[idxs]).float()\n",
    "    ds = TensorDataset(X_t, y_t)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "train_loader = make_loader(X_pseudo, y_pseudo, train_idx, shuffle=True)\n",
    "val_loader   = make_loader(X_pseudo, y_pseudo, val_idx,   shuffle=False)\n",
    "\n",
    "# ---------- 3. Model ----------\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(len(feat_cols), 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 1),\n",
    ").to(device)\n",
    "\n",
    "# Optional: weight positives down if still dominant\n",
    "pos_frac = y_pseudo.mean()\n",
    "neg_frac = 1.0 - pos_frac\n",
    "# weight positives inversely to their frequency\n",
    "pos_weight = torch.tensor(neg_frac / max(pos_frac, 1e-6), device=device)\n",
    "bce = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "best_state = None\n",
    "EPOCHS = 15\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # train\n",
    "    model.train()\n",
    "    train_loss_sum, n_seen = 0.0, 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad()\n",
    "        logits = model(xb).squeeze(-1)\n",
    "        loss = bce(logits, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        bs = xb.size(0)\n",
    "        train_loss_sum += float(loss) * bs\n",
    "        n_seen += bs\n",
    "    train_loss = train_loss_sum / max(1, n_seen)\n",
    "\n",
    "    # val\n",
    "    model.eval()\n",
    "    val_loss_sum, n_seen = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb).squeeze(-1)\n",
    "            loss = bce(logits, yb)\n",
    "            bs = xb.size(0)\n",
    "            val_loss_sum += float(loss) * bs\n",
    "            n_seen += bs\n",
    "    val_loss = val_loss_sum / max(1, n_seen)\n",
    "\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}\")\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# ---------- 4. Score ALL pairs ----------\n",
    "with torch.no_grad():\n",
    "    logits_all = model(torch.from_numpy(X_all).float().to(device)).squeeze(-1)\n",
    "    scores_all = torch.sigmoid(logits_all).cpu().numpy()\n",
    "\n",
    "df_all[\"score_model\"] = scores_all\n",
    "\n",
    "# ---------- 5. Evaluate vs ChIP (same as before) ----------\n",
    "chip_path = \"data/ground_truth_files/mESC_beeline_ChIP-seq.csv\"\n",
    "chip_df = pd.read_csv(chip_path)\n",
    "\n",
    "chip_pairs = set(zip(chip_df[\"Gene1\"], chip_df[\"Gene2\"]))\n",
    "is_gt = np.fromiter(\n",
    "    ((tf, tg) in chip_pairs for tf, tg in zip(df_all[\"TF\"], df_all[\"TG\"])),\n",
    "    dtype=bool,\n",
    "    count=len(df_all),\n",
    ")\n",
    "df_all[\"is_gt\"] = is_gt\n",
    "\n",
    "gt_total = int(is_gt.sum())\n",
    "universe = len(df_all)\n",
    "overall_frac = gt_total / max(universe, 1)\n",
    "print(\"\\n=== ChIP eval on full universe (all TFs) ===\")\n",
    "print(f\"Total pairs: {universe}\")\n",
    "print(f\"GT pairs:    {gt_total}\")\n",
    "print(f\"GT fraction: {overall_frac:.6f}\")\n",
    "\n",
    "def enrichment_by_quantiles(scores, labels, quantiles=(0.9, 0.95, 0.99, 0.995)):\n",
    "    scores = np.asarray(scores)\n",
    "    labels = np.asarray(labels).astype(bool)\n",
    "    rows = []\n",
    "    for q in quantiles:\n",
    "        thr = np.quantile(scores, q)\n",
    "        top = scores >= thr\n",
    "        bot = ~top\n",
    "        if top.sum() == 0 or bot.sum() == 0:\n",
    "            continue\n",
    "        top_frac = labels[top].mean()\n",
    "        bot_frac = labels[bot].mean()\n",
    "        fold = (top_frac / bot_frac) if bot_frac > 0 else np.nan\n",
    "        rows.append(dict(\n",
    "            quantile=q,\n",
    "            threshold=thr,\n",
    "            top_n=int(top.sum()),\n",
    "            top_gt_frac=top_frac,\n",
    "            bottom_n=int(bot.sum()),\n",
    "            bottom_gt_frac=bot_frac,\n",
    "            enrichment_fold=fold,\n",
    "        ))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "if gt_total > 0:\n",
    "    scores = df_all[\"score_model\"].values\n",
    "    labels = df_all[\"is_gt\"].values\n",
    "\n",
    "    enrich = enrichment_by_quantiles(scores, labels)\n",
    "    print(\"\\n[All TFs] GT enrichment in high-score pairs vs rest:\")\n",
    "    print(enrich.to_string(index=False, float_format=lambda x: f\"{x:.6f}\"))\n",
    "\n",
    "    gt_scores = scores[labels]\n",
    "    non_scores = scores[~labels]\n",
    "    if len(gt_scores) > 0 and len(non_scores) > 0:\n",
    "        u, p = mannwhitneyu(gt_scores, non_scores, alternative=\"greater\")\n",
    "        print(f\"\\n[All TFs] Mann–Whitney (GT > non-GT): \"\n",
    "              f\"p={p:.3e}, GT mean={gt_scores.mean():.4f}, non-GT mean={non_scores.mean():.4f}\")\n",
    "\n",
    "    auroc = roc_auc_score(labels, scores)\n",
    "    aupr  = average_precision_score(labels, scores)\n",
    "    print(f\"[All TFs] AUROC={auroc:.4f}, AUPR={aupr:.4f}\")\n",
    "\n",
    "# ChIP TFs only\n",
    "chip_tfs = set(chip_df[\"Gene1\"].unique())\n",
    "sub = df_all[df_all[\"TF\"].isin(chip_tfs)].copy()\n",
    "scores_c = sub[\"score_model\"].values\n",
    "labels_c = sub[\"is_gt\"].values\n",
    "gt_c = int(labels_c.sum())\n",
    "univ_c = len(sub)\n",
    "frac_c = gt_c / max(univ_c, 1)\n",
    "\n",
    "print(\"\\n=== ChIP eval (ChIP TFs only) ===\")\n",
    "print(f\"Pairs with TF in ChIP set: {univ_c}\")\n",
    "print(f\"GT pairs in this subset:   {gt_c}\")\n",
    "print(f\"GT fraction:               {frac_c:.6f}\")\n",
    "\n",
    "if gt_c > 0:\n",
    "    enrich_c = enrichment_by_quantiles(scores_c, labels_c)\n",
    "    print(\"\\n[ChIP TFs only] GT enrichment in high-score pairs vs rest:\")\n",
    "    print(enrich_c.to_string(index=False, float_format=lambda x: f\"{x:.6f}\"))\n",
    "\n",
    "    gt_scores_c = scores_c[labels_c]\n",
    "    non_scores_c = scores_c[~labels_c]\n",
    "    if len(gt_scores_c) > 0 and len(non_scores_c) > 0:\n",
    "        u, p = mannwhitneyu(gt_scores_c, non_scores_c, alternative=\"greater\")\n",
    "        print(f\"\\n[ChIP TFs only] Mann–Whitney (GT > non-GT): \"\n",
    "              f\"p={p:.3e}, GT mean={gt_scores_c.mean():.4f}, non-GT mean={non_scores_c.mean():.4f}\")\n",
    "\n",
    "    auroc_c = roc_auc_score(labels_c, scores_c)\n",
    "    aupr_c  = average_precision_score(labels_c, scores_c)\n",
    "    print(f\"[ChIP TFs only] AUROC={auroc_c:.4f}, AUPR={aupr_c:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a484d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo-labeled set: 25860 rows (pos=18804, neg=7056)\n",
      "\n",
      "==== cos_only (1 feats) ====\n",
      "AUROC(all): 0.5252, AUPR(all): 0.0213\n",
      "GT mean score=0.7760, non-GT mean=0.7681, Mann-Whitney p=1.14e-20\n",
      " quantile  threshold  top_n  top_gt_frac  bottom_n  bottom_gt_frac  enrichment_fold\n",
      " 0.900000   0.876949  59777     0.023454    537983        0.018627         1.259132\n",
      " 0.950000   0.901710  29888     0.026064    567872        0.018744         1.390549\n",
      " 0.990000   0.944862   5978     0.028939    591782        0.019010         1.522297\n",
      " 0.995000   0.952749   2989     0.032118    594771        0.019044         1.686476\n",
      "\n",
      "==== motif_only (2 feats) ====\n",
      "AUROC(all): 0.5732, AUPR(all): 0.0232\n",
      "GT mean score=0.7055, non-GT mean=0.5832, Mann-Whitney p=1.29e-175\n",
      " quantile  threshold  top_n  top_gt_frac  bottom_n  bottom_gt_frac  enrichment_fold\n",
      " 0.900000   0.994067  65968     0.026119    531792        0.018240         1.431931\n",
      " 0.950000   0.995863  33418     0.026902    564342        0.018648         1.442583\n",
      " 0.990000   0.997661   7378     0.032665    590382        0.018940         1.724614\n",
      " 0.995000   0.998148   4774     0.034981    592986        0.018982         1.842869\n",
      "\n",
      "==== regpot_only (1 feats) ====\n",
      "AUROC(all): 0.4999, AUPR(all): 0.0191\n",
      "GT mean score=0.7275, non-GT mean=0.7275, Mann-Whitney p=8.48e-01\n",
      " quantile  threshold  top_n  top_gt_frac  bottom_n  bottom_gt_frac  enrichment_fold\n",
      " 0.900000   0.727512 597336     0.019105       424        0.025943         0.736404\n",
      " 0.950000   0.727512 597336     0.019105       424        0.025943         0.736404\n",
      " 0.990000   0.727512 597336     0.019105       424        0.025943         0.736404\n",
      " 0.995000   0.727512 597336     0.019105       424        0.025943         0.736404\n",
      "\n",
      "==== expr_only (3 feats) ====\n",
      "AUROC(all): 0.6273, AUPR(all): 0.0264\n",
      "GT mean score=0.6187, non-GT mean=0.5781, Mann-Whitney p=0.00e+00\n",
      " quantile  threshold  top_n  top_gt_frac  bottom_n  bottom_gt_frac  enrichment_fold\n",
      " 0.900000   0.740696  59776     0.025579    537984        0.018391         1.390843\n",
      " 0.950000   0.796191  29888     0.024425    567872        0.018830         1.297110\n",
      " 0.990000   0.878285   5978     0.023921    591782        0.019061         1.254968\n",
      " 0.995000   0.900865   2989     0.020743    594771        0.019101         1.085923\n",
      "\n",
      "==== cos+motif (3 feats) ====\n",
      "AUROC(all): 0.5795, AUPR(all): 0.0245\n",
      "GT mean score=0.7177, non-GT mean=0.5985, Mann-Whitney p=4.49e-187\n",
      " quantile  threshold  top_n  top_gt_frac  bottom_n  bottom_gt_frac  enrichment_fold\n",
      " 0.900000   0.995987  59777     0.026616    537983        0.018276         1.456340\n",
      " 0.950000   0.997358  29890     0.027802    567870        0.018652         1.490548\n",
      " 0.990000   0.998663   5978     0.032452    591782        0.018975         1.710277\n",
      " 0.995000   0.998971   2990     0.039465    594770        0.019007         2.076296\n",
      "\n",
      "==== cos+regpot (2 feats) ====\n",
      "AUROC(all): 0.5252, AUPR(all): 0.0213\n",
      "GT mean score=0.7595, non-GT mean=0.7533, Mann-Whitney p=1.14e-20\n",
      " quantile  threshold  top_n  top_gt_frac  bottom_n  bottom_gt_frac  enrichment_fold\n",
      " 0.900000   0.835297  59777     0.023454    537983        0.018627         1.259132\n",
      " 0.950000   0.858795  29888     0.026064    567872        0.018744         1.390549\n",
      " 0.990000   0.908264   5978     0.028939    591782        0.019010         1.522297\n",
      " 0.995000   0.916968   2989     0.032118    594771        0.019044         1.686476\n",
      "\n",
      "==== cos+motif+regpot (4 feats) ====\n",
      "AUROC(all): 0.5795, AUPR(all): 0.0245\n",
      "GT mean score=0.7184, non-GT mean=0.6003, Mann-Whitney p=4.72e-187\n",
      " quantile  threshold  top_n  top_gt_frac  bottom_n  bottom_gt_frac  enrichment_fold\n",
      " 0.900000   0.994959  59777     0.026616    537983        0.018276         1.456340\n",
      " 0.950000   0.996804  29889     0.027702    567871        0.018657         1.484799\n",
      " 0.990000   0.998558   5978     0.032787    591782        0.018972         1.728217\n",
      " 0.995000   0.998943   2990     0.039799    594770        0.019006         2.094077\n",
      "\n",
      "==== cos+all_expr (4 feats) ====\n",
      "AUROC(all): 0.6091, AUPR(all): 0.0260\n",
      "GT mean score=0.6669, non-GT mean=0.6167, Mann-Whitney p=0.00e+00\n",
      " quantile  threshold  top_n  top_gt_frac  bottom_n  bottom_gt_frac  enrichment_fold\n",
      " 0.900000   0.814529  59777     0.028339    537983        0.018084         1.567038\n",
      " 0.950000   0.864546  29888     0.027068    567872        0.018691         1.448182\n",
      " 0.990000   0.931534   5978     0.025092    591782        0.019049         1.317218\n",
      " 0.995000   0.949023   2989     0.022750    594771        0.019091         1.191642\n",
      "\n",
      "==== no_cos (6 feats) ====\n",
      "AUROC(all): 0.6014, AUPR(all): 0.0259\n",
      "GT mean score=0.7124, non-GT mean=0.5901, Mann-Whitney p=5.39e-303\n",
      " quantile  threshold  top_n  top_gt_frac  bottom_n  bottom_gt_frac  enrichment_fold\n",
      " 0.900000   0.995104  59779     0.028656    537981        0.018049         1.587656\n",
      " 0.950000   0.996998  29889     0.030546    567871        0.018508         1.650465\n",
      " 0.990000   0.998742   5978     0.037303    591782        0.018926         1.971027\n",
      " 0.995000   0.999071   2994     0.039412    594766        0.019007         2.073508\n",
      "\n",
      "==== all_feats (7 feats) ====\n",
      "AUROC(all): 0.5921, AUPR(all): 0.0257\n",
      "GT mean score=0.7240, non-GT mean=0.6075, Mann-Whitney p=2.14e-250\n",
      " quantile  threshold  top_n  top_gt_frac  bottom_n  bottom_gt_frac  enrichment_fold\n",
      " 0.900000   0.990903  59778     0.028154    537982        0.018105         1.555076\n",
      " 0.950000   0.993653  29890     0.030646    567870        0.018502         1.656303\n",
      " 0.990000   0.996668   5978     0.038976    591782        0.018909         2.061255\n",
      " 0.995000   0.997359   2990     0.038462    594770        0.019012         2.022972\n",
      "\n",
      "\n",
      "=== Feature set ranking by AUROC (ChIP, all TFs) ===\n",
      "     feature_set  n_features  auroc_all  aupr_all  gt_mean  non_mean  mw_p_all\n",
      "       expr_only           3     0.6273    0.0264   0.6187    0.5781    0.0000\n",
      "    cos+all_expr           4     0.6091    0.0260   0.6669    0.6167    0.0000\n",
      "          no_cos           6     0.6014    0.0259   0.7124    0.5901    0.0000\n",
      "       all_feats           7     0.5921    0.0257   0.7240    0.6075    0.0000\n",
      "       cos+motif           3     0.5795    0.0245   0.7177    0.5985    0.0000\n",
      "cos+motif+regpot           4     0.5795    0.0245   0.7184    0.6003    0.0000\n",
      "      motif_only           2     0.5732    0.0232   0.7055    0.5832    0.0000\n",
      "        cos_only           1     0.5252    0.0213   0.7760    0.7681    0.0000\n",
      "      cos+regpot           2     0.5252    0.0213   0.7595    0.7533    0.0000\n",
      "     regpot_only           1     0.4999    0.0191   0.7275    0.7275    0.8478\n"
     ]
    }
   ],
   "source": [
    "# Base features\n",
    "all_feat_cols = [\n",
    "    \"cos_sim\",\n",
    "    \"log_reg_pot\",\n",
    "    \"motif_density\",\n",
    "    \"motif_present\",\n",
    "    \"mean_tf_expr\",\n",
    "    \"mean_tg_expr\",\n",
    "    \"expr_product\",\n",
    "]\n",
    "\n",
    "# Define ablation sets\n",
    "feature_sets = {\n",
    "    \"cos_only\":          [\"cos_sim\"],\n",
    "    \"motif_only\":        [\"motif_present\", \"motif_density\"],\n",
    "    \"regpot_only\":       [\"log_reg_pot\"],\n",
    "    \"expr_only\":         [\"mean_tf_expr\", \"mean_tg_expr\", \"expr_product\"],\n",
    "    \"cos+motif\":         [\"cos_sim\", \"motif_present\", \"motif_density\"],\n",
    "    \"cos+regpot\":        [\"cos_sim\", \"log_reg_pot\"],\n",
    "    \"cos+motif+regpot\":  [\"cos_sim\", \"motif_present\", \"motif_density\", \"log_reg_pot\"],\n",
    "    \"cos+all_expr\":      [\"cos_sim\", \"mean_tf_expr\", \"mean_tg_expr\", \"expr_product\"],\n",
    "    \"no_cos\":            [c for c in all_feat_cols if c != \"cos_sim\"],\n",
    "    \"all_feats\":         all_feat_cols,\n",
    "}\n",
    "\n",
    "def build_pseudo_dataset(df, pos_mask, neg_mask):\n",
    "    \"\"\"Use your strict masks to build (X, y) for training.\"\"\"\n",
    "    pos = df[pos_mask].copy()\n",
    "    neg = df[neg_mask].copy()\n",
    "    # use all strict pos/negs (no balancing, preserve your 0.727 pos_frac)\n",
    "    pos[\"y\"] = 1.0\n",
    "    neg[\"y\"] = 0.0\n",
    "    train_df = pd.concat([pos, neg], axis=0)\n",
    "    return train_df\n",
    "\n",
    "\n",
    "def make_loader(X, y, batch_size=1024, shuffle=False):\n",
    "    X_t = torch.from_numpy(X).float()\n",
    "    y_t = torch.from_numpy(y).float()\n",
    "    ds = TensorDataset(X_t, y_t)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "\n",
    "def train_small_mlp(X, y, n_epochs=15, hidden=64, lr=1e-3, val_frac=0.15, seed=0):\n",
    "    \"\"\"Train a tiny MLP on pseudo-labels, return trained model.\"\"\"\n",
    "    N, D = X.shape\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.arange(N)\n",
    "    rng.shuffle(idx)\n",
    "\n",
    "    n_val = int(val_frac * N)\n",
    "    val_idx = idx[:n_val]\n",
    "    train_idx = idx[n_val:]\n",
    "\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_val,   y_val   = X[val_idx],   y[val_idx]\n",
    "\n",
    "    train_loader = make_loader(X_train, y_train, shuffle=True)\n",
    "    val_loader   = make_loader(X_val,   y_val,   shuffle=False)\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(D, hidden),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden, 1),\n",
    "    ).to(device)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # train\n",
    "        model.train()\n",
    "        tr_sum, tr_n = 0.0, 0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            logits = model(xb).squeeze(-1)\n",
    "            loss = loss_fn(logits, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            bs = xb.size(0)\n",
    "            tr_sum += float(loss) * bs\n",
    "            tr_n += bs\n",
    "        tr_loss = tr_sum / max(tr_n, 1)\n",
    "\n",
    "        # val\n",
    "        model.eval()\n",
    "        va_sum, va_n = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                logits = model(xb).squeeze(-1)\n",
    "                loss = loss_fn(logits, yb)\n",
    "                bs = xb.size(0)\n",
    "                va_sum += float(loss) * bs\n",
    "                va_n += bs\n",
    "        va_loss = va_sum / max(va_n, 1)\n",
    "\n",
    "        if va_loss < best_val:\n",
    "            best_val = va_loss\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def enrichment_by_quantiles(scores, labels, quantiles=(0.9, 0.95, 0.99, 0.995)):\n",
    "    scores = np.asarray(scores)\n",
    "    labels = np.asarray(labels).astype(bool)\n",
    "    rows = []\n",
    "    for q in quantiles:\n",
    "        thr = np.quantile(scores, q)\n",
    "        top = scores >= thr\n",
    "        bot = ~top\n",
    "        if top.sum() == 0 or bot.sum() == 0:\n",
    "            continue\n",
    "        top_frac = labels[top].mean()\n",
    "        bot_frac = labels[bot].mean()\n",
    "        fold = (top_frac / bot_frac) if bot_frac > 0 else np.nan\n",
    "        rows.append(dict(\n",
    "            quantile=q,\n",
    "            threshold=thr,\n",
    "            top_n=int(top.sum()),\n",
    "            top_gt_frac=top_frac,\n",
    "            bottom_n=int(bot.sum()),\n",
    "            bottom_gt_frac=bot_frac,\n",
    "            enrichment_fold=fold,\n",
    "        ))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def eval_against_chip(model, df, chip_df, feat_cols):\n",
    "    \"\"\"\n",
    "    Evaluate a trained model on the FULL df vs ChIP edges.\n",
    "    Returns dict of summary metrics.\n",
    "    \"\"\"\n",
    "    # Build full feature matrix\n",
    "    X_all = df[feat_cols].astype(\"float32\").to_numpy()\n",
    "    X_all_t = torch.from_numpy(X_all).float().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_all_t).squeeze(-1)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "    # Ground truth labels from ChIP\n",
    "    chip_pairs = set(zip(chip_df[\"Gene1\"], chip_df[\"Gene2\"]))\n",
    "    is_gt = np.fromiter(\n",
    "        ((tf, tg) in chip_pairs for tf, tg in zip(df[\"TF\"], df[\"TG\"])),\n",
    "        dtype=bool,\n",
    "        count=len(df),\n",
    "    )\n",
    "\n",
    "    if is_gt.sum() == 0:\n",
    "        return {\n",
    "            \"gt_total\": 0,\n",
    "            \"auroc_all\": np.nan,\n",
    "            \"aupr_all\": np.nan,\n",
    "            \"mw_p_all\": np.nan,\n",
    "        }\n",
    "\n",
    "    # overall\n",
    "    auroc_all = roc_auc_score(is_gt, probs)\n",
    "    aupr_all = average_precision_score(is_gt, probs)\n",
    "\n",
    "    gt_scores = probs[is_gt]\n",
    "    non_scores = probs[~is_gt]\n",
    "    u, p = mannwhitneyu(gt_scores, non_scores, alternative=\"greater\")\n",
    "\n",
    "    enrich = enrichment_by_quantiles(probs, is_gt)\n",
    "\n",
    "    return {\n",
    "        \"gt_total\": int(is_gt.sum()),\n",
    "        \"auroc_all\": float(auroc_all),\n",
    "        \"aupr_all\": float(aupr_all),\n",
    "        \"mw_p_all\": float(p),\n",
    "        \"gt_mean\": float(gt_scores.mean()),\n",
    "        \"non_mean\": float(non_scores.mean()),\n",
    "        \"enrich_table\": enrich,\n",
    "    }\n",
    "\n",
    "# --- Load embeddings & vocab ---\n",
    "emb = torch.load(SELECTED_EXPERIMENT_DIR / \"tf_tg_embeddings.pt\", map_location=\"cpu\")\n",
    "tf_emb = emb[\"tf_emb\"]   # [T, D]\n",
    "tg_emb = emb[\"tg_emb\"]   # [G, D]\n",
    "\n",
    "id2name = torch.load(SELECTED_EXPERIMENT_DIR / \"tf_tg_vocab_id2name.pt\", map_location=\"cpu\")\n",
    "tf_id2name = id2name[\"tf_id2name\"]\n",
    "tg_id2name = id2name[\"tg_id2name\"]\n",
    "\n",
    "tf_name2id = {n: i for i, n in enumerate(tf_id2name)}\n",
    "tg_name2id = {n: i for i, n in enumerate(tg_id2name)}\n",
    "\n",
    "tf_norm = torch.nn.functional.normalize(tf_emb, p=2, dim=1)\n",
    "tg_norm = torch.nn.functional.normalize(tg_emb, p=2, dim=1)\n",
    "\n",
    "# --- Load prior TF-TG scores ---\n",
    "df_all = pd.read_parquet(\"data/processed/mESC_no_scale_linear/E7.5_rep1/tf_tg_data.parquet\")\n",
    "\n",
    "# Keep only pairs that exist in embedding vocab\n",
    "mask = df_all[\"TF\"].isin(tf_name2id) & df_all[\"TG\"].isin(tg_name2id)\n",
    "df_all = df_all[mask].copy()\n",
    "\n",
    "# Map to indices\n",
    "df_all[\"tf_id\"] = df_all[\"TF\"].map(tf_name2id)\n",
    "df_all[\"tg_id\"] = df_all[\"TG\"].map(tg_name2id)\n",
    "\n",
    "# Cosine similarity feature from embeddings\n",
    "tf_vec = tf_norm[df_all[\"tf_id\"].values]       # [N, D]\n",
    "tg_vec = tg_norm[df_all[\"tg_id\"].values]       # [N, D]\n",
    "cos_sim = (tf_vec * tg_vec).sum(dim=1).numpy()\n",
    "df_all[\"cos_sim\"] = cos_sim\n",
    "\n",
    "# Use stricter highs/lows\n",
    "hi_logreg = df_all[\"log_reg_pot\"].quantile(0.95)\n",
    "hi_cos    = df_all[\"cos_sim\"].quantile(0.95)\n",
    "hi_expr   = df_all[\"expr_product\"].quantile(0.95)\n",
    "\n",
    "lo_logreg = df_all[\"log_reg_pot\"].quantile(0.10)\n",
    "lo_cos    = df_all[\"cos_sim\"].quantile(0.10)\n",
    "lo_expr   = df_all[\"expr_product\"].quantile(0.25)\n",
    "\n",
    "# Strong positives:\n",
    "#   motif present\n",
    "#   AND (high log_reg OR high cos)\n",
    "#   AND high-ish expr product\n",
    "pos_mask_strict = (\n",
    "    (df_all[\"motif_present\"] == 1) &\n",
    "    ((df_all[\"log_reg_pot\"] >= hi_logreg) |\n",
    "     (df_all[\"cos_sim\"]     >= hi_cos)) &\n",
    "    (df_all[\"expr_product\"] >= hi_expr)\n",
    ")\n",
    "\n",
    "# Candidate negatives:\n",
    "#   no motif\n",
    "#   AND all signals low\n",
    "neg_strict_mask = (\n",
    "    (df_all[\"motif_present\"] == 0) &\n",
    "    (df_all[\"log_reg_pot\"] <= lo_logreg) &\n",
    "    (df_all[\"cos_sim\"]     <= lo_cos) &\n",
    "    (df_all[\"expr_product\"]<= lo_expr)\n",
    ")\n",
    "\n",
    "# 1) Build pseudo-labeled dataset from your strict masks\n",
    "train_df = build_pseudo_dataset(df_all, pos_mask_strict, neg_strict_mask)\n",
    "print(f\"Pseudo-labeled set: {len(train_df)} rows \"\n",
    "      f\"(pos={int((train_df['y']==1).sum())}, neg={int((train_df['y']==0).sum())})\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, cols in feature_sets.items():\n",
    "    # make sure columns exist\n",
    "    cols = [c for c in cols if c in train_df.columns]\n",
    "    if not cols:\n",
    "        continue\n",
    "\n",
    "    X = train_df[cols].astype(\"float32\").to_numpy()\n",
    "    y = train_df[\"y\"].to_numpy().astype(\"float32\")\n",
    "\n",
    "    model = train_small_mlp(X, y, n_epochs=15, hidden=64, lr=1e-3)\n",
    "\n",
    "    metrics = eval_against_chip(model, df, chip_df, cols)\n",
    "\n",
    "    results.append({\n",
    "        \"feature_set\": name,\n",
    "        \"n_features\": len(cols),\n",
    "        \"auroc_all\": metrics[\"auroc_all\"],\n",
    "        \"aupr_all\": metrics[\"aupr_all\"],\n",
    "        \"gt_mean\": metrics[\"gt_mean\"],\n",
    "        \"non_mean\": metrics[\"non_mean\"],\n",
    "        \"mw_p_all\": metrics[\"mw_p_all\"],\n",
    "    })\n",
    "\n",
    "    print(f\"\\n==== {name} ({len(cols)} feats) ====\")\n",
    "    print(f\"AUROC(all): {metrics['auroc_all']:.4f}, \"\n",
    "          f\"AUPR(all): {metrics['aupr_all']:.4f}\")\n",
    "    print(f\"GT mean score={metrics['gt_mean']:.4f}, \"\n",
    "          f\"non-GT mean={metrics['non_mean']:.4f}, \"\n",
    "          f\"Mann-Whitney p={metrics['mw_p_all']:.2e}\")\n",
    "    print(metrics[\"enrich_table\"].to_string(index=False,\n",
    "          float_format=lambda x: f\"{x:.6f}\"))\n",
    "\n",
    "# Summary table\n",
    "results_df = pd.DataFrame(results).sort_values(\"auroc_all\", ascending=False)\n",
    "print(\"\\n\\n=== Feature set ranking by AUROC (ChIP, all TFs) ===\")\n",
    "print(results_df.to_string(index=False,\n",
    "       float_format=lambda x: f\"{x:.4f}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "275e262f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total candidate pairs (universe): 6149386\n",
      "Strict positives: 144711, strict negatives: 54222\n",
      "Pseudo-labeled training set size: 40000 (pos=20000, neg=20000, pos_frac=0.500)\n",
      "\n",
      "=== ChIP eval on full universe (all TFs) ===\n",
      "Total pairs: 6149386\n",
      "GT pairs:    83961\n",
      "GT fraction: 0.013654\n",
      "\n",
      "[All TFs] GT enrichment in high-score pairs vs rest:\n",
      " quantile  threshold  top_n  top_gt_frac  bottom_n  bottom_gt_frac  enrichment_fold\n",
      " 0.900000   5.849766 614939     0.026217   5534447        0.012258         2.138857\n",
      " 0.950000   7.130404 307470     0.030380   5841916        0.012773         2.378432\n",
      " 0.990000  10.012398  61494     0.043874   6087892        0.013348         3.286876\n",
      " 0.995000  11.296568  30747     0.049728   6118639        0.013472         3.691167\n",
      "\n",
      "[All TFs] Mann–Whitney (GT > non-GT): p=0.000e+00, GT mean=2.1138, non-GT mean=0.2672\n",
      "[All TFs] AUROC=0.6120, AUPR=0.0221\n",
      "\n",
      "=== ChIP eval (ChIP TFs only) ===\n",
      "Pairs with TF in ChIP set: 430281\n",
      "GT pairs in this subset:   83961\n",
      "GT fraction:               0.195131\n",
      "\n",
      "[ChIP TFs only] GT enrichment in high-score pairs vs rest:\n",
      " quantile  threshold  top_n  top_gt_frac  bottom_n  bottom_gt_frac  enrichment_fold\n",
      " 0.900000   6.233927  43029     0.317646    387252        0.181517         1.749949\n",
      " 0.950000   7.511982  21515     0.368441    408766        0.186009         1.980772\n",
      " 0.990000  10.533884   4303     0.501975    425978        0.192031         2.614032\n",
      " 0.995000  11.890605   2152     0.560409    428129        0.193295         2.899249\n",
      "\n",
      "[ChIP TFs only] Mann–Whitney (GT > non-GT): p=0.000e+00, GT mean=2.1138, non-GT mean=1.0188\n",
      "[ChIP TFs only] AUROC=0.5695, AUPR=0.2614\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. Load embeddings, vocab, and TF–TG feature table\n",
    "# ============================================================\n",
    "\n",
    "EXP_DIR = Path(SELECTED_EXPERIMENT_DIR)\n",
    "\n",
    "emb = torch.load(EXP_DIR / \"tf_tg_embeddings.pt\", map_location=\"cpu\")\n",
    "tf_emb = emb[\"tf_emb\"]   # [T, D]\n",
    "tg_emb = emb[\"tg_emb\"]   # [G, D]\n",
    "\n",
    "id2name = torch.load(EXP_DIR / \"tf_tg_vocab_id2name.pt\", map_location=\"cpu\")\n",
    "tf_id2name = id2name[\"tf_id2name\"]\n",
    "tg_id2name = id2name[\"tg_id2name\"]\n",
    "\n",
    "tf_name2id = {n: i for i, n in enumerate(tf_id2name)}\n",
    "tg_name2id = {n: i for i, n in enumerate(tg_id2name)}\n",
    "\n",
    "tf_norm = F.normalize(tf_emb, p=2, dim=1)\n",
    "tg_norm = F.normalize(tg_emb, p=2, dim=1)\n",
    "\n",
    "df = total_tf_tg_data\n",
    "\n",
    "mask = df[\"TF\"].isin(tf_name2id) & df[\"TG\"].isin(tg_name2id)\n",
    "df = df[mask].copy().reset_index(drop=True)\n",
    "\n",
    "df[\"tf_id\"] = df[\"TF\"].map(tf_name2id)\n",
    "df[\"tg_id\"] = df[\"TG\"].map(tg_name2id)\n",
    "\n",
    "tf_vec = tf_norm[df[\"tf_id\"].values]\n",
    "tg_vec = tg_norm[df[\"tg_id\"].values]\n",
    "df[\"cos_sim\"] = (tf_vec * tg_vec).sum(dim=1).numpy()\n",
    "\n",
    "for c in [\n",
    "    \"log_reg_pot\",\n",
    "    \"motif_density\",\n",
    "    \"motif_present\",\n",
    "    \"mean_tf_expr\",\n",
    "    \"mean_tg_expr\",\n",
    "    \"expr_product\",\n",
    "    \"cos_sim\",\n",
    "]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0.0)\n",
    "    else:\n",
    "        df[c] = 0.0\n",
    "\n",
    "# ============================================================\n",
    "# 2. Feature set & STRICT pseudo-labels (balanced)\n",
    "# ============================================================\n",
    "\n",
    "feat_cols = [\n",
    "    \"cos_sim\",\n",
    "    \"motif_present\",\n",
    "    \"motif_density\",\n",
    "    \"mean_tf_expr\",\n",
    "    \"mean_tg_expr\",\n",
    "    \"expr_product\",\n",
    "]\n",
    "\n",
    "X_all = df[feat_cols].values.astype(\"float32\")\n",
    "N = len(df)\n",
    "\n",
    "motif_present = (df[\"motif_present\"] == 1)\n",
    "\n",
    "# thresholds\n",
    "expr_q80 = df[\"expr_product\"].quantile(0.80)\n",
    "expr_q20 = df[\"expr_product\"].quantile(0.20)\n",
    "cos_q95  = df[\"cos_sim\"].quantile(0.95)\n",
    "cos_q10  = df[\"cos_sim\"].quantile(0.10)\n",
    "md_q95   = df[\"motif_density\"].quantile(0.95)\n",
    "\n",
    "# ----- Strict positives -----\n",
    "# Motif + at least TWO strong signals (intersection patterns)\n",
    "high_expr = df[\"expr_product\"] >= expr_q80\n",
    "high_cos  = df[\"cos_sim\"]       >= cos_q95\n",
    "high_md   = df[\"motif_density\"] >= md_q95\n",
    "\n",
    "two_strong = (\n",
    "    (high_expr & high_cos) |\n",
    "    (high_expr & high_md) |\n",
    "    (high_cos  & high_md)\n",
    ")\n",
    "\n",
    "strict_pos = motif_present & two_strong\n",
    "\n",
    "# ----- Strict negatives -----\n",
    "# No motif, low expr, low cosine\n",
    "low_expr = df[\"expr_product\"] <= expr_q20\n",
    "low_cos  = df[\"cos_sim\"]      <= cos_q10\n",
    "\n",
    "strict_neg = (~motif_present) & low_expr & low_cos\n",
    "\n",
    "pos_idx = np.where(strict_pos)[0]\n",
    "neg_idx = np.where(strict_neg)[0]\n",
    "\n",
    "print(f\"Total candidate pairs (universe): {N}\")\n",
    "print(f\"Strict positives: {len(pos_idx)}, strict negatives: {len(neg_idx)}\")\n",
    "\n",
    "# remove any overlap just in case\n",
    "overlap = np.intersect1d(pos_idx, neg_idx)\n",
    "if len(overlap) > 0:\n",
    "    neg_idx = np.setdiff1d(neg_idx, overlap)\n",
    "    print(f\"Removed {len(overlap)} overlapping indices from negatives.\")\n",
    "\n",
    "# Balanced sampling\n",
    "rng = np.random.default_rng(42)\n",
    "max_per_class = 20000  # cap to keep it lean\n",
    "\n",
    "n_pos = min(len(pos_idx), max_per_class)\n",
    "n_neg = min(len(neg_idx), max_per_class, n_pos)  # enforce balance\n",
    "\n",
    "if n_pos == 0 or n_neg == 0:\n",
    "    raise RuntimeError(\"No strict positives or negatives under current thresholds.\")\n",
    "\n",
    "pos_sample = rng.choice(pos_idx, size=n_pos, replace=False)\n",
    "neg_sample = rng.choice(neg_idx, size=n_neg, replace=False)\n",
    "\n",
    "train_idx = np.concatenate([pos_sample, neg_sample])\n",
    "y_train = np.concatenate([\n",
    "    np.ones(n_pos, dtype=np.float32),\n",
    "    np.zeros(n_neg, dtype=np.float32),\n",
    "])\n",
    "\n",
    "print(\n",
    "    f\"Pseudo-labeled training set size: {len(train_idx)} \"\n",
    "    f\"(pos={n_pos}, neg={n_neg}, pos_frac={y_train.mean():.3f})\"\n",
    ")\n",
    "\n",
    "X_train = X_all[train_idx]\n",
    "\n",
    "# ============================================================\n",
    "# 3. Standardize & train regularized logistic regression\n",
    "# ============================================================\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_z = scaler.fit_transform(X_train)\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "    C=0.1,              # stronger regularization than default\n",
    "    class_weight=None,  # already balanced\n",
    "    max_iter=1000,\n",
    "    solver=\"lbfgs\",\n",
    ")\n",
    "log_reg.fit(X_train_z, y_train)\n",
    "\n",
    "# ============================================================\n",
    "# 4. Score all pairs (use margins as main score)\n",
    "# ============================================================\n",
    "\n",
    "X_all_z = scaler.transform(X_all)\n",
    "\n",
    "edge_logit = log_reg.decision_function(X_all_z)  # can be negative/positive\n",
    "df[\"edge_score_raw\"] = edge_logit\n",
    "\n",
    "# optional 0–1 scaled version for convenience (not used for AUROC)\n",
    "min_l, max_l = edge_logit.min(), edge_logit.max()\n",
    "if max_l > min_l:\n",
    "    df[\"edge_score\"] = (edge_logit - min_l) / (max_l - min_l)\n",
    "else:\n",
    "    df[\"edge_score\"] = 0.5  # degenerate fallback\n",
    "# For evaluation we will use edge_score_raw (monotonic with edge_score).\n",
    "\n",
    "# ============================================================\n",
    "# 5. Evaluate vs ChIP-seq\n",
    "# ============================================================\n",
    "\n",
    "chip_path = \"data/ground_truth_files/mESC_beeline_ChIP-seq.csv\"\n",
    "chip_df = pd.read_csv(chip_path)\n",
    "\n",
    "chip_pairs = set(zip(chip_df[\"Gene1\"], chip_df[\"Gene2\"]))\n",
    "is_gt = np.fromiter(\n",
    "    ((tf, tg) in chip_pairs for tf, tg in zip(df[\"TF\"], df[\"TG\"])),\n",
    "    dtype=bool,\n",
    "    count=len(df),\n",
    ")\n",
    "df[\"is_gt\"] = is_gt\n",
    "\n",
    "gt_total = int(is_gt.sum())\n",
    "overall_frac = gt_total / max(N, 1)\n",
    "\n",
    "print(\"\\n=== ChIP eval on full universe (all TFs) ===\")\n",
    "print(f\"Total pairs: {N}\")\n",
    "print(f\"GT pairs:    {gt_total}\")\n",
    "print(f\"GT fraction: {overall_frac:.6f}\")\n",
    "\n",
    "\n",
    "def enrichment_by_quantiles(scores, labels, quantiles=(0.9, 0.95, 0.99, 0.995)):\n",
    "    scores = np.asarray(scores)\n",
    "    labels = np.asarray(labels).astype(bool)\n",
    "    rows = []\n",
    "    for q in quantiles:\n",
    "        thr = np.quantile(scores, q)\n",
    "        top = scores >= thr\n",
    "        bot = ~top\n",
    "        if top.sum() == 0 or bot.sum() == 0:\n",
    "            continue\n",
    "        top_frac = labels[top].mean()\n",
    "        bot_frac = labels[bot].mean()\n",
    "        fold = (top_frac / bot_frac) if bot_frac > 0 else np.nan\n",
    "        rows.append(dict(\n",
    "            quantile=q,\n",
    "            threshold=float(thr),\n",
    "            top_n=int(top.sum()),\n",
    "            top_gt_frac=float(top_frac),\n",
    "            bottom_n=int(bot.sum()),\n",
    "            bottom_gt_frac=float(bot_frac),\n",
    "            enrichment_fold=float(fold),\n",
    "        ))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "if gt_total > 0:\n",
    "    scores = df[\"edge_score_raw\"].values  # use margin\n",
    "    labels = df[\"is_gt\"].values\n",
    "\n",
    "    enrich = enrichment_by_quantiles(scores, labels)\n",
    "    print(\"\\n[All TFs] GT enrichment in high-score pairs vs rest:\")\n",
    "    print(enrich.to_string(index=False, float_format=lambda x: f\"{x:.6f}\"))\n",
    "\n",
    "    gt_scores = scores[labels]\n",
    "    non_scores = scores[~labels]\n",
    "    u, p = mannwhitneyu(gt_scores, non_scores, alternative=\"greater\")\n",
    "    print(\n",
    "        f\"\\n[All TFs] Mann–Whitney (GT > non-GT): \"\n",
    "        f\"p={p:.3e}, GT mean={gt_scores.mean():.4f}, \"\n",
    "        f\"non-GT mean={non_scores.mean():.4f}\"\n",
    "    )\n",
    "\n",
    "    auroc = roc_auc_score(labels, scores)\n",
    "    aupr = average_precision_score(labels, scores)\n",
    "    print(f\"[All TFs] AUROC={auroc:.4f}, AUPR={aupr:.4f}\")\n",
    "else:\n",
    "    print(\"No ChIP edges in universe; cannot evaluate.\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. ChIP TFs only eval\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n=== ChIP eval (ChIP TFs only) ===\")\n",
    "chip_tfs = set(chip_df[\"Gene1\"].unique())\n",
    "mask_chip_tf = df[\"TF\"].isin(chip_tfs)\n",
    "df_chip = df[mask_chip_tf].copy()\n",
    "\n",
    "scores_c = df_chip[\"edge_score_raw\"].values\n",
    "labels_c = df_chip[\"is_gt\"].values\n",
    "\n",
    "gt_total_c = int(labels_c.sum())\n",
    "universe_c = len(df_chip)\n",
    "overall_frac_c = gt_total_c / max(universe_c, 1)\n",
    "\n",
    "print(f\"Pairs with TF in ChIP set: {universe_c}\")\n",
    "print(f\"GT pairs in this subset:   {gt_total_c}\")\n",
    "print(f\"GT fraction:               {overall_frac_c:.6f}\")\n",
    "\n",
    "if gt_total_c > 0:\n",
    "    enrich_c = enrichment_by_quantiles(scores_c, labels_c)\n",
    "    print(\"\\n[ChIP TFs only] GT enrichment in high-score pairs vs rest:\")\n",
    "    print(enrich_c.to_string(index=False, float_format=lambda x: f\"{x:.6f}\"))\n",
    "\n",
    "    gt_scores_c = scores_c[labels_c]\n",
    "    non_scores_c = scores_c[~labels_c]\n",
    "    u, p = mannwhitneyu(gt_scores_c, non_scores_c, alternative=\"greater\")\n",
    "    print(\n",
    "        f\"\\n[ChIP TFs only] Mann–Whitney (GT > non-GT): \"\n",
    "        f\"p={p:.3e}, GT mean={gt_scores_c.mean():.4f}, \"\n",
    "        f\"non-GT mean={non_scores_c.mean():.4f}\"\n",
    "    )\n",
    "\n",
    "    auroc_c = roc_auc_score(labels_c, scores_c)\n",
    "    aupr_c = average_precision_score(labels_c, scores_c)\n",
    "    print(f\"[ChIP TFs only] AUROC={auroc_c:.4f}, AUPR={aupr_c:.4f}\")\n",
    "else:\n",
    "    print(\"No GT edges with ChIP TFs in this universe.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "982312da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TF",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TG",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reg_potential",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "motif_density",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_tf_expr",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "mean_tg_expr",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "expr_product",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "log_reg_pot",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "motif_present",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "in_STRING",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "in_TRRUST",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "in_KEGG",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_sources",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "string_experimental_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "string_database_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "string_textmining_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "string_combined_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trrust_sign",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trrust_regulation",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "trrust_pmids",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "trrust_support_n",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "kegg_signal",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "kegg_n_pathways",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "kegg_pathways",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "tf_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tg_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cos_sim",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "edge_score_raw",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "edge_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "is_gt",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "8e4068e4-2e40-4fb8-b8bf-a5d4c84a8579",
       "rows": [
        [
         "0",
         "RORB",
         "TAMALIN",
         "0.0",
         "0.0",
         "0.009336619",
         "0.012839624",
         "0.00011987867",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "376",
         "5949",
         "0.009111829",
         "-5.881791465072244",
         "0.09952212708841147",
         "False"
        ],
        [
         "1",
         "ZFP711",
         "RAB39",
         "0.0",
         "0.0",
         "0.04585585",
         "0.012976407",
         "0.00059504417",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "565",
         "4895",
         "-0.0064790975",
         "-5.671125893137308",
         "0.1050024289133434",
         "False"
        ],
        [
         "2",
         "TRP73",
         "CYYR1",
         "0.0",
         "0.6931471805599453",
         "0.008033529",
         "0.045601826",
         "0.0003663436",
         "0.0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "460",
         "1588",
         "0.043301903",
         "2.383743521393638",
         "0.3145436232650999",
         "False"
        ],
        [
         "3",
         "HHEX",
         "CPED1",
         "0.0",
         "1.0986122886681098",
         "0.017146219",
         "0.016808927",
         "0.00028820953",
         "0.0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "157",
         "1445",
         "0.04303119",
         "3.192322708882464",
         "0.3355781850878812",
         "False"
        ],
        [
         "4",
         "CREB5",
         "OGFOD3",
         "0.0",
         "0.0",
         "0.008647242",
         "0.022741944",
         "0.00019665508",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "41",
         "4230",
         "0.035288446",
         "-5.424239439003604",
         "0.11142498895821769",
         "False"
        ]
       ],
       "shape": {
        "columns": 31,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>TG</th>\n",
       "      <th>reg_potential</th>\n",
       "      <th>motif_density</th>\n",
       "      <th>mean_tf_expr</th>\n",
       "      <th>mean_tg_expr</th>\n",
       "      <th>expr_product</th>\n",
       "      <th>log_reg_pot</th>\n",
       "      <th>motif_present</th>\n",
       "      <th>label</th>\n",
       "      <th>...</th>\n",
       "      <th>trrust_support_n</th>\n",
       "      <th>kegg_signal</th>\n",
       "      <th>kegg_n_pathways</th>\n",
       "      <th>kegg_pathways</th>\n",
       "      <th>tf_id</th>\n",
       "      <th>tg_id</th>\n",
       "      <th>cos_sim</th>\n",
       "      <th>edge_score_raw</th>\n",
       "      <th>edge_score</th>\n",
       "      <th>is_gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RORB</td>\n",
       "      <td>TAMALIN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009337</td>\n",
       "      <td>0.012840</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>376</td>\n",
       "      <td>5949</td>\n",
       "      <td>0.009112</td>\n",
       "      <td>-5.881791</td>\n",
       "      <td>0.099522</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZFP711</td>\n",
       "      <td>RAB39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045856</td>\n",
       "      <td>0.012976</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>565</td>\n",
       "      <td>4895</td>\n",
       "      <td>-0.006479</td>\n",
       "      <td>-5.671126</td>\n",
       "      <td>0.105002</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRP73</td>\n",
       "      <td>CYYR1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.045602</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>460</td>\n",
       "      <td>1588</td>\n",
       "      <td>0.043302</td>\n",
       "      <td>2.383744</td>\n",
       "      <td>0.314544</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HHEX</td>\n",
       "      <td>CPED1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.017146</td>\n",
       "      <td>0.016809</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>157</td>\n",
       "      <td>1445</td>\n",
       "      <td>0.043031</td>\n",
       "      <td>3.192323</td>\n",
       "      <td>0.335578</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CREB5</td>\n",
       "      <td>OGFOD3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.022742</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>41</td>\n",
       "      <td>4230</td>\n",
       "      <td>0.035288</td>\n",
       "      <td>-5.424239</td>\n",
       "      <td>0.111425</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TF       TG  reg_potential  motif_density  mean_tf_expr  mean_tg_expr  \\\n",
       "0    RORB  TAMALIN            0.0       0.000000      0.009337      0.012840   \n",
       "1  ZFP711    RAB39            0.0       0.000000      0.045856      0.012976   \n",
       "2   TRP73    CYYR1            0.0       0.693147      0.008034      0.045602   \n",
       "3    HHEX    CPED1            0.0       1.098612      0.017146      0.016809   \n",
       "4   CREB5   OGFOD3            0.0       0.000000      0.008647      0.022742   \n",
       "\n",
       "   expr_product  log_reg_pot  motif_present  label  ...  trrust_support_n  \\\n",
       "0      0.000120          0.0              0      0  ...               NaN   \n",
       "1      0.000595          0.0              0      0  ...               NaN   \n",
       "2      0.000366          0.0              1      0  ...               NaN   \n",
       "3      0.000288          0.0              1      0  ...               NaN   \n",
       "4      0.000197          0.0              0      0  ...               NaN   \n",
       "\n",
       "   kegg_signal  kegg_n_pathways  kegg_pathways  tf_id  tg_id   cos_sim  \\\n",
       "0          NaN              NaN           None    376   5949  0.009112   \n",
       "1          NaN              NaN           None    565   4895 -0.006479   \n",
       "2          NaN              NaN           None    460   1588  0.043302   \n",
       "3          NaN              NaN           None    157   1445  0.043031   \n",
       "4          NaN              NaN           None     41   4230  0.035288   \n",
       "\n",
       "   edge_score_raw  edge_score  is_gt  \n",
       "0       -5.881791    0.099522  False  \n",
       "1       -5.671126    0.105002  False  \n",
       "2        2.383744    0.314544  False  \n",
       "3        3.192323    0.335578  False  \n",
       "4       -5.424239    0.111425  False  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbda740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_grn = df[[\"TF\", \"TG\", \"edge_score\"]].rename(columns={\"edge_score\":\"Score\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee945e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TF",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TG",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "7fbc0093-98d0-4315-a412-f34017141b4b",
       "rows": [
        [
         "0",
         "RORB",
         "TAMALIN",
         "0.10166513277827723"
        ],
        [
         "1",
         "ZFP711",
         "RAB39",
         "0.10841167785045519"
        ],
        [
         "2",
         "TRP73",
         "CYYR1",
         "0.36924798503022405"
        ],
        [
         "3",
         "HHEX",
         "CPED1",
         "0.39450724367036355"
        ],
        [
         "4",
         "CREB5",
         "OGFOD3",
         "0.1141789982581012"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>TG</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RORB</td>\n",
       "      <td>TAMALIN</td>\n",
       "      <td>0.101665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZFP711</td>\n",
       "      <td>RAB39</td>\n",
       "      <td>0.108412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRP73</td>\n",
       "      <td>CYYR1</td>\n",
       "      <td>0.369248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HHEX</td>\n",
       "      <td>CPED1</td>\n",
       "      <td>0.394507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CREB5</td>\n",
       "      <td>OGFOD3</td>\n",
       "      <td>0.114179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TF       TG     Score\n",
       "0    RORB  TAMALIN  0.101665\n",
       "1  ZFP711    RAB39  0.108412\n",
       "2   TRP73    CYYR1  0.369248\n",
       "3    HHEX    CPED1  0.394507\n",
       "4   CREB5   OGFOD3  0.114179"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferred_grn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a0a33f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_grn.to_csv(\"output/model_classifier_testing/inferred_grn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c211b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Target",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "true_interaction",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "predicted_interaction",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "5d37d7ae-4274-435f-8bbf-f2b758e057ba",
       "rows": [
        [
         "14",
         "GATA4",
         "XKR4",
         "0.2304157525560571",
         "1",
         "0"
        ],
        [
         "24",
         "KDM2B",
         "XKR4",
         "0.2853118674920894",
         "1",
         "0"
        ],
        [
         "27",
         "KLF5",
         "XKR4",
         "0.1235649099252205",
         "1",
         "0"
        ],
        [
         "34",
         "NANOG",
         "XKR4",
         "0.2135662532123112",
         "1",
         "0"
        ],
        [
         "38",
         "OTX2",
         "XKR4",
         "0.2445103934416222",
         "1",
         "0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Score</th>\n",
       "      <th>true_interaction</th>\n",
       "      <th>predicted_interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GATA4</td>\n",
       "      <td>XKR4</td>\n",
       "      <td>0.230416</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KDM2B</td>\n",
       "      <td>XKR4</td>\n",
       "      <td>0.285312</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>KLF5</td>\n",
       "      <td>XKR4</td>\n",
       "      <td>0.123565</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NANOG</td>\n",
       "      <td>XKR4</td>\n",
       "      <td>0.213566</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>OTX2</td>\n",
       "      <td>XKR4</td>\n",
       "      <td>0.244510</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source Target     Score  true_interaction  predicted_interaction\n",
       "14  GATA4   XKR4  0.230416                 1                      0\n",
       "24  KDM2B   XKR4  0.285312                 1                      0\n",
       "27   KLF5   XKR4  0.123565                 1                      0\n",
       "34  NANOG   XKR4  0.213566                 1                      0\n",
       "38   OTX2   XKR4  0.244510                 1                      0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_interactions = pd.read_csv(\"output/model_classifier_testing/mESC_inferred_grn/mESC/balanced_true_interactions.csv\", index_col=0)\n",
    "false_interactions = pd.read_csv(\"output/model_classifier_testing/mESC_inferred_grn/mESC/balanced_false_interactions.csv\", index_col=0)\n",
    "labeled_df = pd.concat([true_interactions, false_interactions])\n",
    "labeled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c291558",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df.to_csv(\"output/model_classifier_testing/mESC_inferred_grn/mESC/labeled_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5716b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== All TFs ranking summary ===\n",
      "n=6149386, positives=83961 (pos_frac=0.0137)\n",
      "AUROC=0.6120, AUPR=0.0221\n",
      " top  1%: precision=0.0439 (x3.21 vs baseline)\n",
      " top  5%: precision=0.0304 (x2.23 vs baseline)\n",
      " top 10%: precision=0.0262 (x1.92 vs baseline)\n",
      "\n",
      "[All TFs] GT enrichment by quantile:\n",
      " quantile  threshold  top_n  top_gt_frac  bottom_n  bottom_gt_frac  enrichment_fold\n",
      " 0.900000   0.404710 614939     0.026217   5534447        0.012258         2.138857\n",
      " 0.950000   0.438024 307470     0.030380   5841916        0.012773         2.378432\n",
      " 0.990000   0.512997  61494     0.043874   6087892        0.013348         3.286876\n",
      " 0.995000   0.546404  30747     0.049728   6118639        0.013472         3.691167\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[All TFs] Confidence bins:\n",
      "   bin       n  gt_frac  enrichment_vs_overall\n",
      "  high   61494   0.0439                 3.2134\n",
      "medium  245976   0.0270                 1.9780\n",
      "   low 5841916   0.0128                 0.9355\n",
      "\n",
      "=== ChIP TFs only ranking summary ===\n",
      "n=430281, positives=83961 (pos_frac=0.1951)\n",
      "AUROC=0.5695, AUPR=0.2614\n",
      " top  1%: precision=0.5021 (x2.57 vs baseline)\n",
      " top  5%: precision=0.3685 (x1.89 vs baseline)\n",
      " top 10%: precision=0.3176 (x1.63 vs baseline)\n",
      "\n",
      "[ChIP TFs only] GT enrichment by quantile:\n",
      " quantile  threshold  top_n  top_gt_frac  bottom_n  bottom_gt_frac  enrichment_fold\n",
      " 0.900000   0.414703  43029     0.317646    387252        0.181517         1.749949\n",
      " 0.950000   0.447951  21515     0.368441    408766        0.186009         1.980772\n",
      " 0.990000   0.526563   4303     0.501975    425978        0.192031         2.614032\n",
      " 0.995000   0.561857   2152     0.560409    428129        0.193295         2.899249\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ChIP TFs only] Confidence bins:\n",
      "   bin      n  gt_frac  enrichment_vs_overall\n",
      "  high   4303   0.5020                 2.5725\n",
      "medium  17212   0.3351                 1.7171\n",
      "   low 408766   0.1860                 0.9533\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Helpers\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def summarize_ranking(scores, labels, name=\"\", top_fracs=(0.01, 0.05, 0.10)):\n",
    "    scores = np.asarray(scores)\n",
    "    labels = np.asarray(labels).astype(bool)\n",
    "\n",
    "    baseline = labels.mean()\n",
    "    auroc = roc_auc_score(labels, scores)\n",
    "    aupr = average_precision_score(labels, scores)\n",
    "\n",
    "    print(f\"\\n=== {name} ranking summary ===\")\n",
    "    print(f\"n={len(scores)}, positives={labels.sum()} (pos_frac={baseline:.4f})\")\n",
    "    print(f\"AUROC={auroc:.4f}, AUPR={aupr:.4f}\")\n",
    "\n",
    "    # precision @ top-k% (ranking use-case)\n",
    "    order = np.argsort(scores)[::-1]\n",
    "    for frac in top_fracs:\n",
    "        k = max(1, int(len(scores) * frac))\n",
    "        top = labels[order[:k]].mean() if k > 0 else np.nan\n",
    "        if np.isnan(top):\n",
    "            continue\n",
    "        fold = top / baseline if baseline > 0 else np.nan\n",
    "        print(f\" top {int(frac*100):2d}%: precision={top:.4f} \"\n",
    "              f\"(x{fold:.2f} vs baseline)\")\n",
    "\n",
    "    return dict(auroc=auroc, aupr=aupr, baseline=baseline)\n",
    "\n",
    "\n",
    "def enrichment_by_quantiles(scores, labels, quantiles=(0.9, 0.95, 0.99, 0.995)):\n",
    "    scores = np.asarray(scores)\n",
    "    labels = np.asarray(labels).astype(bool)\n",
    "    rows = []\n",
    "    for q in quantiles:\n",
    "        thr = np.quantile(scores, q)\n",
    "        top = scores >= thr\n",
    "        bot = ~top\n",
    "        if top.sum() == 0 or bot.sum() == 0:\n",
    "            continue\n",
    "        top_frac = labels[top].mean()\n",
    "        bot_frac = labels[bot].mean()\n",
    "        fold = (top_frac / bot_frac) if bot_frac > 0 else np.nan\n",
    "        rows.append(dict(\n",
    "            quantile=q,\n",
    "            threshold=thr,\n",
    "            top_n=int(top.sum()),\n",
    "            top_gt_frac=top_frac,\n",
    "            bottom_n=int(bot.sum()),\n",
    "            bottom_gt_frac=bot_frac,\n",
    "            enrichment_fold=fold,\n",
    "        ))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def plot_reliability(scores, labels, n_bins=15, title=\"Calibration (reliability)\"):\n",
    "    scores = np.asarray(scores)\n",
    "    labels = np.asarray(labels).astype(bool)\n",
    "\n",
    "    # bin by predicted score\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    idx = np.digitize(scores, bins) - 1\n",
    "\n",
    "    bin_centers = []\n",
    "    pred_means = []\n",
    "    obs_means = []\n",
    "    counts = []\n",
    "\n",
    "    for b in range(n_bins):\n",
    "        mask = idx == b\n",
    "        if mask.sum() < 50:  # require some mass\n",
    "            continue\n",
    "        bin_scores = scores[mask]\n",
    "        bin_labels = labels[mask]\n",
    "        bin_centers.append(bin_scores.mean())\n",
    "        pred_means.append(bin_scores.mean())\n",
    "        obs_means.append(bin_labels.mean())\n",
    "        counts.append(mask.sum())\n",
    "\n",
    "    if not bin_centers:\n",
    "        print(\"Not enough variation for reliability curve.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.plot([0,1],[0,1],\"k--\",alpha=0.4,label=\"Perfect calibration\")\n",
    "    plt.plot(pred_means, obs_means, marker=\"o\", lw=2)\n",
    "    plt.xlabel(\"Predicted score (bin average)\")\n",
    "    plt.ylabel(\"Observed GT fraction\")\n",
    "    plt.title(title)\n",
    "    plt.ylim(0, max(obs_means)*1.2)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.grid(alpha=0.2)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def make_confidence_table(df, score_col=\"edge_score\", label_col=\"is_gt\",\n",
    "                          high_q=0.99, med_q=0.95):\n",
    "    \"\"\"High/medium/low confidence bins based on quantiles.\"\"\"\n",
    "    scores = df[score_col].values\n",
    "    labels = df[label_col].values.astype(bool)\n",
    "\n",
    "    h_thr = np.quantile(scores, high_q)\n",
    "    m_thr = np.quantile(scores, med_q)\n",
    "\n",
    "    def bin_label(s):\n",
    "        if s >= h_thr:\n",
    "            return \"high\"\n",
    "        elif s >= m_thr:\n",
    "            return \"medium\"\n",
    "        else:\n",
    "            return \"low\"\n",
    "\n",
    "    bins = np.array([bin_label(s) for s in scores])\n",
    "    df_out = df.copy()\n",
    "    df_out[\"confidence_bin\"] = bins\n",
    "\n",
    "    rows = []\n",
    "    for b in [\"high\", \"medium\", \"low\"]:\n",
    "        mask = bins == b\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        frac = labels[mask].mean()\n",
    "        rows.append(dict(\n",
    "            bin=b,\n",
    "            n=int(mask.sum()),\n",
    "            gt_frac=frac,\n",
    "        ))\n",
    "    tbl = pd.DataFrame(rows)\n",
    "    overall = labels.mean()\n",
    "    tbl[\"enrichment_vs_overall\"] = tbl[\"gt_frac\"] / overall\n",
    "    return df_out, tbl.sort_values(\"gt_frac\", ascending=False)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 1) Evaluate: all TFs\n",
    "# =========================================================\n",
    "\n",
    "scores_all = df[\"edge_score\"].values\n",
    "labels_all = df[\"is_gt\"].values\n",
    "\n",
    "summary_all = summarize_ranking(scores_all, labels_all, name=\"All TFs\")\n",
    "print(\"\\n[All TFs] GT enrichment by quantile:\")\n",
    "print(enrichment_by_quantiles(scores_all, labels_all).to_string(\n",
    "    index=False, float_format=lambda x: f\"{x:.6f}\"\n",
    "))\n",
    "\n",
    "plot_reliability(scores_all, labels_all,\n",
    "                 title=\"Calibration: All TFs (edge_score vs ChIP)\")\n",
    "\n",
    "conf_df_all, conf_tbl_all = make_confidence_table(df, \"edge_score\", \"is_gt\")\n",
    "print(\"\\n[All TFs] Confidence bins:\")\n",
    "print(conf_tbl_all.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "# conf_df_all now has columns: TF, TG, edge_score, is_gt, confidence_bin\n",
    "# You can export only high-confidence edges:\n",
    "# conf_df_all[conf_df_all[\"confidence_bin\"]==\"high\"][[\"TF\",\"TG\",\"edge_score\"]]\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2) Evaluate: ChIP TFs only (sharper check)\n",
    "# =========================================================\n",
    "\n",
    "chip_df = pd.read_csv(\"data/ground_truth_files/mESC_beeline_ChIP-seq.csv\")\n",
    "chip_tfs = set(chip_df[\"Gene1\"].unique())\n",
    "\n",
    "df_chip = df[df[\"TF\"].isin(chip_tfs)].copy()\n",
    "scores_c = df_chip[\"edge_score\"].values\n",
    "labels_c = df_chip[\"is_gt\"].values\n",
    "\n",
    "summary_chip = summarize_ranking(scores_c, labels_c,\n",
    "                                 name=\"ChIP TFs only\")\n",
    "\n",
    "print(\"\\n[ChIP TFs only] GT enrichment by quantile:\")\n",
    "print(enrichment_by_quantiles(scores_c, labels_c).to_string(\n",
    "    index=False, float_format=lambda x: f\"{x:.6f}\"\n",
    "))\n",
    "\n",
    "plot_reliability(scores_c, labels_c,\n",
    "                 title=\"Calibration: ChIP TFs only (edge_score vs ChIP)\")\n",
    "\n",
    "conf_df_chip, conf_tbl_chip = make_confidence_table(df_chip,\n",
    "                                                    \"edge_score\",\n",
    "                                                    \"is_gt\")\n",
    "print(\"\\n[ChIP TFs only] Confidence bins:\")\n",
    "print(conf_tbl_chip.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "# Again, high-confidence candidate GRN:\n",
    "# conf_df_chip[conf_df_chip[\"confidence_bin\"]==\"high\"][[\"TF\",\"TG\",\"edge_score\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59993758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration set: n=408269, positives=83961\n",
      "Chosen calibrated p-threshold = 0.407 (precision=0.515, n_pos=6417)\n",
      "\n",
      "High-confidence network:\n",
      "  edges passing p >= 0.407: 43548\n",
      "  unique TFs: 475, unique TGs: 996\n",
      "Saved calibrated high-confidence GRN to: output/model_classifier_testing/inferred_grn.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# ============================================================\n",
    "# 1. Assume df already exists with columns:\n",
    "#    TF, TG, edge_score, is_gt  (is_gt from ChIP)\n",
    "# ============================================================\n",
    "\n",
    "# If needed, load from disk instead:\n",
    "# df = pd.read_csv(\"labeled_df.csv\")  # must contain the columns above\n",
    "\n",
    "# Basic sanity checks\n",
    "req_cols = {\"TF\", \"TG\", \"edge_score\", \"is_gt\"}\n",
    "missing = req_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"df is missing required columns: {missing}\")\n",
    "\n",
    "df = df.copy()\n",
    "df[\"edge_score\"] = df[\"edge_score\"].astype(float)\n",
    "df[\"is_gt\"] = df[\"is_gt\"].astype(bool)\n",
    "\n",
    "# ============================================================\n",
    "# 2. Build calibration set (ChIP TFs only; more reliable regime)\n",
    "# ============================================================\n",
    "\n",
    "chip_tfs = set(df.loc[df[\"is_gt\"], \"TF\"].unique())\n",
    "cal_mask = df[\"TF\"].isin(chip_tfs)\n",
    "\n",
    "cal = df[cal_mask].copy()\n",
    "print(f\"Calibration set: n={len(cal)}, positives={cal['is_gt'].sum()}\")\n",
    "\n",
    "if cal[\"is_gt\"].sum() < 50:\n",
    "    raise RuntimeError(\"Too few GT positives in calibration set for reliable calibration.\")\n",
    "\n",
    "# Sort by score for isotonic regression\n",
    "cal_sorted = cal.sort_values(\"edge_score\")\n",
    "x = cal_sorted[\"edge_score\"].values\n",
    "y = cal_sorted[\"is_gt\"].values.astype(float)\n",
    "\n",
    "# Fit monotone mapping score -> P(GT)\n",
    "iso = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "iso.fit(x, y)\n",
    "\n",
    "# Attach calibrated probabilities to calibration subset\n",
    "cal[\"p_cal\"] = iso.predict(cal[\"edge_score\"].values)\n",
    "\n",
    "# ============================================================\n",
    "# 3. Pick a probability threshold from calibration\n",
    "#    Strategy: choose smallest p where precision >= target_prec\n",
    "# ============================================================\n",
    "\n",
    "def choose_threshold_from_calibration(cal_df, p_col=\"p_cal\",\n",
    "                                      target_prec=0.5,\n",
    "                                      min_positives=50):\n",
    "    \"\"\"\n",
    "    Choose a calibrated probability threshold such that\n",
    "    precision(P(GT | score) >= thr) >= target_prec on calibration set.\n",
    "    \"\"\"\n",
    "    scores = cal_df[p_col].values\n",
    "    labels = cal_df[\"is_gt\"].values.astype(int)\n",
    "\n",
    "    # Use actual labels for precision-recall curve\n",
    "    prec, rec, thr = precision_recall_curve(labels, scores)\n",
    "\n",
    "    # precision_recall_curve returns thr for all but first point\n",
    "    thr = np.concatenate(([0.0], thr))  # align lengths\n",
    "\n",
    "    # mask thresholds that give enough positives\n",
    "    # (avoid ultra-high thresholds with 3 edges)\n",
    "    n_pred_pos = [(scores >= t).sum() for t in thr]\n",
    "    n_pred_pos = np.array(n_pred_pos)\n",
    "\n",
    "    ok = (prec >= target_prec) & (n_pred_pos >= min_positives)\n",
    "    if not np.any(ok):\n",
    "        # fallback: use percentile-based threshold (e.g. top 5%)\n",
    "        q = 0.95\n",
    "        backup_thr = np.quantile(scores, q)\n",
    "        print(f\"[WARN] No threshold hit precision>={target_prec}. \"\n",
    "              f\"Using backup q={q:.2f} (thr={backup_thr:.3f}).\")\n",
    "        return float(backup_thr)\n",
    "\n",
    "    # pick the *lowest* threshold that satisfies conditions\n",
    "    best_idx = np.where(ok)[0][0]\n",
    "    chosen_thr = float(thr[best_idx])\n",
    "\n",
    "    print(f\"Chosen calibrated p-threshold = {chosen_thr:.3f} \"\n",
    "          f\"(precision={prec[best_idx]:.3f}, n_pos={n_pred_pos[best_idx]})\")\n",
    "    return chosen_thr\n",
    "\n",
    "p_threshold = choose_threshold_from_calibration(\n",
    "    cal,\n",
    "    p_col=\"p_cal\",\n",
    "    target_prec=0.5,      # require ≥50% ChIP precision in calibration set\n",
    "    min_positives=100,    # at least 100 predicted positives to be stable\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 4. Apply calibration to ALL edges and build high-confidence GRN\n",
    "# ============================================================\n",
    "\n",
    "# Calibrated probability for all edges\n",
    "df[\"p_edge\"] = iso.predict(df[\"edge_score\"].values)\n",
    "\n",
    "# High-confidence edges: calibrated P(GT) >= p_threshold\n",
    "hc = df[df[\"p_edge\"] >= p_threshold].copy()\n",
    "\n",
    "# (Optional) constrain to top-K per TF to avoid giant hubs\n",
    "TOP_K_PER_TF = 500  # tune as you like\n",
    "\n",
    "hc = (\n",
    "    hc.sort_values([\"TF\", \"p_edge\"], ascending=[True, False])\n",
    "      .groupby(\"TF\", as_index=False)\n",
    "      .head(TOP_K_PER_TF)\n",
    ")\n",
    "\n",
    "print(f\"\\nHigh-confidence network:\")\n",
    "print(f\"  edges passing p >= {p_threshold:.3f}: {len(hc)}\")\n",
    "print(f\"  unique TFs: {hc['TF'].nunique()}, unique TGs: {hc['TG'].nunique()}\")\n",
    "\n",
    "# Save\n",
    "out_path = \"output/model_classifier_testing/inferred_grn.csv\"\n",
    "hc = hc.rename(columns={\"p_edge\":\"Score\"})\n",
    "hc[[\"TF\", \"TG\", \"Score\"]].to_csv(\n",
    "    out_path, sep=\",\", index=False\n",
    ")\n",
    "print(f\"Saved calibrated high-confidence GRN to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e26ee9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "motif_mask = torch.load(\"data/training_data_cache/mESC_no_scale_linear/chr1/motif_mask_chr1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05fd8eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     0.0000,      0.0000,      0.0000,  ...,      0.0000,\n",
      "              0.0000,      0.0000],\n",
      "        [     0.0000,      0.0000,      0.0000,  ...,      0.0000,\n",
      "              0.0000,      0.0000],\n",
      "        [     0.0000,      0.0000,      0.0000,  ..., -27209.9961,\n",
      "         -49381.5156, -39295.1172],\n",
      "        ...,\n",
      "        [     0.0000,      0.0000,      0.0000,  ...,      0.0000,\n",
      "         -46684.1367, -39094.7305],\n",
      "        [     0.0000,      0.0000,      0.0000,  ...,      0.0000,\n",
      "         -43699.2031, -38727.0508],\n",
      "        [     0.0000,      0.0000,      0.0000,  ...,      0.0000,\n",
      "              0.0000,      0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(motif_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
